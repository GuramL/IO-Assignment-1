{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **QUESTION 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store</th>\n",
       "      <th>week</th>\n",
       "      <th>brand</th>\n",
       "      <th>sales_</th>\n",
       "      <th>count</th>\n",
       "      <th>price_</th>\n",
       "      <th>prom_</th>\n",
       "      <th>cost_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>14181</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>13965</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>13538</td>\n",
       "      <td>3.37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>13735</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>13735</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   store  week  brand  sales_  count  price_  prom_  cost_\n",
       "0      2     1      1      16  14181    3.29    0.0   2.06\n",
       "1      2     2      1      12  13965    3.27    0.0   2.04\n",
       "2      2     3      1       6  13538    3.37    0.0   2.15\n",
       "3      2     4      1      12  13735    3.30    0.0   2.07\n",
       "4      2     5      1      10  13735    3.34    0.0   2.12"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################################### Question 1 (Preparation and Data Import) ###################################\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "df1 = pd.read_csv(\"OTC_Sales.csv\",sep=\"\\t\")\n",
    "df2 = pd.read_csv(\"OTC_Demographics.csv\",sep=\"\\t\")\n",
    "df3 = pd.read_csv(\"OTC_Instruments.csv\",sep=\"\\t\")\n",
    "\n",
    "\n",
    "df1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "share_1: 0.14513692602512893\n",
      "share_2: 0.17988041419128795\n",
      "share_3: 0.11786960705561754\n",
      "share_4: 0.11845629580078901\n",
      "share_5: 0.07822151064127274\n",
      "share_6: 0.035480961401911947\n",
      "share_7: 0.04076390164464756\n",
      "share_8: 0.03445288532976568\n",
      "share_9: 0.0800747891073284\n",
      "share_10: 0.09615938194808078\n",
      "share_11: 0.07350332685416947\n"
     ]
    }
   ],
   "source": [
    "################################### Summary statistics for the table 1 ###################################\n",
    "\n",
    "# Calculate the total sales\n",
    "total_sales = df1['sales_'].sum()\n",
    "\n",
    "# Calculate the sales share for each brand\n",
    "brand_sales = df1.groupby('brand')['sales_'].sum()\n",
    "\n",
    "\n",
    "# Generate share variables for each brand\n",
    "share_1 = brand_sales[1] / total_sales\n",
    "share_2 = brand_sales[2] / total_sales\n",
    "share_3 = brand_sales[3] / total_sales\n",
    "share_4 = brand_sales[4] / total_sales\n",
    "share_5 = brand_sales[5] / total_sales\n",
    "share_6 = brand_sales[6] / total_sales\n",
    "share_7 = brand_sales[7] / total_sales\n",
    "share_8 = brand_sales[8] / total_sales\n",
    "share_9 = brand_sales[9] / total_sales\n",
    "share_10 = brand_sales[10] / total_sales\n",
    "share_11 = brand_sales[11] / total_sales\n",
    "\n",
    "# Print the share variables\n",
    "print(f\"share_1: {share_1}\")\n",
    "print(f\"share_2: {share_2}\")\n",
    "print(f\"share_3: {share_3}\")\n",
    "print(f\"share_4: {share_4}\")\n",
    "print(f\"share_5: {share_5}\")\n",
    "print(f\"share_6: {share_6}\")\n",
    "print(f\"share_7: {share_7}\")\n",
    "print(f\"share_8: {share_8}\")\n",
    "print(f\"share_9: {share_9}\")\n",
    "print(f\"share_10: {share_10}\")\n",
    "print(f\"share_11: {share_11}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weighted_avg_price_1: 3.414884775217227\n",
      "weighted_avg_price_2: 4.888457470318381\n",
      "weighted_avg_price_3: 6.935243987533144\n",
      "weighted_avg_price_4: 2.938778235511942\n",
      "weighted_avg_price_5: 5.02520433197813\n",
      "weighted_avg_price_6: 8.071122701282645\n",
      "weighted_avg_price_7: 2.670661107001143\n",
      "weighted_avg_price_8: 3.600319089679319\n",
      "weighted_avg_price_9: 3.9389793892084364\n",
      "weighted_avg_price_10: 1.8611150392017106\n",
      "weighted_avg_price_11: 4.29954384394465\n",
      "weighted_avg_cost_1: 2.17952871174915\n",
      "weighted_avg_cost_2: 3.6696483928489783\n",
      "weighted_avg_cost_3: 5.748667255896171\n",
      "weighted_avg_cost_4: 2.0292830031475653\n",
      "weighted_avg_cost_5: 3.6047360857984017\n",
      "weighted_avg_cost_6: 6.104660794313088\n",
      "weighted_avg_cost_7: 1.8421487658887619\n",
      "weighted_avg_cost_8: 2.484719503461447\n",
      "weighted_avg_cost_9: 3.7093806491372225\n",
      "weighted_avg_cost_10: 0.9077034925160371\n",
      "weighted_avg_cost_11: 1.8716247062772742\n"
     ]
    }
   ],
   "source": [
    "######################################### Weighted average price and cost for each brand #########################################\n",
    "\n",
    "for i in range(1, 12):\n",
    "    weighted_avg_price_i = (df1[df1['brand'] == i]['sales_'] * df1[df1['brand'] == i]['price_']).sum() / df1[df1['brand'] == i]['sales_'].sum()\n",
    "    print(f\"weighted_avg_price_{i}: {weighted_avg_price_i}\")\n",
    "\n",
    "# Calculate the weighted average cost (wholesale price) for each brand\n",
    "\n",
    "for i in range(1, 12):\n",
    "    weighted_avg_cost_i = (df1[df1['brand'] == i]['sales_'] * df1[df1['brand'] == i]['cost_']).sum() / df1[df1['brand'] == i]['sales_'].sum()\n",
    "    print(f\"weighted_avg_cost_{i}: {weighted_avg_cost_i}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **QUESTION 2**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store</th>\n",
       "      <th>week</th>\n",
       "      <th>brand</th>\n",
       "      <th>sales_</th>\n",
       "      <th>count</th>\n",
       "      <th>price_</th>\n",
       "      <th>prom_</th>\n",
       "      <th>cost_</th>\n",
       "      <th>sales_per_count</th>\n",
       "      <th>share_0</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>14181</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.06</td>\n",
       "      <td>0.001128</td>\n",
       "      <td>0.993724</td>\n",
       "      <td>-6.780774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>13965</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.04</td>\n",
       "      <td>0.000859</td>\n",
       "      <td>0.993913</td>\n",
       "      <td>-7.053298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>13538</td>\n",
       "      <td>3.37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>0.995199</td>\n",
       "      <td>-7.716683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>13735</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.07</td>\n",
       "      <td>0.000874</td>\n",
       "      <td>0.993957</td>\n",
       "      <td>-7.036735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>13735</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.12</td>\n",
       "      <td>0.000728</td>\n",
       "      <td>0.995268</td>\n",
       "      <td>-7.220374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   store  week  brand  sales_  count  price_  prom_  cost_  sales_per_count  \\\n",
       "0      2     1      1      16  14181    3.29    0.0   2.06         0.001128   \n",
       "1      2     2      1      12  13965    3.27    0.0   2.04         0.000859   \n",
       "2      2     3      1       6  13538    3.37    0.0   2.15         0.000443   \n",
       "3      2     4      1      12  13735    3.30    0.0   2.07         0.000874   \n",
       "4      2     5      1      10  13735    3.34    0.0   2.12         0.000728   \n",
       "\n",
       "    share_0         Y  \n",
       "0  0.993724 -6.780774  \n",
       "1  0.993913 -7.053298  \n",
       "2  0.995199 -7.716683  \n",
       "3  0.993957 -7.036735  \n",
       "4  0.995268 -7.220374  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####################################### Question 2 (Data Preparation) #######################################\n",
    "\n",
    "df1['sales_per_count'] = df1['sales_'] / df1['count']\n",
    "\n",
    "df1['share_0'] = 1 - df1.groupby(['store', 'week'])['sales_per_count'].transform('sum')\n",
    "\n",
    "df1['Y'] = np.log(df1['sales_per_count']) - np.log(df1['share_0'])\n",
    "\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   R-squared:                       0.016\n",
      "Model:                            OLS   Adj. R-squared:                  0.016\n",
      "Method:                 Least Squares   F-statistic:                     315.2\n",
      "Date:                Thu, 06 Feb 2025   Prob (F-statistic):          1.72e-136\n",
      "Time:                        20:16:41   Log-Likelihood:                -50711.\n",
      "No. Observations:               38544   AIC:                         1.014e+05\n",
      "Df Residuals:                   38541   BIC:                         1.015e+05\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -7.7660      0.012   -627.345      0.000      -7.790      -7.742\n",
      "prom_          0.2130      0.016     13.074      0.000       0.181       0.245\n",
      "price_        -0.0514      0.003    -20.194      0.000      -0.056      -0.046\n",
      "==============================================================================\n",
      "Omnibus:                     2323.526   Durbin-Watson:                   0.558\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2372.728\n",
      "Skew:                          -0.566   Prob(JB):                         0.00\n",
      "Kurtosis:                       2.558   Cond. No.                         17.7\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "##################################### OLS Q2.(a) #####################################\n",
    "\n",
    "# Define the independent variables\n",
    "X = df1[['prom_', 'price_']]\n",
    "\n",
    "# Add a constant to the independent variables\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Define the dependent variable\n",
    "Y = df1['Y']\n",
    "\n",
    "# Fit the regression model\n",
    "model = sm.OLS(Y, X).fit()\n",
    "\n",
    "# Print the regression results\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store</th>\n",
       "      <th>week</th>\n",
       "      <th>brand</th>\n",
       "      <th>sales_</th>\n",
       "      <th>count</th>\n",
       "      <th>price_</th>\n",
       "      <th>prom_</th>\n",
       "      <th>cost_</th>\n",
       "      <th>sales_per_count</th>\n",
       "      <th>share_0</th>\n",
       "      <th>Y</th>\n",
       "      <th>tyl</th>\n",
       "      <th>adv</th>\n",
       "      <th>bay</th>\n",
       "      <th>sto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>14181</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.06</td>\n",
       "      <td>0.001128</td>\n",
       "      <td>0.993724</td>\n",
       "      <td>-6.780774</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>13965</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.04</td>\n",
       "      <td>0.000859</td>\n",
       "      <td>0.993913</td>\n",
       "      <td>-7.053298</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>13538</td>\n",
       "      <td>3.37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>0.995199</td>\n",
       "      <td>-7.716683</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>13735</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.07</td>\n",
       "      <td>0.000874</td>\n",
       "      <td>0.993957</td>\n",
       "      <td>-7.036735</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>13735</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.12</td>\n",
       "      <td>0.000728</td>\n",
       "      <td>0.995268</td>\n",
       "      <td>-7.220374</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   store  week  brand  sales_  count  price_  prom_  cost_  sales_per_count  \\\n",
       "0      2     1      1      16  14181    3.29    0.0   2.06         0.001128   \n",
       "1      2     2      1      12  13965    3.27    0.0   2.04         0.000859   \n",
       "2      2     3      1       6  13538    3.37    0.0   2.15         0.000443   \n",
       "3      2     4      1      12  13735    3.30    0.0   2.07         0.000874   \n",
       "4      2     5      1      10  13735    3.34    0.0   2.12         0.000728   \n",
       "\n",
       "    share_0         Y  tyl  adv  bay  sto  \n",
       "0  0.993724 -6.780774    1    0    0    0  \n",
       "1  0.993913 -7.053298    1    0    0    0  \n",
       "2  0.995199 -7.716683    1    0    0    0  \n",
       "3  0.993957 -7.036735    1    0    0    0  \n",
       "4  0.995268 -7.220374    1    0    0    0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######################################## Generate Dummies for Product Type ########################################\n",
    "\n",
    "# Create dummy variables\n",
    "df1['tyl'] = df1['brand'].isin([1, 2, 3]).astype(int)\n",
    "df1['adv'] = df1['brand'].isin([4, 5, 6]).astype(int)\n",
    "df1['bay'] = df1['brand'].isin([7, 8, 9]).astype(int)\n",
    "df1['sto'] = df1['brand'].isin([10, 11]).astype(int)\n",
    "\n",
    "# Display the first few rows to verify\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   R-squared:                       0.370\n",
      "Model:                            OLS   Adj. R-squared:                  0.370\n",
      "Method:                 Least Squares   F-statistic:                     4535.\n",
      "Date:                Thu, 06 Feb 2025   Prob (F-statistic):               0.00\n",
      "Time:                        20:16:41   Log-Likelihood:                -42106.\n",
      "No. Observations:               38544   AIC:                         8.422e+04\n",
      "Df Residuals:                   38538   BIC:                         8.427e+04\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -5.7781      0.009   -648.960      0.000      -5.796      -5.761\n",
      "price_        -0.1886      0.002    -78.175      0.000      -0.193      -0.184\n",
      "prom_          0.4458      0.013     33.887      0.000       0.420       0.472\n",
      "tyl           -0.5455      0.007    -73.282      0.000      -0.560      -0.531\n",
      "adv           -1.3392      0.008   -170.461      0.000      -1.355      -1.324\n",
      "bay           -2.1007      0.006   -332.015      0.000      -2.113      -2.088\n",
      "sto           -1.7926      0.007   -243.914      0.000      -1.807      -1.778\n",
      "==============================================================================\n",
      "Omnibus:                     1560.106   Durbin-Watson:                   0.872\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1767.102\n",
      "Skew:                          -0.500   Prob(JB):                         0.00\n",
      "Kurtosis:                       3.314   Cond. No.                     2.80e+15\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 1.16e-25. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "##################################### OLS Q2.(b) #####################################\n",
    "\n",
    "# Define the independent variables including the dummy variables\n",
    "X = df1[['price_', 'prom_', 'tyl', 'adv', 'bay', 'sto']]\n",
    "\n",
    "# Add a constant to the independent variables\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Define the dependent variable\n",
    "Y = df1['Y']\n",
    "\n",
    "# Fit the regression model\n",
    "model_with_dummies = sm.OLS(Y, X).fit()\n",
    "\n",
    "# Print the regression results\n",
    "print(model_with_dummies.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_75222/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_75222/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store</th>\n",
       "      <th>week</th>\n",
       "      <th>brand</th>\n",
       "      <th>sales_</th>\n",
       "      <th>count</th>\n",
       "      <th>price_</th>\n",
       "      <th>prom_</th>\n",
       "      <th>cost_</th>\n",
       "      <th>sales_per_count</th>\n",
       "      <th>share_0</th>\n",
       "      <th>...</th>\n",
       "      <th>bay_store_121</th>\n",
       "      <th>sto_store_121</th>\n",
       "      <th>tyl_store_122</th>\n",
       "      <th>adv_store_122</th>\n",
       "      <th>bay_store_122</th>\n",
       "      <th>sto_store_122</th>\n",
       "      <th>tyl_store_123</th>\n",
       "      <th>adv_store_123</th>\n",
       "      <th>bay_store_123</th>\n",
       "      <th>sto_store_123</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>14181</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.06</td>\n",
       "      <td>0.001128</td>\n",
       "      <td>0.993724</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>13965</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.04</td>\n",
       "      <td>0.000859</td>\n",
       "      <td>0.993913</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>13538</td>\n",
       "      <td>3.37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>0.995199</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>13735</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.07</td>\n",
       "      <td>0.000874</td>\n",
       "      <td>0.993957</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>13735</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.12</td>\n",
       "      <td>0.000728</td>\n",
       "      <td>0.995268</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 307 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   store  week  brand  sales_  count  price_  prom_  cost_  sales_per_count  \\\n",
       "0      2     1      1      16  14181    3.29    0.0   2.06         0.001128   \n",
       "1      2     2      1      12  13965    3.27    0.0   2.04         0.000859   \n",
       "2      2     3      1       6  13538    3.37    0.0   2.15         0.000443   \n",
       "3      2     4      1      12  13735    3.30    0.0   2.07         0.000874   \n",
       "4      2     5      1      10  13735    3.34    0.0   2.12         0.000728   \n",
       "\n",
       "    share_0  ...  bay_store_121  sto_store_121  tyl_store_122  adv_store_122  \\\n",
       "0  0.993724  ...              0              0              0              0   \n",
       "1  0.993913  ...              0              0              0              0   \n",
       "2  0.995199  ...              0              0              0              0   \n",
       "3  0.993957  ...              0              0              0              0   \n",
       "4  0.995268  ...              0              0              0              0   \n",
       "\n",
       "   bay_store_122  sto_store_122  tyl_store_123  adv_store_123  bay_store_123  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   sto_store_123  \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              0  \n",
       "\n",
       "[5 rows x 307 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############################################### Fixed Effects for Everything ###############################################\n",
    "\n",
    "# Generate new variables for each unique combination of store number and tyl, adv, bay, and sto\n",
    "for store in df1['store'].unique():\n",
    "    df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
    "    df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
    "    df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
    "    df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
    "\n",
    "# Display the first few rows to verify\n",
    "df1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "const           -7.200177\n",
      "price_          -0.188035\n",
      "prom_            0.443860\n",
      "tyl_store_2      0.824262\n",
      "adv_store_2      0.155209\n",
      "                   ...   \n",
      "sto_store_122    0.141384\n",
      "tyl_store_123    0.938088\n",
      "adv_store_123    0.025048\n",
      "bay_store_123   -0.829285\n",
      "sto_store_123   -0.217803\n",
      "Length: 295, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "##################################### OLS Q2.(c) Fixed Effects Model #####################################\n",
    "\n",
    "# Define the independent variables including the dummy variables\n",
    "X_fixed_effects = df1[['price_', 'prom_'] + [col for col in df1.columns if '_store' in col]]\n",
    "\n",
    "# Add a constant to the independent variables\n",
    "X_fixed_effects = sm.add_constant(X_fixed_effects)\n",
    "\n",
    "# Define the dependent variable\n",
    "Y = df1['Y']\n",
    "\n",
    "# Fit the regression model\n",
    "fixed_effects_model = sm.OLS(Y, X_fixed_effects).fit()\n",
    "\n",
    "# Print the coefficients for price and promotion\n",
    "print(fixed_effects_model.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          IV2SLS Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   R-squared:                    -402.655\n",
      "Model:                         IV2SLS   Adj. R-squared:               -402.676\n",
      "Method:                     Two Stage   F-statistic:                 2.269e-08\n",
      "                        Least Squares   Prob (F-statistic):               1.00\n",
      "Date:                Thu, 06 Feb 2025                                         \n",
      "Time:                        20:27:19                                         \n",
      "No. Observations:               38544                                         \n",
      "Df Residuals:                   38541                                         \n",
      "Df Model:                           2                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -9.9143   8.22e+05  -1.21e-05      1.000   -1.61e+06    1.61e+06\n",
      "prom_         63.7277   2.24e+06   2.84e-05      1.000    -4.4e+06     4.4e+06\n",
      "price_        -1.0083   1.07e+05  -9.39e-06      1.000    -2.1e+05     2.1e+05\n",
      "==============================================================================\n",
      "Omnibus:                    16766.478   Durbin-Watson:                   1.250\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            59096.604\n",
      "Skew:                          -2.304   Prob(JB):                         0.00\n",
      "Kurtosis:                       6.945   Cond. No.                         17.7\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "####################################### OLS Q2.(d) #####################################\n",
    "\n",
    "\n",
    "from statsmodels.sandbox.regression.gmm import IV2SLS\n",
    "\n",
    "###################################### Q2.(d) #####################################\n",
    "\n",
    "# Define the instrument variable\n",
    "instrument = df1['cost_']\n",
    "\n",
    "# First regression: original model\n",
    "X = df1[['prom_', 'price_']]\n",
    "X = sm.add_constant(X)\n",
    "Y = df1['Y']\n",
    "model_iv = IV2SLS(Y, X, instrument=instrument).fit()\n",
    "print(model_iv.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          IV2SLS Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   R-squared:                  -26401.342\n",
      "Model:                         IV2SLS   Adj. R-squared:             -26405.453\n",
      "Method:                     Two Stage   F-statistic:                 1.383e-12\n",
      "                        Least Squares   Prob (F-statistic):               1.00\n",
      "Date:                Thu, 06 Feb 2025                                         \n",
      "Time:                        20:27:42                                         \n",
      "No. Observations:               38544                                         \n",
      "Df Residuals:                   38537                                         \n",
      "Df Model:                           6                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         34.7875        nan        nan        nan         nan         nan\n",
      "price_       -16.9280   5.41e+06  -3.13e-06      1.000   -1.06e+07    1.06e+07\n",
      "prom_       -244.5878        nan        nan        nan         nan         nan\n",
      "tyl           70.1779        nan        nan        nan         nan         nan\n",
      "adv          207.7923        nan        nan        nan         nan         nan\n",
      "bay         -134.1796    1.1e+08  -1.22e-06      1.000   -2.16e+08    2.16e+08\n",
      "sto          120.3137        nan        nan        nan         nan         nan\n",
      "==============================================================================\n",
      "Omnibus:                     2656.748   Durbin-Watson:                   0.285\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             3212.652\n",
      "Skew:                           0.701   Prob(JB):                         0.00\n",
      "Kurtosis:                       2.821   Cond. No.                          nan\n",
      "==============================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/statsmodels/sandbox/regression/gmm.py:290: RuntimeWarning: invalid value encountered in sqrt\n",
      "  condno = np.sqrt(eigvals[-1]/eigvals[0])\n",
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1884: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return np.sqrt(np.diag(self.cov_params()))\n"
     ]
    }
   ],
   "source": [
    "# Second regression: model with dummies\n",
    "X_dummies = df1[['price_', 'prom_', 'tyl', 'adv', 'bay', 'sto']]\n",
    "X_dummies = sm.add_constant(X_dummies)\n",
    "model_iv_dummies = IV2SLS(Y, X_dummies, instrument=instrument).fit()\n",
    "print(model_iv_dummies.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    IV2SLS Regression Results                                                     \n",
      "==================================================================================================================================\n",
      "Dep. Variable:                      Y   R-squared:          -14150158091774929084288182590758937299020044459459455452832595968.000\n",
      "Model:                         IV2SLS   Adj. R-squared:     -14258922934750740862731063574446402798759246554793865038121664512.000\n",
      "Method:                     Two Stage   F-statistic:                                                                     1.800e-18\n",
      "                        Least Squares   Prob (F-statistic):                                                                   1.00\n",
      "Date:                Thu, 06 Feb 2025                                                                                             \n",
      "Time:                        20:28:19                                                                                             \n",
      "No. Observations:               38544                                                                                             \n",
      "Df Residuals:                   38249                                                                                             \n",
      "Df Model:                         294                                                                                             \n",
      "=================================================================================\n",
      "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "const          4.323e+16        nan        nan        nan         nan         nan\n",
      "price_         2.984e+14        nan        nan        nan         nan         nan\n",
      "prom_         -2.783e+17        nan        nan        nan         nan         nan\n",
      "tyl_store_2    2.567e+18        nan        nan        nan         nan         nan\n",
      "adv_store_2   -1.179e+19        nan        nan        nan         nan         nan\n",
      "bay_store_2    -1.16e+19        nan        nan        nan         nan         nan\n",
      "sto_store_2   -3.524e+19        nan        nan        nan         nan         nan\n",
      "tyl_store_5    3.175e+18        nan        nan        nan         nan         nan\n",
      "adv_store_5   -4.656e+19        nan        nan        nan         nan         nan\n",
      "bay_store_5    3.337e+18        nan        nan        nan         nan         nan\n",
      "sto_store_5    9.905e+18        nan        nan        nan         nan         nan\n",
      "tyl_store_8    8.039e+18        nan        nan        nan         nan         nan\n",
      "adv_store_8    1.795e+18        nan        nan        nan         nan         nan\n",
      "bay_store_8    7.406e+18        nan        nan        nan         nan         nan\n",
      "sto_store_8    1.563e+19        nan        nan        nan         nan         nan\n",
      "tyl_store_9    5.717e+18        nan        nan        nan         nan         nan\n",
      "adv_store_9   -6.566e+18        nan        nan        nan         nan         nan\n",
      "bay_store_9   -1.546e+18        nan        nan        nan         nan         nan\n",
      "sto_store_9   -7.218e+18        nan        nan        nan         nan         nan\n",
      "tyl_store_12   2.217e+18        nan        nan        nan         nan         nan\n",
      "adv_store_12   1.522e+18        nan        nan        nan         nan         nan\n",
      "bay_store_12   3.965e+18        nan        nan        nan         nan         nan\n",
      "sto_store_12  -1.584e+19        nan        nan        nan         nan         nan\n",
      "tyl_store_14  -1.153e+18        nan        nan        nan         nan         nan\n",
      "adv_store_14  -5.552e+18        nan        nan        nan         nan         nan\n",
      "bay_store_14   2.767e+17        nan        nan        nan         nan         nan\n",
      "sto_store_14  -1.209e+18        nan        nan        nan         nan         nan\n",
      "tyl_store_18   1.172e+18        nan        nan        nan         nan         nan\n",
      "adv_store_18   2.862e+17        nan        nan        nan         nan         nan\n",
      "bay_store_18  -2.864e+19        nan        nan        nan         nan         nan\n",
      "sto_store_18  -3.395e+19        nan        nan        nan         nan         nan\n",
      "tyl_store_21   2.144e+18        nan        nan        nan         nan         nan\n",
      "adv_store_21  -8.693e+18        nan        nan        nan         nan         nan\n",
      "bay_store_21   1.353e+19        nan        nan        nan         nan         nan\n",
      "sto_store_21   2.187e+19        nan        nan        nan         nan         nan\n",
      "tyl_store_28  -5.417e+18        nan        nan        nan         nan         nan\n",
      "adv_store_28  -4.206e+16        nan        nan        nan         nan         nan\n",
      "bay_store_28   -9.85e+18        nan        nan        nan         nan         nan\n",
      "sto_store_28    1.88e+19        nan        nan        nan         nan         nan\n",
      "tyl_store_32  -3.501e+18        nan        nan        nan         nan         nan\n",
      "adv_store_32   2.413e+19        nan        nan        nan         nan         nan\n",
      "bay_store_32  -7.106e+18        nan        nan        nan         nan         nan\n",
      "sto_store_32   -5.07e+18        nan        nan        nan         nan         nan\n",
      "tyl_store_33   1.971e+18        nan        nan        nan         nan         nan\n",
      "adv_store_33  -6.592e+18        nan        nan        nan         nan         nan\n",
      "bay_store_33   -1.17e+19        nan        nan        nan         nan         nan\n",
      "sto_store_33   7.773e+18        nan        nan        nan         nan         nan\n",
      "tyl_store_40  -1.291e+19        nan        nan        nan         nan         nan\n",
      "adv_store_40   -3.52e+17        nan        nan        nan         nan         nan\n",
      "bay_store_40  -2.214e+19        nan        nan        nan         nan         nan\n",
      "sto_store_40   -1.83e+19        nan        nan        nan         nan         nan\n",
      "tyl_store_44   7.689e+18        nan        nan        nan         nan         nan\n",
      "adv_store_44  -5.128e+18        nan        nan        nan         nan         nan\n",
      "bay_store_44  -1.884e+18        nan        nan        nan         nan         nan\n",
      "sto_store_44   3.939e+18        nan        nan        nan         nan         nan\n",
      "tyl_store_45  -5.989e+17        nan        nan        nan         nan         nan\n",
      "adv_store_45   4.891e+18        nan        nan        nan         nan         nan\n",
      "bay_store_45  -3.043e+18        nan        nan        nan         nan         nan\n",
      "sto_store_45  -8.288e+19        nan        nan        nan         nan         nan\n",
      "tyl_store_47  -1.055e+18        nan        nan        nan         nan         nan\n",
      "adv_store_47  -9.824e+18        nan        nan        nan         nan         nan\n",
      "bay_store_47   9.777e+18        nan        nan        nan         nan         nan\n",
      "sto_store_47   2.858e+19        nan        nan        nan         nan         nan\n",
      "tyl_store_48   -3.48e+18        nan        nan        nan         nan         nan\n",
      "adv_store_48   5.567e+18        nan        nan        nan         nan         nan\n",
      "bay_store_48   1.163e+19        nan        nan        nan         nan         nan\n",
      "sto_store_48   3.928e+19        nan        nan        nan         nan         nan\n",
      "tyl_store_49  -4.563e+18        nan        nan        nan         nan         nan\n",
      "adv_store_49   3.534e+18        nan        nan        nan         nan         nan\n",
      "bay_store_49   -9.27e+18        nan        nan        nan         nan         nan\n",
      "sto_store_49    1.23e+19        nan        nan        nan         nan         nan\n",
      "tyl_store_50  -4.584e+18        nan        nan        nan         nan         nan\n",
      "adv_store_50   2.003e+18        nan        nan        nan         nan         nan\n",
      "bay_store_50   4.655e+18        nan        nan        nan         nan         nan\n",
      "sto_store_50  -1.125e+19        nan        nan        nan         nan         nan\n",
      "tyl_store_51  -1.977e+18        nan        nan        nan         nan         nan\n",
      "adv_store_51   4.012e+18        nan        nan        nan         nan         nan\n",
      "bay_store_51   -9.13e+17        nan        nan        nan         nan         nan\n",
      "sto_store_51   5.383e+19        nan        nan        nan         nan         nan\n",
      "tyl_store_52  -3.943e+18        nan        nan        nan         nan         nan\n",
      "adv_store_52   6.143e+18        nan        nan        nan         nan         nan\n",
      "bay_store_52   1.141e+19        nan        nan        nan         nan         nan\n",
      "sto_store_52   3.209e+19        nan        nan        nan         nan         nan\n",
      "tyl_store_53  -2.839e+18        nan        nan        nan         nan         nan\n",
      "adv_store_53   5.415e+18        nan        nan        nan         nan         nan\n",
      "bay_store_53   1.278e+18        nan        nan        nan         nan         nan\n",
      "sto_store_53   4.516e+17        nan        nan        nan         nan         nan\n",
      "tyl_store_54   5.277e+18        nan        nan        nan         nan         nan\n",
      "adv_store_54   2.735e+18        nan        nan        nan         nan         nan\n",
      "bay_store_54   1.387e+19        nan        nan        nan         nan         nan\n",
      "sto_store_54   1.738e+19        nan        nan        nan         nan         nan\n",
      "tyl_store_56   8.938e+18        nan        nan        nan         nan         nan\n",
      "adv_store_56   9.445e+18        nan        nan        nan         nan         nan\n",
      "bay_store_56   1.493e+19        nan        nan        nan         nan         nan\n",
      "sto_store_56   2.505e+19        nan        nan        nan         nan         nan\n",
      "tyl_store_59   1.255e+18        nan        nan        nan         nan         nan\n",
      "adv_store_59  -4.354e+18        nan        nan        nan         nan         nan\n",
      "bay_store_59  -1.691e+18        nan        nan        nan         nan         nan\n",
      "sto_store_59   2.207e+19        nan        nan        nan         nan         nan\n",
      "tyl_store_62   1.269e+18   7.38e+39   1.72e-22      1.000   -1.45e+40    1.45e+40\n",
      "adv_store_62   5.474e+18        nan        nan        nan         nan         nan\n",
      "bay_store_62    7.98e+18        nan        nan        nan         nan         nan\n",
      "sto_store_62  -7.062e+18        nan        nan        nan         nan         nan\n",
      "tyl_store_64   2.534e+18        nan        nan        nan         nan         nan\n",
      "adv_store_64   7.826e+17        nan        nan        nan         nan         nan\n",
      "bay_store_64  -1.318e+19        nan        nan        nan         nan         nan\n",
      "sto_store_64    8.32e+18        nan        nan        nan         nan         nan\n",
      "tyl_store_67   8.134e+18        nan        nan        nan         nan         nan\n",
      "adv_store_67  -1.219e+18        nan        nan        nan         nan         nan\n",
      "bay_store_67  -2.669e+18        nan        nan        nan         nan         nan\n",
      "sto_store_67  -2.775e+18        nan        nan        nan         nan         nan\n",
      "tyl_store_68   3.208e+18        nan        nan        nan         nan         nan\n",
      "adv_store_68   3.131e+18        nan        nan        nan         nan         nan\n",
      "bay_store_68  -1.758e+19        nan        nan        nan         nan         nan\n",
      "sto_store_68   2.299e+19        nan        nan        nan         nan         nan\n",
      "tyl_store_70   1.206e+19        nan        nan        nan         nan         nan\n",
      "adv_store_70   7.656e+18        nan        nan        nan         nan         nan\n",
      "bay_store_70  -3.814e+17        nan        nan        nan         nan         nan\n",
      "sto_store_70  -3.186e+19        nan        nan        nan         nan         nan\n",
      "tyl_store_71  -5.111e+16        nan        nan        nan         nan         nan\n",
      "adv_store_71  -1.788e+19        nan        nan        nan         nan         nan\n",
      "bay_store_71   1.161e+19        nan        nan        nan         nan         nan\n",
      "sto_store_71    2.07e+19        nan        nan        nan         nan         nan\n",
      "tyl_store_72  -5.391e+17        nan        nan        nan         nan         nan\n",
      "adv_store_72  -5.991e+17        nan        nan        nan         nan         nan\n",
      "bay_store_72   1.625e+17        nan        nan        nan         nan         nan\n",
      "sto_store_72   -3.08e+19        nan        nan        nan         nan         nan\n",
      "tyl_store_73    1.32e+19        nan        nan        nan         nan         nan\n",
      "adv_store_73  -3.768e+18        nan        nan        nan         nan         nan\n",
      "bay_store_73  -1.916e+18        nan        nan        nan         nan         nan\n",
      "sto_store_73   4.957e+19        nan        nan        nan         nan         nan\n",
      "tyl_store_74   3.818e+18        nan        nan        nan         nan         nan\n",
      "adv_store_74   7.322e+18        nan        nan        nan         nan         nan\n",
      "bay_store_74  -1.789e+19        nan        nan        nan         nan         nan\n",
      "sto_store_74  -4.004e+19        nan        nan        nan         nan         nan\n",
      "tyl_store_75   9.952e+17        nan        nan        nan         nan         nan\n",
      "adv_store_75  -9.688e+18        nan        nan        nan         nan         nan\n",
      "bay_store_75  -6.304e+18        nan        nan        nan         nan         nan\n",
      "sto_store_75   3.924e+19        nan        nan        nan         nan         nan\n",
      "tyl_store_76  -4.231e+18        nan        nan        nan         nan         nan\n",
      "adv_store_76   7.199e+18        nan        nan        nan         nan         nan\n",
      "bay_store_76    1.14e+18        nan        nan        nan         nan         nan\n",
      "sto_store_76   3.052e+19        nan        nan        nan         nan         nan\n",
      "tyl_store_77   9.038e+18        nan        nan        nan         nan         nan\n",
      "adv_store_77   -5.71e+18        nan        nan        nan         nan         nan\n",
      "bay_store_77  -8.245e+18        nan        nan        nan         nan         nan\n",
      "sto_store_77  -1.189e+19        nan        nan        nan         nan         nan\n",
      "tyl_store_78   1.246e+18        nan        nan        nan         nan         nan\n",
      "adv_store_78   6.642e+18        nan        nan        nan         nan         nan\n",
      "bay_store_78   5.165e+18        nan        nan        nan         nan         nan\n",
      "sto_store_78   4.755e+19        nan        nan        nan         nan         nan\n",
      "tyl_store_80  -7.966e+18        nan        nan        nan         nan         nan\n",
      "adv_store_80   -1.12e+18        nan        nan        nan         nan         nan\n",
      "bay_store_80  -7.684e+18        nan        nan        nan         nan         nan\n",
      "sto_store_80  -2.615e+19        nan        nan        nan         nan         nan\n",
      "tyl_store_81  -7.487e+18        nan        nan        nan         nan         nan\n",
      "adv_store_81  -3.005e+18        nan        nan        nan         nan         nan\n",
      "bay_store_81  -7.899e+18        nan        nan        nan         nan         nan\n",
      "sto_store_81  -1.274e+19        nan        nan        nan         nan         nan\n",
      "tyl_store_83    6.99e+18        nan        nan        nan         nan         nan\n",
      "adv_store_83  -3.053e+18        nan        nan        nan         nan         nan\n",
      "bay_store_83   6.421e+18        nan        nan        nan         nan         nan\n",
      "sto_store_83  -1.629e+19        nan        nan        nan         nan         nan\n",
      "tyl_store_84    7.77e+15        nan        nan        nan         nan         nan\n",
      "adv_store_84   -3.76e+17        nan        nan        nan         nan         nan\n",
      "bay_store_84  -4.851e+17        nan        nan        nan         nan         nan\n",
      "sto_store_84  -1.846e+19        nan        nan        nan         nan         nan\n",
      "tyl_store_86   6.984e+18        nan        nan        nan         nan         nan\n",
      "adv_store_86    5.58e+18        nan        nan        nan         nan         nan\n",
      "bay_store_86   2.823e+18        nan        nan        nan         nan         nan\n",
      "sto_store_86  -4.526e+19        nan        nan        nan         nan         nan\n",
      "tyl_store_89  -4.588e+17        nan        nan        nan         nan         nan\n",
      "adv_store_89   6.116e+18        nan        nan        nan         nan         nan\n",
      "bay_store_89  -8.713e+18        nan        nan        nan         nan         nan\n",
      "sto_store_89  -1.628e+19        nan        nan        nan         nan         nan\n",
      "tyl_store_90  -4.625e+18        nan        nan        nan         nan         nan\n",
      "adv_store_90  -9.513e+17        nan        nan        nan         nan         nan\n",
      "bay_store_90   1.164e+18        nan        nan        nan         nan         nan\n",
      "sto_store_90   9.518e+18        nan        nan        nan         nan         nan\n",
      "tyl_store_91  -8.798e+17        nan        nan        nan         nan         nan\n",
      "adv_store_91   1.522e+18        nan        nan        nan         nan         nan\n",
      "bay_store_91  -7.325e+18        nan        nan        nan         nan         nan\n",
      "sto_store_91   2.001e+19        nan        nan        nan         nan         nan\n",
      "tyl_store_92   7.366e+18        nan        nan        nan         nan         nan\n",
      "adv_store_92  -2.512e+18        nan        nan        nan         nan         nan\n",
      "bay_store_92   7.019e+18        nan        nan        nan         nan         nan\n",
      "sto_store_92   2.529e+19        nan        nan        nan         nan         nan\n",
      "tyl_store_93   -2.11e+18        nan        nan        nan         nan         nan\n",
      "adv_store_93   3.713e+18        nan        nan        nan         nan         nan\n",
      "bay_store_93   8.666e+18        nan        nan        nan         nan         nan\n",
      "sto_store_93   -1.58e+19        nan        nan        nan         nan         nan\n",
      "tyl_store_94  -1.334e+18        nan        nan        nan         nan         nan\n",
      "adv_store_94   -8.02e+18        nan        nan        nan         nan         nan\n",
      "bay_store_94  -1.278e+19        nan        nan        nan         nan         nan\n",
      "sto_store_94  -1.082e+19        nan        nan        nan         nan         nan\n",
      "tyl_store_95  -3.598e+18        nan        nan        nan         nan         nan\n",
      "adv_store_95   1.246e+18        nan        nan        nan         nan         nan\n",
      "bay_store_95  -4.305e+18        nan        nan        nan         nan         nan\n",
      "sto_store_95  -8.494e+18        nan        nan        nan         nan         nan\n",
      "tyl_store_97   2.562e+18        nan        nan        nan         nan         nan\n",
      "adv_store_97   1.251e+33        nan        nan        nan         nan         nan\n",
      "bay_store_97  -7.473e+16        nan        nan        nan         nan         nan\n",
      "sto_store_97   4.036e+19        nan        nan        nan         nan         nan\n",
      "tyl_store_98  -4.842e+18        nan        nan        nan         nan         nan\n",
      "adv_store_98   4.415e+18        nan        nan        nan         nan         nan\n",
      "bay_store_98  -4.126e+18        nan        nan        nan         nan         nan\n",
      "sto_store_98  -1.698e+19        nan        nan        nan         nan         nan\n",
      "tyl_store_100  1.718e+18        nan        nan        nan         nan         nan\n",
      "adv_store_100  5.751e+18        nan        nan        nan         nan         nan\n",
      "bay_store_100 -1.364e+19        nan        nan        nan         nan         nan\n",
      "sto_store_100  1.323e+19        nan        nan        nan         nan         nan\n",
      "tyl_store_101 -6.928e+18        nan        nan        nan         nan         nan\n",
      "adv_store_101  2.121e+18        nan        nan        nan         nan         nan\n",
      "bay_store_101  2.023e+19        nan        nan        nan         nan         nan\n",
      "sto_store_101 -8.733e+18        nan        nan        nan         nan         nan\n",
      "tyl_store_102  4.393e+17        nan        nan        nan         nan         nan\n",
      "adv_store_102 -7.857e+18        nan        nan        nan         nan         nan\n",
      "bay_store_102  9.945e+18        nan        nan        nan         nan         nan\n",
      "sto_store_102  1.069e+19        nan        nan        nan         nan         nan\n",
      "tyl_store_103 -3.896e+18        nan        nan        nan         nan         nan\n",
      "adv_store_103 -4.725e+16        nan        nan        nan         nan         nan\n",
      "bay_store_103 -1.847e+19        nan        nan        nan         nan         nan\n",
      "sto_store_103  2.087e+19        nan        nan        nan         nan         nan\n",
      "tyl_store_104 -1.878e+18        nan        nan        nan         nan         nan\n",
      "adv_store_104  9.056e+18        nan        nan        nan         nan         nan\n",
      "bay_store_104  9.576e+18        nan        nan        nan         nan         nan\n",
      "sto_store_104  -2.48e+19        nan        nan        nan         nan         nan\n",
      "tyl_store_105  3.907e+18        nan        nan        nan         nan         nan\n",
      "adv_store_105  8.544e+18        nan        nan        nan         nan         nan\n",
      "bay_store_105  9.703e+17        nan        nan        nan         nan         nan\n",
      "sto_store_105 -2.345e+19        nan        nan        nan         nan         nan\n",
      "tyl_store_106  1.797e+18        nan        nan        nan         nan         nan\n",
      "adv_store_106 -4.094e+17        nan        nan        nan         nan         nan\n",
      "bay_store_106 -3.057e+18        nan        nan        nan         nan         nan\n",
      "sto_store_106 -1.517e+18        nan        nan        nan         nan         nan\n",
      "tyl_store_107 -3.184e+18        nan        nan        nan         nan         nan\n",
      "adv_store_107 -4.585e+18        nan        nan        nan         nan         nan\n",
      "bay_store_107  9.296e+18        nan        nan        nan         nan         nan\n",
      "sto_store_107  2.563e+19        nan        nan        nan         nan         nan\n",
      "tyl_store_109  8.101e+18        nan        nan        nan         nan         nan\n",
      "adv_store_109  9.713e+18        nan        nan        nan         nan         nan\n",
      "bay_store_109  -4.23e+18        nan        nan        nan         nan         nan\n",
      "sto_store_109 -1.316e+19        nan        nan        nan         nan         nan\n",
      "tyl_store_110  4.523e+18        nan        nan        nan         nan         nan\n",
      "adv_store_110 -2.913e+18        nan        nan        nan         nan         nan\n",
      "bay_store_110 -4.149e+18        nan        nan        nan         nan         nan\n",
      "sto_store_110  2.176e+19        nan        nan        nan         nan         nan\n",
      "tyl_store_111 -3.784e+18        nan        nan        nan         nan         nan\n",
      "adv_store_111 -6.153e+18        nan        nan        nan         nan         nan\n",
      "bay_store_111  8.698e+18        nan        nan        nan         nan         nan\n",
      "sto_store_111  3.099e+18        nan        nan        nan         nan         nan\n",
      "tyl_store_112  9.094e+16        nan        nan        nan         nan         nan\n",
      "adv_store_112 -4.844e+18        nan        nan        nan         nan         nan\n",
      "bay_store_112 -6.296e+18        nan        nan        nan         nan         nan\n",
      "sto_store_112 -1.286e+19        nan        nan        nan         nan         nan\n",
      "tyl_store_113 -8.394e+18        nan        nan        nan         nan         nan\n",
      "adv_store_113   5.65e+18        nan        nan        nan         nan         nan\n",
      "bay_store_113  2.131e+18        nan        nan        nan         nan         nan\n",
      "sto_store_113 -4.617e+19        nan        nan        nan         nan         nan\n",
      "tyl_store_114 -1.145e+18        nan        nan        nan         nan         nan\n",
      "adv_store_114 -5.466e+17        nan        nan        nan         nan         nan\n",
      "bay_store_114 -2.396e+18        nan        nan        nan         nan         nan\n",
      "sto_store_114 -1.865e+19        nan        nan        nan         nan         nan\n",
      "tyl_store_115 -5.877e+18        nan        nan        nan         nan         nan\n",
      "adv_store_115 -9.013e+17        nan        nan        nan         nan         nan\n",
      "bay_store_115  6.382e+18        nan        nan        nan         nan         nan\n",
      "sto_store_115   1.04e+19        nan        nan        nan         nan         nan\n",
      "tyl_store_116  8.326e+18        nan        nan        nan         nan         nan\n",
      "adv_store_116 -1.251e+33        nan        nan        nan         nan         nan\n",
      "bay_store_116  1.424e+19        nan        nan        nan         nan         nan\n",
      "sto_store_116  2.317e+19        nan        nan        nan         nan         nan\n",
      "tyl_store_117 -3.686e+18        nan        nan        nan         nan         nan\n",
      "adv_store_117  2.211e+19        nan        nan        nan         nan         nan\n",
      "bay_store_117 -2.628e+18        nan        nan        nan         nan         nan\n",
      "sto_store_117  4.824e+18        nan        nan        nan         nan         nan\n",
      "tyl_store_118 -7.239e+18        nan        nan        nan         nan         nan\n",
      "adv_store_118  -8.35e+17        nan        nan        nan         nan         nan\n",
      "bay_store_118  3.365e+18        nan        nan        nan         nan         nan\n",
      "sto_store_118 -2.158e+19        nan        nan        nan         nan         nan\n",
      "tyl_store_119  1.257e+19        nan        nan        nan         nan         nan\n",
      "adv_store_119 -1.294e+19        nan        nan        nan         nan         nan\n",
      "bay_store_119 -9.009e+18        nan        nan        nan         nan         nan\n",
      "sto_store_119  3.011e+19        nan        nan        nan         nan         nan\n",
      "tyl_store_121 -3.799e+16        nan        nan        nan         nan         nan\n",
      "adv_store_121  6.915e+18        nan        nan        nan         nan         nan\n",
      "bay_store_121 -9.472e+18        nan        nan        nan         nan         nan\n",
      "sto_store_121  4.927e+18        nan        nan        nan         nan         nan\n",
      "tyl_store_122 -1.435e+18        nan        nan        nan         nan         nan\n",
      "adv_store_122 -3.257e+18        nan        nan        nan         nan         nan\n",
      "bay_store_122 -1.153e+19        nan        nan        nan         nan         nan\n",
      "sto_store_122 -4.736e+19        nan        nan        nan         nan         nan\n",
      "tyl_store_123 -2.475e+18        nan        nan        nan         nan         nan\n",
      "adv_store_123  5.497e+18        nan        nan        nan         nan         nan\n",
      "bay_store_123  7.612e+18        nan        nan        nan         nan         nan\n",
      "sto_store_123  6.388e+18        nan        nan        nan         nan         nan\n",
      "==============================================================================\n",
      "Omnibus:                    15823.086   Durbin-Watson:                   0.014\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):         27490481.944\n",
      "Skew:                           0.000   Prob(JB):                         0.00\n",
      "Kurtosis:                     133.833   Cond. No.                     3.25e+09\n",
      "==============================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 294, but rank is 292\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1884: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return np.sqrt(np.diag(self.cov_params()))\n"
     ]
    }
   ],
   "source": [
    "# Third regression: fixed effects model\n",
    "X_fixed_effects = df1[['price_', 'prom_'] + [col for col in df1.columns if '_store' in col]]\n",
    "X_fixed_effects = sm.add_constant(X_fixed_effects)\n",
    "model_iv_fixed_effects = IV2SLS(Y, X_fixed_effects, instrument=instrument).fit()\n",
    "print(model_iv_fixed_effects.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
