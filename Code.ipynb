{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **QUESTION 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store</th>\n",
       "      <th>week</th>\n",
       "      <th>brand</th>\n",
       "      <th>sales_</th>\n",
       "      <th>count</th>\n",
       "      <th>price_</th>\n",
       "      <th>prom_</th>\n",
       "      <th>cost_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>14181</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>13965</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>13538</td>\n",
       "      <td>3.37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>13735</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>13735</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   store  week  brand  sales_  count  price_  prom_  cost_\n",
       "0      2     1      1      16  14181    3.29    0.0   2.06\n",
       "1      2     2      1      12  13965    3.27    0.0   2.04\n",
       "2      2     3      1       6  13538    3.37    0.0   2.15\n",
       "3      2     4      1      12  13735    3.30    0.0   2.07\n",
       "4      2     5      1      10  13735    3.34    0.0   2.12"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################################### Question 1 (Preparation and Data Import) ###################################\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "df1 = pd.read_csv(\"OTC_Sales.csv\",sep=\"\\t\")\n",
    "df2 = pd.read_csv(\"OTC_Demographics.csv\",sep=\"\\t\")\n",
    "df3 = pd.read_csv(\"OTC_Instruments.csv\",sep=\"\\t\")\n",
    "\n",
    "\n",
    "df1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "share_1: 0.14513692602512893\n",
      "share_2: 0.17988041419128795\n",
      "share_3: 0.11786960705561754\n",
      "share_4: 0.11845629580078901\n",
      "share_5: 0.07822151064127274\n",
      "share_6: 0.035480961401911947\n",
      "share_7: 0.04076390164464756\n",
      "share_8: 0.03445288532976568\n",
      "share_9: 0.0800747891073284\n",
      "share_10: 0.09615938194808078\n",
      "share_11: 0.07350332685416947\n"
     ]
    }
   ],
   "source": [
    "################################### Summary statistics for the table 1 ###################################\n",
    "\n",
    "# Calculate the total sales\n",
    "total_sales = df1['sales_'].sum()\n",
    "\n",
    "# Calculate the sales share for each brand\n",
    "brand_sales = df1.groupby('brand')['sales_'].sum()\n",
    "\n",
    "\n",
    "# Generate share variables for each brand\n",
    "share_1 = brand_sales[1] / total_sales\n",
    "share_2 = brand_sales[2] / total_sales\n",
    "share_3 = brand_sales[3] / total_sales\n",
    "share_4 = brand_sales[4] / total_sales\n",
    "share_5 = brand_sales[5] / total_sales\n",
    "share_6 = brand_sales[6] / total_sales\n",
    "share_7 = brand_sales[7] / total_sales\n",
    "share_8 = brand_sales[8] / total_sales\n",
    "share_9 = brand_sales[9] / total_sales\n",
    "share_10 = brand_sales[10] / total_sales\n",
    "share_11 = brand_sales[11] / total_sales\n",
    "\n",
    "# Print the share variables\n",
    "print(f\"share_1: {share_1}\")\n",
    "print(f\"share_2: {share_2}\")\n",
    "print(f\"share_3: {share_3}\")\n",
    "print(f\"share_4: {share_4}\")\n",
    "print(f\"share_5: {share_5}\")\n",
    "print(f\"share_6: {share_6}\")\n",
    "print(f\"share_7: {share_7}\")\n",
    "print(f\"share_8: {share_8}\")\n",
    "print(f\"share_9: {share_9}\")\n",
    "print(f\"share_10: {share_10}\")\n",
    "print(f\"share_11: {share_11}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weighted_avg_price_1: 3.414884775217227\n",
      "weighted_avg_price_2: 4.888457470318381\n",
      "weighted_avg_price_3: 6.935243987533144\n",
      "weighted_avg_price_4: 2.938778235511942\n",
      "weighted_avg_price_5: 5.02520433197813\n",
      "weighted_avg_price_6: 8.071122701282645\n",
      "weighted_avg_price_7: 2.670661107001143\n",
      "weighted_avg_price_8: 3.600319089679319\n",
      "weighted_avg_price_9: 3.9389793892084364\n",
      "weighted_avg_price_10: 1.8611150392017106\n",
      "weighted_avg_price_11: 4.29954384394465\n",
      "weighted_avg_cost_1: 2.17952871174915\n",
      "weighted_avg_cost_2: 3.6696483928489783\n",
      "weighted_avg_cost_3: 5.748667255896171\n",
      "weighted_avg_cost_4: 2.0292830031475653\n",
      "weighted_avg_cost_5: 3.6047360857984017\n",
      "weighted_avg_cost_6: 6.104660794313088\n",
      "weighted_avg_cost_7: 1.8421487658887619\n",
      "weighted_avg_cost_8: 2.484719503461447\n",
      "weighted_avg_cost_9: 3.7093806491372225\n",
      "weighted_avg_cost_10: 0.9077034925160371\n",
      "weighted_avg_cost_11: 1.8716247062772742\n"
     ]
    }
   ],
   "source": [
    "######################################### Weighted average price and cost for each brand #########################################\n",
    "\n",
    "for i in range(1, 12):\n",
    "    weighted_avg_price_i = (df1[df1['brand'] == i]['sales_'] * df1[df1['brand'] == i]['price_']).sum() / df1[df1['brand'] == i]['sales_'].sum()\n",
    "    print(f\"weighted_avg_price_{i}: {weighted_avg_price_i}\")\n",
    "\n",
    "# Calculate the weighted average cost (wholesale price) for each brand\n",
    "\n",
    "for i in range(1, 12):\n",
    "    weighted_avg_cost_i = (df1[df1['brand'] == i]['sales_'] * df1[df1['brand'] == i]['cost_']).sum() / df1[df1['brand'] == i]['sales_'].sum()\n",
    "    print(f\"weighted_avg_cost_{i}: {weighted_avg_cost_i}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **QUESTION 2**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store</th>\n",
       "      <th>week</th>\n",
       "      <th>brand</th>\n",
       "      <th>sales_</th>\n",
       "      <th>count</th>\n",
       "      <th>price_</th>\n",
       "      <th>prom_</th>\n",
       "      <th>cost_</th>\n",
       "      <th>sales_per_count</th>\n",
       "      <th>share_0</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>14181</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.06</td>\n",
       "      <td>0.001128</td>\n",
       "      <td>0.993724</td>\n",
       "      <td>-6.780774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>13965</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.04</td>\n",
       "      <td>0.000859</td>\n",
       "      <td>0.993913</td>\n",
       "      <td>-7.053298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>13538</td>\n",
       "      <td>3.37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>0.995199</td>\n",
       "      <td>-7.716683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>13735</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.07</td>\n",
       "      <td>0.000874</td>\n",
       "      <td>0.993957</td>\n",
       "      <td>-7.036735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>13735</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.12</td>\n",
       "      <td>0.000728</td>\n",
       "      <td>0.995268</td>\n",
       "      <td>-7.220374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   store  week  brand  sales_  count  price_  prom_  cost_  sales_per_count  \\\n",
       "0      2     1      1      16  14181    3.29    0.0   2.06         0.001128   \n",
       "1      2     2      1      12  13965    3.27    0.0   2.04         0.000859   \n",
       "2      2     3      1       6  13538    3.37    0.0   2.15         0.000443   \n",
       "3      2     4      1      12  13735    3.30    0.0   2.07         0.000874   \n",
       "4      2     5      1      10  13735    3.34    0.0   2.12         0.000728   \n",
       "\n",
       "    share_0         Y  \n",
       "0  0.993724 -6.780774  \n",
       "1  0.993913 -7.053298  \n",
       "2  0.995199 -7.716683  \n",
       "3  0.993957 -7.036735  \n",
       "4  0.995268 -7.220374  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####################################### Question 2 (Data Preparation) #######################################\n",
    "\n",
    "df1['sales_per_count'] = df1['sales_'] / df1['count']\n",
    "\n",
    "df1['share_0'] = 1 - df1.groupby(['store', 'week'])['sales_per_count'].transform('sum')\n",
    "\n",
    "df1['Y'] = np.log(df1['sales_per_count']) - np.log(df1['share_0'])\n",
    "\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **QUESTION 2.A**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   R-squared:                       0.016\n",
      "Model:                            OLS   Adj. R-squared:                  0.016\n",
      "Method:                 Least Squares   F-statistic:                     315.2\n",
      "Date:                Fri, 07 Feb 2025   Prob (F-statistic):          1.72e-136\n",
      "Time:                        04:35:51   Log-Likelihood:                -50711.\n",
      "No. Observations:               38544   AIC:                         1.014e+05\n",
      "Df Residuals:                   38541   BIC:                         1.015e+05\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -7.7660      0.012   -627.345      0.000      -7.790      -7.742\n",
      "prom_          0.2130      0.016     13.074      0.000       0.181       0.245\n",
      "price_        -0.0514      0.003    -20.194      0.000      -0.056      -0.046\n",
      "==============================================================================\n",
      "Omnibus:                     2323.526   Durbin-Watson:                   0.558\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2372.728\n",
      "Skew:                          -0.566   Prob(JB):                         0.00\n",
      "Kurtosis:                       2.558   Cond. No.                         17.7\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "##################################### OLS Q2.(a) #####################################\n",
    "\n",
    "# Define the independent variables\n",
    "X = df1[['prom_', 'price_']]\n",
    "\n",
    "# Add a constant to the independent variables\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Define the dependent variable\n",
    "Y = df1['Y']\n",
    "\n",
    "# Fit the regression model\n",
    "model = sm.OLS(Y, X).fit()\n",
    "\n",
    "# Print the regression results\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **QUESTION 2.B**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store</th>\n",
       "      <th>week</th>\n",
       "      <th>brand</th>\n",
       "      <th>sales_</th>\n",
       "      <th>count</th>\n",
       "      <th>price_</th>\n",
       "      <th>prom_</th>\n",
       "      <th>cost_</th>\n",
       "      <th>sales_per_count</th>\n",
       "      <th>share_0</th>\n",
       "      <th>Y</th>\n",
       "      <th>tyl</th>\n",
       "      <th>adv</th>\n",
       "      <th>bay</th>\n",
       "      <th>sto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>14181</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.06</td>\n",
       "      <td>0.001128</td>\n",
       "      <td>0.993724</td>\n",
       "      <td>-6.780774</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>13965</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.04</td>\n",
       "      <td>0.000859</td>\n",
       "      <td>0.993913</td>\n",
       "      <td>-7.053298</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>13538</td>\n",
       "      <td>3.37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>0.995199</td>\n",
       "      <td>-7.716683</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>13735</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.07</td>\n",
       "      <td>0.000874</td>\n",
       "      <td>0.993957</td>\n",
       "      <td>-7.036735</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>13735</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.12</td>\n",
       "      <td>0.000728</td>\n",
       "      <td>0.995268</td>\n",
       "      <td>-7.220374</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   store  week  brand  sales_  count  price_  prom_  cost_  sales_per_count  \\\n",
       "0      2     1      1      16  14181    3.29    0.0   2.06         0.001128   \n",
       "1      2     2      1      12  13965    3.27    0.0   2.04         0.000859   \n",
       "2      2     3      1       6  13538    3.37    0.0   2.15         0.000443   \n",
       "3      2     4      1      12  13735    3.30    0.0   2.07         0.000874   \n",
       "4      2     5      1      10  13735    3.34    0.0   2.12         0.000728   \n",
       "\n",
       "    share_0         Y  tyl  adv  bay  sto  \n",
       "0  0.993724 -6.780774    1    0    0    0  \n",
       "1  0.993913 -7.053298    1    0    0    0  \n",
       "2  0.995199 -7.716683    1    0    0    0  \n",
       "3  0.993957 -7.036735    1    0    0    0  \n",
       "4  0.995268 -7.220374    1    0    0    0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######################################## Generate Dummies for Product Type ########################################\n",
    "\n",
    "# Create dummy variables\n",
    "df1['tyl'] = df1['brand'].isin([1, 2, 3]).astype(int)\n",
    "df1['adv'] = df1['brand'].isin([4, 5, 6]).astype(int)\n",
    "df1['bay'] = df1['brand'].isin([7, 8, 9]).astype(int)\n",
    "df1['sto'] = df1['brand'].isin([10, 11]).astype(int)\n",
    "\n",
    "# Display the first few rows to verify\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   R-squared:                       0.370\n",
      "Model:                            OLS   Adj. R-squared:                  0.370\n",
      "Method:                 Least Squares   F-statistic:                     4535.\n",
      "Date:                Fri, 07 Feb 2025   Prob (F-statistic):               0.00\n",
      "Time:                        04:35:51   Log-Likelihood:                -42106.\n",
      "No. Observations:               38544   AIC:                         8.422e+04\n",
      "Df Residuals:                   38538   BIC:                         8.427e+04\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -5.7781      0.009   -648.960      0.000      -5.796      -5.761\n",
      "price_        -0.1886      0.002    -78.175      0.000      -0.193      -0.184\n",
      "prom_          0.4458      0.013     33.887      0.000       0.420       0.472\n",
      "tyl           -0.5455      0.007    -73.282      0.000      -0.560      -0.531\n",
      "adv           -1.3392      0.008   -170.461      0.000      -1.355      -1.324\n",
      "bay           -2.1007      0.006   -332.015      0.000      -2.113      -2.088\n",
      "sto           -1.7926      0.007   -243.914      0.000      -1.807      -1.778\n",
      "==============================================================================\n",
      "Omnibus:                     1560.106   Durbin-Watson:                   0.872\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1767.102\n",
      "Skew:                          -0.500   Prob(JB):                         0.00\n",
      "Kurtosis:                       3.314   Cond. No.                     2.80e+15\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 1.16e-25. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "##################################### OLS Q2.(b) #####################################\n",
    "\n",
    "# Define the independent variables including the dummy variables\n",
    "X = df1[['price_', 'prom_', 'tyl', 'adv', 'bay', 'sto']]\n",
    "\n",
    "\n",
    "# Add a constant to the independent variables\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Define the dependent variable\n",
    "Y = df1['Y']\n",
    "\n",
    "# Fit the regression model\n",
    "model_with_dummies = sm.OLS(Y, X).fit()\n",
    "\n",
    "# Print the regression results\n",
    "print(model_with_dummies.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **QUESTION 2.C**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3187/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_3187/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store</th>\n",
       "      <th>week</th>\n",
       "      <th>brand</th>\n",
       "      <th>sales_</th>\n",
       "      <th>count</th>\n",
       "      <th>price_</th>\n",
       "      <th>prom_</th>\n",
       "      <th>cost_</th>\n",
       "      <th>sales_per_count</th>\n",
       "      <th>share_0</th>\n",
       "      <th>...</th>\n",
       "      <th>bay_store_121</th>\n",
       "      <th>sto_store_121</th>\n",
       "      <th>tyl_store_122</th>\n",
       "      <th>adv_store_122</th>\n",
       "      <th>bay_store_122</th>\n",
       "      <th>sto_store_122</th>\n",
       "      <th>tyl_store_123</th>\n",
       "      <th>adv_store_123</th>\n",
       "      <th>bay_store_123</th>\n",
       "      <th>sto_store_123</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>14181</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.06</td>\n",
       "      <td>0.001128</td>\n",
       "      <td>0.993724</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>13965</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.04</td>\n",
       "      <td>0.000859</td>\n",
       "      <td>0.993913</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>13538</td>\n",
       "      <td>3.37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>0.995199</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>13735</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.07</td>\n",
       "      <td>0.000874</td>\n",
       "      <td>0.993957</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>13735</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.12</td>\n",
       "      <td>0.000728</td>\n",
       "      <td>0.995268</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  307 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   store  week  brand  sales_  count  price_  prom_  cost_  sales_per_count  \\\n",
       "0      2     1      1      16  14181    3.29    0.0   2.06         0.001128   \n",
       "1      2     2      1      12  13965    3.27    0.0   2.04         0.000859   \n",
       "2      2     3      1       6  13538    3.37    0.0   2.15         0.000443   \n",
       "3      2     4      1      12  13735    3.30    0.0   2.07         0.000874   \n",
       "4      2     5      1      10  13735    3.34    0.0   2.12         0.000728   \n",
       "\n",
       "    share_0  ...  bay_store_121  sto_store_121  tyl_store_122  adv_store_122  \\\n",
       "0  0.993724  ...              0              0              0              0   \n",
       "1  0.993913  ...              0              0              0              0   \n",
       "2  0.995199  ...              0              0              0              0   \n",
       "3  0.993957  ...              0              0              0              0   \n",
       "4  0.995268  ...              0              0              0              0   \n",
       "\n",
       "   bay_store_122  sto_store_122  tyl_store_123  adv_store_123  bay_store_123  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   sto_store_123  \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              0  \n",
       "\n",
       "[5 rows x 307 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############################################### Fixed Effects for Everything ###############################################\n",
    "\n",
    "# Generate new variables for each unique combination of store number and tyl, adv, bay, and sto\n",
    "for store in df1['store'].unique():\n",
    "    df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
    "    df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
    "    df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
    "    df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
    "\n",
    "# Display the first few rows to verify\n",
    "df1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "const           -7.200177\n",
      "price_          -0.188035\n",
      "prom_            0.443860\n",
      "tyl_store_2      0.824262\n",
      "adv_store_2      0.155209\n",
      "                   ...   \n",
      "sto_store_122    0.141384\n",
      "tyl_store_123    0.938088\n",
      "adv_store_123    0.025048\n",
      "bay_store_123   -0.829285\n",
      "sto_store_123   -0.217803\n",
      "Length: 295, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "##################################### OLS Q2.(c) Fixed Effects Model #####################################\n",
    "\n",
    "# Define the independent variables including the dummy variables\n",
    "X_fixed_effects = df1[['price_', 'prom_'] + [col for col in df1.columns if '_store' in col]]\n",
    "\n",
    "\n",
    "# Add a constant to the independent variables\n",
    "X_fixed_effects = sm.add_constant(X_fixed_effects)\n",
    "\n",
    "# Define the dependent variable\n",
    "Y = df1['Y']\n",
    "\n",
    "# Fit the regression model\n",
    "fixed_effects_model = sm.OLS(Y, X_fixed_effects).fit()\n",
    "\n",
    "# Print the coefficients for price and promotion\n",
    "print(fixed_effects_model.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **QUESTION 2.D**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   R-squared:                       0.006\n",
      "Model:                            OLS   Adj. R-squared:                  0.006\n",
      "Method:                 Least Squares   F-statistic:                     117.7\n",
      "Date:                Fri, 07 Feb 2025   Prob (F-statistic):           1.09e-51\n",
      "Time:                        04:35:54   Log-Likelihood:                -50906.\n",
      "No. Observations:               38544   AIC:                         1.018e+05\n",
      "Df Residuals:                   38541   BIC:                         1.018e+05\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -7.9482      0.013   -611.462      0.000      -7.974      -7.923\n",
      "prom_          0.2409      0.016     14.770      0.000       0.209       0.273\n",
      "price_hat     -0.0106      0.003     -3.891      0.000      -0.016      -0.005\n",
      "==============================================================================\n",
      "Omnibus:                     2380.675   Durbin-Watson:                   0.555\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2436.579\n",
      "Skew:                          -0.574   Prob(JB):                         0.00\n",
      "Kurtosis:                       2.554   Cond. No.                         17.3\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3187/3327803042.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1['price_hat'] = first_stage.fittedvalues\n"
     ]
    }
   ],
   "source": [
    "####################################### OLS Q2.(d) #####################################\n",
    "\n",
    "# Define the independent variables and the instrument\n",
    "X = df1[['prom_']]\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "instrument = df1['cost_']\n",
    "\n",
    "# First stage: regress price_ on the instrument and other exogenous variables\n",
    "first_stage = sm.OLS(df1['price_'], sm.add_constant(instrument)).fit()\n",
    "df1['price_hat'] = first_stage.fittedvalues\n",
    "\n",
    "# Second stage: regress Y on the predicted values of price_ and other exogenous variables\n",
    "X['price_hat'] = df1['price_hat']\n",
    "second_stage = sm.OLS(Y, X).fit()\n",
    "\n",
    "# Print the regression results\n",
    "print(second_stage.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   R-squared:                       0.417\n",
      "Model:                            OLS   Adj. R-squared:                  0.417\n",
      "Method:                 Least Squares   F-statistic:                     4595.\n",
      "Date:                Fri, 07 Feb 2025   Prob (F-statistic):               0.00\n",
      "Time:                        04:35:55   Log-Likelihood:                -40623.\n",
      "No. Observations:               38544   AIC:                         8.126e+04\n",
      "Df Residuals:                   38537   BIC:                         8.132e+04\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -5.6167      0.009   -620.789      0.000      -5.634      -5.599\n",
      "price_        -0.5574      0.007    -79.205      0.000      -0.571      -0.544\n",
      "prom_          0.2917      0.013     22.510      0.000       0.266       0.317\n",
      "tyl           -0.6299      0.007    -86.017      0.000      -0.644      -0.616\n",
      "adv           -1.3330      0.008   -176.301      0.000      -1.348      -1.318\n",
      "bay           -2.2282      0.007   -342.421      0.000      -2.241      -2.215\n",
      "sto           -1.4256      0.010   -147.256      0.000      -1.445      -1.407\n",
      "cost_          0.4714      0.008     55.510      0.000       0.455       0.488\n",
      "==============================================================================\n",
      "Omnibus:                     2168.323   Durbin-Watson:                   0.960\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2818.321\n",
      "Skew:                          -0.543   Prob(JB):                         0.00\n",
      "Kurtosis:                       3.758   Cond. No.                     3.40e+15\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 1.19e-25. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "##################################### IV with Dummies #####################################\n",
    "\n",
    "# Second regression: model with dummies\n",
    "\n",
    "X_dummies = df1[['price_', 'prom_', 'tyl', 'adv', 'bay', 'sto','cost_']]\n",
    "\n",
    "X_dummies = sm.add_constant(X_dummies)\n",
    "model_iv_dummies = sm.OLS(Y, X_dummies).fit()\n",
    "print(model_iv_dummies.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   R-squared:                       0.401\n",
      "Model:                            OLS   Adj. R-squared:                  0.396\n",
      "Method:                 Least Squares   F-statistic:                     87.28\n",
      "Date:                Fri, 07 Feb 2025   Prob (F-statistic):               0.00\n",
      "Time:                        04:35:58   Log-Likelihood:                -41156.\n",
      "No. Observations:               38544   AIC:                         8.290e+04\n",
      "Df Residuals:                   38250   BIC:                         8.542e+04\n",
      "Df Model:                         293                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=================================================================================\n",
      "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "const            -7.3622      0.012   -620.879      0.000      -7.385      -7.339\n",
      "prom_             0.5031      0.013     38.959      0.000       0.478       0.528\n",
      "tyl_store_2       0.7846      0.059     13.331      0.000       0.669       0.900\n",
      "adv_store_2       0.0861      0.059      1.463      0.144      -0.029       0.201\n",
      "bay_store_2      -0.2717      0.059     -4.620      0.000      -0.387      -0.156\n",
      "sto_store_2      -0.9298      0.072    -12.899      0.000      -1.071      -0.789\n",
      "tyl_store_5       1.0744      0.059     18.255      0.000       0.959       1.190\n",
      "adv_store_5       0.3788      0.059      6.436      0.000       0.263       0.494\n",
      "bay_store_5      -0.4390      0.059     -7.465      0.000      -0.554      -0.324\n",
      "sto_store_5      -0.3322      0.072     -4.609      0.000      -0.474      -0.191\n",
      "tyl_store_8       0.9145      0.059     15.538      0.000       0.799       1.030\n",
      "adv_store_8      -0.1985      0.059     -3.373      0.001      -0.314      -0.083\n",
      "bay_store_8      -0.5111      0.059     -8.691      0.000      -0.626      -0.396\n",
      "sto_store_8      -0.1851      0.072     -2.567      0.010      -0.326      -0.044\n",
      "tyl_store_9       0.7485      0.059     12.718      0.000       0.633       0.864\n",
      "adv_store_9      -0.0413      0.059     -0.701      0.483      -0.157       0.074\n",
      "bay_store_9      -0.6188      0.059    -10.522      0.000      -0.734      -0.504\n",
      "sto_store_9      -0.6117      0.072     -8.484      0.000      -0.753      -0.470\n",
      "tyl_store_12      0.8570      0.059     14.560      0.000       0.742       0.972\n",
      "adv_store_12     -0.1445      0.059     -2.455      0.014      -0.260      -0.029\n",
      "bay_store_12     -0.7178      0.059    -12.206      0.000      -0.833      -0.603\n",
      "sto_store_12     -0.4179      0.072     -5.796      0.000      -0.559      -0.277\n",
      "tyl_store_14      1.0904      0.059     18.527      0.000       0.975       1.206\n",
      "adv_store_14      0.3197      0.059      5.432      0.000       0.204       0.435\n",
      "bay_store_14     -0.3446      0.059     -5.860      0.000      -0.460      -0.229\n",
      "sto_store_14     -0.6979      0.072     -9.680      0.000      -0.839      -0.557\n",
      "tyl_store_18      1.0470      0.059     17.790      0.000       0.932       1.162\n",
      "adv_store_18      0.0925      0.059      1.572      0.116      -0.023       0.208\n",
      "bay_store_18     -0.3804      0.059     -6.469      0.000      -0.496      -0.265\n",
      "sto_store_18     -0.6700      0.072     -9.294      0.000      -0.811      -0.529\n",
      "tyl_store_21      0.8109      0.059     13.779      0.000       0.696       0.926\n",
      "adv_store_21      0.0899      0.059      1.528      0.127      -0.025       0.205\n",
      "bay_store_21     -0.8372      0.059    -14.237      0.000      -0.952      -0.722\n",
      "sto_store_21     -0.1352      0.072     -1.875      0.061      -0.277       0.006\n",
      "tyl_store_28      0.8772      0.059     14.905      0.000       0.762       0.993\n",
      "adv_store_28      0.0306      0.059      0.520      0.603      -0.085       0.146\n",
      "bay_store_28     -0.6191      0.059    -10.529      0.000      -0.734      -0.504\n",
      "sto_store_28     -0.6876      0.072     -9.538      0.000      -0.829      -0.546\n",
      "tyl_store_32      0.6097      0.059     10.360      0.000       0.494       0.725\n",
      "adv_store_32     -0.2073      0.059     -3.522      0.000      -0.323      -0.092\n",
      "bay_store_32     -0.6774      0.059    -11.518      0.000      -0.793      -0.562\n",
      "sto_store_32     -0.8448      0.072    -11.717      0.000      -0.986      -0.703\n",
      "tyl_store_33      0.3301      0.059      5.608      0.000       0.215       0.445\n",
      "adv_store_33     -0.0681      0.059     -1.157      0.247      -0.183       0.047\n",
      "bay_store_33     -0.7489      0.059    -12.734      0.000      -0.864      -0.634\n",
      "sto_store_33     -0.8420      0.072    -11.679      0.000      -0.983      -0.701\n",
      "tyl_store_40      0.9027      0.059     15.338      0.000       0.787       1.018\n",
      "adv_store_40     -0.1858      0.059     -3.158      0.002      -0.301      -0.070\n",
      "bay_store_40     -0.7014      0.059    -11.927      0.000      -0.817      -0.586\n",
      "sto_store_40     -0.2277      0.072     -3.158      0.002      -0.369      -0.086\n",
      "tyl_store_44      0.7813      0.059     13.275      0.000       0.666       0.897\n",
      "adv_store_44     -0.0200      0.059     -0.340      0.734      -0.135       0.095\n",
      "bay_store_44     -0.3730      0.059     -6.343      0.000      -0.488      -0.258\n",
      "sto_store_44     -0.4724      0.072     -6.552      0.000      -0.614      -0.331\n",
      "tyl_store_45      0.9136      0.059     15.523      0.000       0.798       1.029\n",
      "adv_store_45      0.1251      0.059      2.125      0.034       0.010       0.240\n",
      "bay_store_45     -0.4855      0.059     -8.256      0.000      -0.601      -0.370\n",
      "sto_store_45     -0.3251      0.072     -4.509      0.000      -0.466      -0.184\n",
      "tyl_store_47      0.8779      0.059     14.917      0.000       0.763       0.993\n",
      "adv_store_47     -0.0894      0.059     -1.518      0.129      -0.205       0.026\n",
      "bay_store_47     -0.7427      0.059    -12.628      0.000      -0.858      -0.627\n",
      "sto_store_47     -0.5812      0.072     -8.061      0.000      -0.722      -0.440\n",
      "tyl_store_48      0.9101      0.059     15.462      0.000       0.795       1.025\n",
      "adv_store_48      0.1317      0.059      2.237      0.025       0.016       0.247\n",
      "bay_store_48     -0.4599      0.059     -7.822      0.000      -0.575      -0.345\n",
      "sto_store_48     -0.4708      0.072     -6.531      0.000      -0.612      -0.330\n",
      "tyl_store_49      0.6438      0.059     10.939      0.000       0.528       0.759\n",
      "adv_store_49     -0.1712      0.059     -2.909      0.004      -0.287      -0.056\n",
      "bay_store_49     -0.6436      0.059    -10.945      0.000      -0.759      -0.528\n",
      "sto_store_49     -0.4835      0.072     -6.707      0.000      -0.625      -0.342\n",
      "tyl_store_50      0.8681      0.059     14.749      0.000       0.753       0.983\n",
      "adv_store_50      0.0036      0.059      0.061      0.951      -0.112       0.119\n",
      "bay_store_50     -0.5809      0.059     -9.878      0.000      -0.696      -0.466\n",
      "sto_store_50     -0.4877      0.072     -6.764      0.000      -0.629      -0.346\n",
      "tyl_store_51      0.8508      0.059     14.456      0.000       0.735       0.966\n",
      "adv_store_51      0.1591      0.059      2.704      0.007       0.044       0.275\n",
      "bay_store_51     -0.4855      0.059     -8.256      0.000      -0.601      -0.370\n",
      "sto_store_51     -0.2935      0.072     -4.071      0.000      -0.435      -0.152\n",
      "tyl_store_52      0.8824      0.059     14.992      0.000       0.767       0.998\n",
      "adv_store_52      0.3014      0.059      5.121      0.000       0.186       0.417\n",
      "bay_store_52     -0.7335      0.059    -12.474      0.000      -0.849      -0.618\n",
      "sto_store_52     -0.6941      0.072     -9.628      0.000      -0.835      -0.553\n",
      "tyl_store_53      0.6928      0.059     11.771      0.000       0.577       0.808\n",
      "adv_store_53     -0.2301      0.059     -3.910      0.000      -0.346      -0.115\n",
      "bay_store_53     -0.7960      0.059    -13.536      0.000      -0.911      -0.681\n",
      "sto_store_53     -0.8595      0.072    -11.921      0.000      -1.001      -0.718\n",
      "tyl_store_54      0.9007      0.059     15.303      0.000       0.785       1.016\n",
      "adv_store_54      0.2254      0.059      3.830      0.000       0.110       0.341\n",
      "bay_store_54     -0.6120      0.059    -10.407      0.000      -0.727      -0.497\n",
      "sto_store_54     -0.0807      0.072     -1.119      0.263      -0.222       0.061\n",
      "tyl_store_56      0.7791      0.059     13.238      0.000       0.664       0.894\n",
      "adv_store_56     -0.1009      0.059     -1.715      0.086      -0.216       0.014\n",
      "bay_store_56     -0.5192      0.059     -8.830      0.000      -0.634      -0.404\n",
      "sto_store_56     -0.4526      0.072     -6.278      0.000      -0.594      -0.311\n",
      "tyl_store_59      0.9139      0.059     15.529      0.000       0.799       1.029\n",
      "adv_store_59      0.1729      0.059      2.937      0.003       0.057       0.288\n",
      "bay_store_59     -0.4639      0.059     -7.888      0.000      -0.579      -0.349\n",
      "sto_store_59     -0.3207      0.072     -4.449      0.000      -0.462      -0.179\n",
      "tyl_store_62      1.0989      0.059     18.670      0.000       0.983       1.214\n",
      "adv_store_62      0.6304      0.059     10.710      0.000       0.515       0.746\n",
      "bay_store_62     -0.1177      0.059     -2.001      0.045      -0.233      -0.002\n",
      "sto_store_62     -0.3230      0.072     -4.481      0.000      -0.464      -0.182\n",
      "tyl_store_64      0.8858      0.059     15.051      0.000       0.770       1.001\n",
      "adv_store_64      0.1780      0.059      3.025      0.002       0.063       0.293\n",
      "bay_store_64     -0.5477      0.059     -9.314      0.000      -0.663      -0.432\n",
      "sto_store_64     -0.0761      0.072     -1.056      0.291      -0.217       0.065\n",
      "tyl_store_67      0.8015      0.059     13.618      0.000       0.686       0.917\n",
      "adv_store_67      0.0058      0.059      0.099      0.921      -0.110       0.121\n",
      "bay_store_67     -0.3103      0.059     -5.277      0.000      -0.426      -0.195\n",
      "sto_store_67     -0.2535      0.072     -3.516      0.000      -0.395      -0.112\n",
      "tyl_store_68      0.6080      0.059     10.330      0.000       0.493       0.723\n",
      "adv_store_68     -0.3738      0.059     -6.351      0.000      -0.489      -0.258\n",
      "bay_store_68     -0.8557      0.059    -14.553      0.000      -0.971      -0.740\n",
      "sto_store_68     -0.9858      0.072    -13.673      0.000      -1.127      -0.845\n",
      "tyl_store_70      0.8860      0.059     15.053      0.000       0.771       1.001\n",
      "adv_store_70      0.0099      0.059      0.168      0.867      -0.105       0.125\n",
      "bay_store_70     -0.4277      0.059     -7.272      0.000      -0.543      -0.312\n",
      "sto_store_70     -0.6128      0.072     -8.501      0.000      -0.754      -0.471\n",
      "tyl_store_71      0.7078      0.059     12.027      0.000       0.592       0.823\n",
      "adv_store_71     -0.1649      0.059     -2.801      0.005      -0.280      -0.050\n",
      "bay_store_71     -0.6295      0.059    -10.705      0.000      -0.745      -0.514\n",
      "sto_store_71     -0.2517      0.072     -3.491      0.000      -0.393      -0.110\n",
      "tyl_store_72      0.7397      0.059     12.568      0.000       0.624       0.855\n",
      "adv_store_72     -0.1736      0.059     -2.949      0.003      -0.289      -0.058\n",
      "bay_store_72     -0.7532      0.059    -12.808      0.000      -0.868      -0.638\n",
      "sto_store_72     -0.8639      0.072    -11.983      0.000      -1.005      -0.723\n",
      "tyl_store_73      0.8158      0.059     13.862      0.000       0.700       0.931\n",
      "adv_store_73     -0.2588      0.059     -4.397      0.000      -0.374      -0.143\n",
      "bay_store_73     -0.4923      0.059     -8.372      0.000      -0.608      -0.377\n",
      "sto_store_73     -0.7683      0.072    -10.657      0.000      -0.910      -0.627\n",
      "tyl_store_74      0.9784      0.059     16.623      0.000       0.863       1.094\n",
      "adv_store_74     -0.0916      0.059     -1.557      0.120      -0.207       0.024\n",
      "bay_store_74     -0.3137      0.059     -5.334      0.000      -0.429      -0.198\n",
      "sto_store_74     -0.5156      0.072     -7.152      0.000      -0.657      -0.374\n",
      "tyl_store_75      0.6845      0.059     11.629      0.000       0.569       0.800\n",
      "adv_store_75     -0.2587      0.059     -4.395      0.000      -0.374      -0.143\n",
      "bay_store_75     -0.7256      0.059    -12.340      0.000      -0.841      -0.610\n",
      "sto_store_75     -1.0295      0.072    -14.281      0.000      -1.171      -0.888\n",
      "tyl_store_76      0.5300      0.059      9.005      0.000       0.415       0.645\n",
      "adv_store_76     -0.4008      0.059     -6.810      0.000      -0.516      -0.285\n",
      "bay_store_76     -0.6694      0.059    -11.383      0.000      -0.785      -0.554\n",
      "sto_store_76     -0.6513      0.072     -9.035      0.000      -0.793      -0.510\n",
      "tyl_store_77      0.8981      0.059     15.259      0.000       0.783       1.013\n",
      "adv_store_77      0.2732      0.059      4.642      0.000       0.158       0.389\n",
      "bay_store_77     -0.5825      0.059     -9.906      0.000      -0.698      -0.467\n",
      "sto_store_77     -0.3596      0.072     -4.987      0.000      -0.501      -0.218\n",
      "tyl_store_78      0.7471      0.059     12.696      0.000       0.632       0.862\n",
      "adv_store_78     -0.1125      0.059     -1.911      0.056      -0.228       0.003\n",
      "bay_store_78     -0.7529      0.059    -12.802      0.000      -0.868      -0.638\n",
      "sto_store_78     -0.4040      0.072     -5.603      0.000      -0.545      -0.263\n",
      "tyl_store_80      0.9840      0.059     16.718      0.000       0.869       1.099\n",
      "adv_store_80      0.2434      0.059      4.135      0.000       0.128       0.359\n",
      "bay_store_80     -0.5569      0.059     -9.470      0.000      -0.672      -0.442\n",
      "sto_store_80     -0.1789      0.072     -2.481      0.013      -0.320      -0.038\n",
      "tyl_store_81      0.7406      0.059     12.584      0.000       0.625       0.856\n",
      "adv_store_81     -0.1944      0.059     -3.303      0.001      -0.310      -0.079\n",
      "bay_store_81     -0.6620      0.059    -11.258      0.000      -0.777      -0.547\n",
      "sto_store_81     -0.6853      0.072     -9.505      0.000      -0.827      -0.544\n",
      "tyl_store_83      0.8745      0.059     14.858      0.000       0.759       0.990\n",
      "adv_store_83     -0.0520      0.059     -0.883      0.377      -0.167       0.063\n",
      "bay_store_83     -0.5318      0.059     -9.044      0.000      -0.647      -0.417\n",
      "sto_store_83     -0.4397      0.072     -6.099      0.000      -0.581      -0.298\n",
      "tyl_store_84      1.0863      0.059     18.456      0.000       0.971       1.202\n",
      "adv_store_84      0.1342      0.059      2.280      0.023       0.019       0.250\n",
      "bay_store_84     -0.3980      0.059     -6.767      0.000      -0.513      -0.283\n",
      "sto_store_84     -0.3497      0.072     -4.851      0.000      -0.491      -0.208\n",
      "tyl_store_86      0.7393      0.059     12.562      0.000       0.624       0.855\n",
      "adv_store_86     -0.0419      0.059     -0.712      0.476      -0.157       0.073\n",
      "bay_store_86     -0.5896      0.059    -10.026      0.000      -0.705      -0.474\n",
      "sto_store_86     -0.2979      0.072     -4.133      0.000      -0.439      -0.157\n",
      "tyl_store_89      0.1499      0.059      2.547      0.011       0.035       0.265\n",
      "adv_store_89     -0.6467      0.059    -10.986      0.000      -0.762      -0.531\n",
      "bay_store_89     -0.9034      0.059    -15.363      0.000      -1.019      -0.788\n",
      "sto_store_89     -0.8417      0.072    -11.674      0.000      -0.983      -0.700\n",
      "tyl_store_90      0.6259      0.059     10.634      0.000       0.511       0.741\n",
      "adv_store_90     -0.5343      0.059     -9.077      0.000      -0.650      -0.419\n",
      "bay_store_90     -0.8229      0.059    -13.994      0.000      -0.938      -0.708\n",
      "sto_store_90     -0.9011      0.072    -12.499      0.000      -1.042      -0.760\n",
      "tyl_store_91      0.7854      0.059     13.346      0.000       0.670       0.901\n",
      "adv_store_91     -0.2073      0.059     -3.523      0.000      -0.323      -0.092\n",
      "bay_store_91     -0.6261      0.059    -10.648      0.000      -0.741      -0.511\n",
      "sto_store_91     -0.5885      0.072     -8.163      0.000      -0.730      -0.447\n",
      "tyl_store_92      0.7730      0.059     13.133      0.000       0.658       0.888\n",
      "adv_store_92     -0.3257      0.059     -5.533      0.000      -0.441      -0.210\n",
      "bay_store_92     -0.7733      0.059    -13.151      0.000      -0.889      -0.658\n",
      "sto_store_92     -0.4610      0.072     -6.395      0.000      -0.602      -0.320\n",
      "tyl_store_93      0.7516      0.059     12.772      0.000       0.636       0.867\n",
      "adv_store_93      0.1129      0.059      1.919      0.055      -0.002       0.228\n",
      "bay_store_93     -0.5915      0.059    -10.058      0.000      -0.707      -0.476\n",
      "sto_store_93     -0.4543      0.072     -6.302      0.000      -0.596      -0.313\n",
      "tyl_store_94      0.9778      0.059     16.613      0.000       0.862       1.093\n",
      "adv_store_94      0.1638      0.059      2.783      0.005       0.048       0.279\n",
      "bay_store_94     -0.5227      0.059     -8.889      0.000      -0.638      -0.407\n",
      "sto_store_94     -0.1041      0.072     -1.444      0.149      -0.245       0.037\n",
      "tyl_store_95      0.5620      0.059      9.549      0.000       0.447       0.677\n",
      "adv_store_95     -0.1944      0.059     -3.303      0.001      -0.310      -0.079\n",
      "bay_store_95     -0.4480      0.059     -7.618      0.000      -0.563      -0.333\n",
      "sto_store_95     -0.8664      0.072    -12.018      0.000      -1.008      -0.725\n",
      "tyl_store_97      0.9324      0.059     15.842      0.000       0.817       1.048\n",
      "adv_store_97      0.2126      0.059      3.612      0.000       0.097       0.328\n",
      "bay_store_97     -0.6569      0.059    -11.172      0.000      -0.772      -0.542\n",
      "sto_store_97     -0.3189      0.072     -4.423      0.000      -0.460      -0.178\n",
      "tyl_store_98      1.2157      0.059     20.653      0.000       1.100       1.331\n",
      "adv_store_98      0.0661      0.059      1.123      0.261      -0.049       0.181\n",
      "bay_store_98     -0.3192      0.059     -5.427      0.000      -0.434      -0.204\n",
      "sto_store_98     -0.0235      0.072     -0.326      0.744      -0.165       0.118\n",
      "tyl_store_100     1.0015      0.059     17.014      0.000       0.886       1.117\n",
      "adv_store_100    -0.0777      0.059     -1.319      0.187      -0.193       0.038\n",
      "bay_store_100    -0.7006      0.059    -11.914      0.000      -0.816      -0.585\n",
      "sto_store_100    -0.4337      0.072     -6.015      0.000      -0.575      -0.292\n",
      "tyl_store_101     1.1341      0.059     19.267      0.000       1.019       1.249\n",
      "adv_store_101     0.3506      0.059      5.956      0.000       0.235       0.466\n",
      "bay_store_101    -0.3177      0.059     -5.402      0.000      -0.433      -0.202\n",
      "sto_store_101    -0.0300      0.072     -0.417      0.677      -0.171       0.111\n",
      "tyl_store_102     1.1046      0.059     18.766      0.000       0.989       1.220\n",
      "adv_store_102    -0.0272      0.059     -0.462      0.644      -0.143       0.088\n",
      "bay_store_102    -0.3543      0.059     -6.025      0.000      -0.470      -0.239\n",
      "sto_store_102     0.0106      0.072      0.147      0.883      -0.131       0.152\n",
      "tyl_store_103     1.0513      0.059     17.861      0.000       0.936       1.167\n",
      "adv_store_103    -0.0171      0.059     -0.290      0.772      -0.132       0.098\n",
      "bay_store_103    -0.9536      0.059    -16.216      0.000      -1.069      -0.838\n",
      "sto_store_103     0.3761      0.072      5.217      0.000       0.235       0.517\n",
      "tyl_store_104     1.1897      0.059     20.214      0.000       1.074       1.305\n",
      "adv_store_104     0.6845      0.059     11.629      0.000       0.569       0.800\n",
      "bay_store_104    -0.3368      0.059     -5.727      0.000      -0.452      -0.222\n",
      "sto_store_104     0.1873      0.072      2.597      0.009       0.046       0.329\n",
      "tyl_store_105     1.1708      0.059     19.892      0.000       1.055       1.286\n",
      "adv_store_105     0.1303      0.059      2.214      0.027       0.015       0.246\n",
      "bay_store_105    -0.4360      0.059     -7.414      0.000      -0.551      -0.321\n",
      "sto_store_105     0.0456      0.072      0.632      0.527      -0.096       0.187\n",
      "tyl_store_106     0.8816      0.059     14.978      0.000       0.766       0.997\n",
      "adv_store_106     0.2707      0.059      4.599      0.000       0.155       0.386\n",
      "bay_store_106    -0.5706      0.059     -9.703      0.000      -0.686      -0.455\n",
      "sto_store_106     0.0843      0.072      1.170      0.242      -0.057       0.226\n",
      "tyl_store_107     0.9642      0.059     16.382      0.000       0.849       1.080\n",
      "adv_store_107     0.0711      0.059      1.208      0.227      -0.044       0.186\n",
      "bay_store_107    -0.4353      0.059     -7.402      0.000      -0.551      -0.320\n",
      "sto_store_107    -0.4495      0.072     -6.235      0.000      -0.591      -0.308\n",
      "tyl_store_109     1.0719      0.059     18.214      0.000       0.957       1.187\n",
      "adv_store_109     0.4983      0.059      8.467      0.000       0.383       0.614\n",
      "bay_store_109    -0.4686      0.059     -7.969      0.000      -0.584      -0.353\n",
      "sto_store_109    -0.4945      0.072     -6.859      0.000      -0.636      -0.353\n",
      "tyl_store_110     1.0626      0.059     18.055      0.000       0.947       1.178\n",
      "adv_store_110     0.2920      0.059      4.962      0.000       0.177       0.407\n",
      "bay_store_110    -0.4647      0.059     -7.902      0.000      -0.580      -0.349\n",
      "sto_store_110     0.0422      0.072      0.585      0.558      -0.099       0.184\n",
      "tyl_store_111     0.3395      0.059      5.769      0.000       0.224       0.455\n",
      "adv_store_111    -1.0512      0.059    -17.859      0.000      -1.167      -0.936\n",
      "bay_store_111    -0.8465      0.059    -14.395      0.000      -0.962      -0.731\n",
      "sto_store_111    -1.5100      0.072    -20.944      0.000      -1.651      -1.369\n",
      "tyl_store_112     1.3039      0.059     22.153      0.000       1.189       1.419\n",
      "adv_store_112     0.6356      0.059     10.798      0.000       0.520       0.751\n",
      "bay_store_112    -0.5770      0.059     -9.813      0.000      -0.692      -0.462\n",
      "sto_store_112     0.0137      0.072      0.190      0.849      -0.128       0.155\n",
      "tyl_store_113     0.6387      0.059     10.854      0.000       0.523       0.754\n",
      "adv_store_113    -0.0978      0.059     -1.662      0.097      -0.213       0.018\n",
      "bay_store_113    -0.5840      0.059     -9.930      0.000      -0.699      -0.469\n",
      "sto_store_113    -0.7779      0.072    -10.790      0.000      -0.919      -0.637\n",
      "tyl_store_114     1.0044      0.059     17.064      0.000       0.889       1.120\n",
      "adv_store_114    -0.1508      0.059     -2.561      0.010      -0.266      -0.035\n",
      "bay_store_114    -0.3732      0.059     -6.346      0.000      -0.488      -0.258\n",
      "sto_store_114    -0.3695      0.072     -5.125      0.000      -0.511      -0.228\n",
      "tyl_store_115     1.2946      0.059     21.995      0.000       1.179       1.410\n",
      "adv_store_115     0.6225      0.059     10.577      0.000       0.507       0.738\n",
      "bay_store_115    -0.5810      0.059     -9.880      0.000      -0.696      -0.466\n",
      "sto_store_115     0.2716      0.072      3.767      0.000       0.130       0.413\n",
      "tyl_store_116     0.9033      0.059     15.349      0.000       0.788       1.019\n",
      "adv_store_116     0.1867      0.059      3.171      0.002       0.071       0.302\n",
      "bay_store_116    -0.5403      0.059     -9.189      0.000      -0.656      -0.425\n",
      "sto_store_116    -0.1014      0.072     -1.406      0.160      -0.243       0.040\n",
      "tyl_store_117     0.8626      0.059     14.657      0.000       0.747       0.978\n",
      "adv_store_117     0.0465      0.059      0.791      0.429      -0.069       0.162\n",
      "bay_store_117    -0.7069      0.059    -12.022      0.000      -0.822      -0.592\n",
      "sto_store_117    -0.5447      0.072     -7.555      0.000      -0.686      -0.403\n",
      "tyl_store_118     0.7044      0.059     11.968      0.000       0.589       0.820\n",
      "adv_store_118    -0.0917      0.059     -1.558      0.119      -0.207       0.024\n",
      "bay_store_118    -0.7385      0.059    -12.559      0.000      -0.854      -0.623\n",
      "sto_store_118    -0.7522      0.072    -10.434      0.000      -0.894      -0.611\n",
      "tyl_store_119     0.6844      0.059     11.630      0.000       0.569       0.800\n",
      "adv_store_119     0.0356      0.059      0.606      0.545      -0.080       0.151\n",
      "bay_store_119    -0.7841      0.059    -13.335      0.000      -0.899      -0.669\n",
      "sto_store_119    -0.4181      0.072     -5.800      0.000      -0.559      -0.277\n",
      "tyl_store_121     1.1028      0.059     18.736      0.000       0.987       1.218\n",
      "adv_store_121     0.3880      0.059      6.592      0.000       0.273       0.503\n",
      "bay_store_121    -0.2423      0.059     -4.120      0.000      -0.358      -0.127\n",
      "sto_store_121     0.0235      0.072      0.327      0.744      -0.118       0.165\n",
      "tyl_store_122     1.2499      0.059     21.234      0.000       1.135       1.365\n",
      "adv_store_122     0.4134      0.059      7.023      0.000       0.298       0.529\n",
      "bay_store_122    -0.5829      0.059     -9.912      0.000      -0.698      -0.468\n",
      "sto_store_122     0.0931      0.072      1.291      0.197      -0.048       0.234\n",
      "tyl_store_123     0.9212      0.059     15.652      0.000       0.806       1.037\n",
      "adv_store_123    -0.0391      0.059     -0.665      0.506      -0.154       0.076\n",
      "bay_store_123    -0.7221      0.059    -12.279      0.000      -0.837      -0.607\n",
      "sto_store_123    -0.2734      0.072     -3.793      0.000      -0.415      -0.132\n",
      "price_hat        -0.1535      0.003    -57.542      0.000      -0.159      -0.148\n",
      "==============================================================================\n",
      "Omnibus:                     1827.956   Durbin-Watson:                   0.919\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2116.251\n",
      "Skew:                          -0.544   Prob(JB):                         0.00\n",
      "Kurtosis:                       3.368   Cond. No.                     1.55e+16\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 3.69e-27. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n",
      "-57.541554716524786\n",
      "                      0         1\n",
      "const         -7.385453 -7.338971\n",
      "prom_          0.477792  0.528414\n",
      "tyl_store_2    0.669237  0.899957\n",
      "adv_store_2   -0.029284  0.201454\n",
      "bay_store_2   -0.386932 -0.156405\n",
      "...                 ...       ...\n",
      "tyl_store_123  0.805812  1.036526\n",
      "adv_store_123 -0.154494  0.076234\n",
      "bay_store_123 -0.837400 -0.606866\n",
      "sto_store_123 -0.414745 -0.132144\n",
      "price_hat     -0.158776 -0.148316\n",
      "\n",
      "[295 rows x 2 columns]\n",
      "Price coefficient: -0.1535461351128077\n"
     ]
    }
   ],
   "source": [
    "##################################### IV with Fixed Effects #####################################\n",
    "\n",
    "# Define the independent variables and the instrument\n",
    "X_fixed_effects = df1[['prom_'] + [col for col in df1.columns if '_store' in col]]\n",
    "X_fixed_effects = sm.add_constant(X_fixed_effects)\n",
    "instrument = df1['cost_']\n",
    "\n",
    "# First stage: regress price_ on the instrument and other exogenous variables\n",
    "first_stage = sm.OLS(df1['price_'], sm.add_constant(instrument)).fit()\n",
    "df1['price_hat'] = first_stage.fittedvalues\n",
    "\n",
    "# Second stage: regress Y on the predicted values of price_ and other exogenous variables\n",
    "X_fixed_effects['price_hat'] = df1['price_hat']\n",
    "model_iv_fixed_effects = sm.OLS(Y, X_fixed_effects).fit()\n",
    "\n",
    "# Print the regression results\n",
    "print(model_iv_fixed_effects.summary())\n",
    "\n",
    "\n",
    "#print t statistic (-57.541554716524786) \n",
    "print(model_iv_fixed_effects.tvalues['price_hat'])\n",
    "#print confidence interval (-0.158776 -0.148316) for \"price_\" coefficient\n",
    "print(model_iv_fixed_effects.conf_int(alpha=0.05, cols=None))\n",
    "\n",
    "# Print the coefficient for price\n",
    "print(f\"Price coefficient: {model_iv_fixed_effects.params['price_hat']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **QUESTION 2.E**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store</th>\n",
       "      <th>week</th>\n",
       "      <th>brand</th>\n",
       "      <th>sales_</th>\n",
       "      <th>count</th>\n",
       "      <th>price_</th>\n",
       "      <th>prom_</th>\n",
       "      <th>cost_</th>\n",
       "      <th>sales_per_count</th>\n",
       "      <th>share_0</th>\n",
       "      <th>...</th>\n",
       "      <th>tyl_store_122</th>\n",
       "      <th>adv_store_122</th>\n",
       "      <th>bay_store_122</th>\n",
       "      <th>sto_store_122</th>\n",
       "      <th>tyl_store_123</th>\n",
       "      <th>adv_store_123</th>\n",
       "      <th>bay_store_123</th>\n",
       "      <th>sto_store_123</th>\n",
       "      <th>price_hat</th>\n",
       "      <th>Hausman</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>14181</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.06</td>\n",
       "      <td>0.001128</td>\n",
       "      <td>0.993724</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.270719</td>\n",
       "      <td>4.261043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>13965</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.04</td>\n",
       "      <td>0.000859</td>\n",
       "      <td>0.993913</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.249346</td>\n",
       "      <td>4.261043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>13538</td>\n",
       "      <td>3.37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>0.995199</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.366900</td>\n",
       "      <td>4.261043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>13735</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.07</td>\n",
       "      <td>0.000874</td>\n",
       "      <td>0.993957</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.281406</td>\n",
       "      <td>4.261043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>13735</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.12</td>\n",
       "      <td>0.000728</td>\n",
       "      <td>0.995268</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.334840</td>\n",
       "      <td>4.261043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38534</th>\n",
       "      <td>123</td>\n",
       "      <td>39</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>26033</td>\n",
       "      <td>3.53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.43</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>0.995198</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.597458</td>\n",
       "      <td>4.262648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38535</th>\n",
       "      <td>123</td>\n",
       "      <td>40</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>25488</td>\n",
       "      <td>3.72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.57</td>\n",
       "      <td>0.000353</td>\n",
       "      <td>0.994703</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.747071</td>\n",
       "      <td>4.262648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38536</th>\n",
       "      <td>123</td>\n",
       "      <td>41</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>25488</td>\n",
       "      <td>3.72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.57</td>\n",
       "      <td>0.000353</td>\n",
       "      <td>0.994703</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.747071</td>\n",
       "      <td>4.262648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38537</th>\n",
       "      <td>123</td>\n",
       "      <td>42</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>25454</td>\n",
       "      <td>3.77</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.60</td>\n",
       "      <td>0.000354</td>\n",
       "      <td>0.995168</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.779131</td>\n",
       "      <td>4.262648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38538</th>\n",
       "      <td>123</td>\n",
       "      <td>43</td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "      <td>30874</td>\n",
       "      <td>4.41</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.000713</td>\n",
       "      <td>0.995530</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.260033</td>\n",
       "      <td>4.262648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38539 rows  309 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       store  week  brand  sales_  count  price_  prom_  cost_  \\\n",
       "0          2     1      1      16  14181    3.29    0.0   2.06   \n",
       "1          2     2      1      12  13965    3.27    0.0   2.04   \n",
       "2          2     3      1       6  13538    3.37    0.0   2.15   \n",
       "3          2     4      1      12  13735    3.30    0.0   2.07   \n",
       "4          2     5      1      10  13735    3.34    0.0   2.12   \n",
       "...      ...   ...    ...     ...    ...     ...    ...    ...   \n",
       "38534    123    39     11      14  26033    3.53    0.0   1.43   \n",
       "38535    123    40     11       9  25488    3.72    0.0   1.57   \n",
       "38536    123    41     11       9  25488    3.72    0.0   1.57   \n",
       "38537    123    42     11       9  25454    3.77    0.0   1.60   \n",
       "38538    123    43     11      22  30874    4.41    0.0   2.05   \n",
       "\n",
       "       sales_per_count   share_0  ...  tyl_store_122  adv_store_122  \\\n",
       "0             0.001128  0.993724  ...              0              0   \n",
       "1             0.000859  0.993913  ...              0              0   \n",
       "2             0.000443  0.995199  ...              0              0   \n",
       "3             0.000874  0.993957  ...              0              0   \n",
       "4             0.000728  0.995268  ...              0              0   \n",
       "...                ...       ...  ...            ...            ...   \n",
       "38534         0.000538  0.995198  ...              0              0   \n",
       "38535         0.000353  0.994703  ...              0              0   \n",
       "38536         0.000353  0.994703  ...              0              0   \n",
       "38537         0.000354  0.995168  ...              0              0   \n",
       "38538         0.000713  0.995530  ...              0              0   \n",
       "\n",
       "       bay_store_122  sto_store_122  tyl_store_123  adv_store_123  \\\n",
       "0                  0              0              0              0   \n",
       "1                  0              0              0              0   \n",
       "2                  0              0              0              0   \n",
       "3                  0              0              0              0   \n",
       "4                  0              0              0              0   \n",
       "...              ...            ...            ...            ...   \n",
       "38534              0              0              0              0   \n",
       "38535              0              0              0              0   \n",
       "38536              0              0              0              0   \n",
       "38537              0              0              0              0   \n",
       "38538              0              0              0              0   \n",
       "\n",
       "       bay_store_123  sto_store_123  price_hat   Hausman  \n",
       "0                  0              0   3.270719  4.261043  \n",
       "1                  0              0   3.249346  4.261043  \n",
       "2                  0              0   3.366900  4.261043  \n",
       "3                  0              0   3.281406  4.261043  \n",
       "4                  0              0   3.334840  4.261043  \n",
       "...              ...            ...        ...       ...  \n",
       "38534              0              1   2.597458  4.262648  \n",
       "38535              0              1   2.747071  4.262648  \n",
       "38536              0              1   2.747071  4.262648  \n",
       "38537              0              1   2.779131  4.262648  \n",
       "38538              0              1   3.260033  4.262648  \n",
       "\n",
       "[38539 rows x 309 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################################################# Generate Hausman Variable #################################################\n",
    "# Initialize the Hausman variable\n",
    "df1['Hausman'] = np.nan\n",
    "\n",
    "# Loop through each store\n",
    "for store in df1['store'].unique():\n",
    "    # Filter out the current store\n",
    "    other_stores = df1[df1['store'] != store]\n",
    "    \n",
    "    # Calculate the weighted average price in other stores\n",
    "    weighted_avg_price_other_stores = (other_stores['sales_'] * other_stores['price_']).sum() / other_stores['sales_'].sum()\n",
    "    \n",
    "    # Assign the calculated value to the Hausman variable for the current store\n",
    "    df1.loc[df1['store'] == store, 'Hausman'] = weighted_avg_price_other_stores\n",
    "\n",
    "# Display the first few rows to verify\n",
    "df1.head(-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   R-squared:                       0.008\n",
      "Model:                            OLS   Adj. R-squared:                  0.008\n",
      "Method:                 Least Squares   F-statistic:                     147.2\n",
      "Date:                Fri, 07 Feb 2025   Prob (F-statistic):           1.98e-64\n",
      "Time:                        04:41:42   Log-Likelihood:                -50877.\n",
      "No. Observations:               38544   AIC:                         1.018e+05\n",
      "Df Residuals:                   38541   BIC:                         1.018e+05\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=====================================================================================\n",
      "                        coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------\n",
      "const               -13.4716      0.637    -21.142      0.000     -14.721     -12.223\n",
      "prom_                 0.2418      0.016     14.839      0.000       0.210       0.274\n",
      "price_hat_hausman     1.2481      0.145      8.595      0.000       0.963       1.533\n",
      "==============================================================================\n",
      "Omnibus:                     2348.508   Durbin-Watson:                   0.556\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2382.187\n",
      "Skew:                          -0.566   Prob(JB):                         0.00\n",
      "Kurtosis:                       2.550   Cond. No.                         638.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3187/3992901645.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1['price_hat_hausman'] = first_stage_hausman.fittedvalues\n"
     ]
    }
   ],
   "source": [
    "# First stage: regress price_ on the instrument Hausman\n",
    "first_stage_hausman = sm.OLS(df1['price_'], sm.add_constant(df1['Hausman'])).fit()\n",
    "df1['price_hat_hausman'] = first_stage_hausman.fittedvalues\n",
    "\n",
    "# Second stage: regress Y on the predicted values of price_ and prom_\n",
    "X_hausman = df1[['prom_']]\n",
    "X_hausman = sm.add_constant(X_hausman)\n",
    "X_hausman['price_hat_hausman'] = df1['price_hat_hausman']\n",
    "second_stage_hausman = sm.OLS(Y, X_hausman).fit()\n",
    "\n",
    "# Print the regression results\n",
    "print(second_stage_hausman.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   R-squared:                       0.272\n",
      "Model:                            OLS   Adj. R-squared:                  0.272\n",
      "Method:                 Least Squares   F-statistic:                     2887.\n",
      "Date:                Fri, 07 Feb 2025   Prob (F-statistic):               0.00\n",
      "Time:                        04:43:11   Log-Likelihood:                -44892.\n",
      "No. Observations:               38544   AIC:                         8.980e+04\n",
      "Df Residuals:                   38538   BIC:                         8.985e+04\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=====================================================================================\n",
      "                        coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------\n",
      "const               -10.7969      0.436    -24.736      0.000     -11.652      -9.941\n",
      "prom_                 0.4628      0.014     32.729      0.000       0.435       0.490\n",
      "price_hat_hausman     1.2449      0.124     10.013      0.000       1.001       1.489\n",
      "tyl                  -1.9575      0.109    -17.906      0.000      -2.172      -1.743\n",
      "adv                  -2.8074      0.109    -25.680      0.000      -3.022      -2.593\n",
      "bay                  -3.1920      0.109    -29.197      0.000      -3.406      -2.978\n",
      "sto                  -2.8400      0.109    -25.960      0.000      -3.054      -2.626\n",
      "==============================================================================\n",
      "Omnibus:                     1701.514   Durbin-Watson:                   0.761\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1935.484\n",
      "Skew:                          -0.547   Prob(JB):                         0.00\n",
      "Kurtosis:                       3.094   Cond. No.                     2.53e+15\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 1.23e-25. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "# Define the independent variables including the dummy variables\n",
    "X_dummies_hausman = df1[['prom_', 'price_hat_hausman', 'tyl', 'adv', 'bay', 'sto']]\n",
    "\n",
    "# Add a constant to the independent variables\n",
    "X_dummies_hausman = sm.add_constant(X_dummies_hausman)\n",
    "\n",
    "# Define the dependent variable\n",
    "Y = df1['Y']\n",
    "\n",
    "# Fit the regression model\n",
    "second_stage_dummies_hausman = sm.OLS(Y, X_dummies_hausman).fit()\n",
    "\n",
    "# Print the regression results\n",
    "print(second_stage_dummies_hausman.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   R-squared:                       0.349\n",
      "Model:                            OLS   Adj. R-squared:                  0.344\n",
      "Method:                 Least Squares   F-statistic:                     70.16\n",
      "Date:                Fri, 07 Feb 2025   Prob (F-statistic):               0.00\n",
      "Time:                        04:44:06   Log-Likelihood:                -42757.\n",
      "No. Observations:               38544   AIC:                         8.610e+04\n",
      "Df Residuals:                   38251   BIC:                         8.861e+04\n",
      "Df Model:                         292                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=====================================================================================\n",
      "                        coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------\n",
      "const             -1.118e+11    6.8e+11     -0.164      0.870   -1.45e+12    1.22e+12\n",
      "prom_                 0.4611      0.013     34.294      0.000       0.435       0.488\n",
      "tyl_store_2       -8.135e+08   4.95e+09     -0.164      0.870   -1.05e+10    8.89e+09\n",
      "adv_store_2       -8.135e+08   4.95e+09     -0.164      0.870   -1.05e+10    8.89e+09\n",
      "bay_store_2       -8.135e+08   4.95e+09     -0.164      0.870   -1.05e+10    8.89e+09\n",
      "sto_store_2       -8.135e+08   4.95e+09     -0.164      0.870   -1.05e+10    8.89e+09\n",
      "tyl_store_5       -8.014e+08   4.88e+09     -0.164      0.870   -1.04e+10    8.76e+09\n",
      "adv_store_5       -8.014e+08   4.88e+09     -0.164      0.870   -1.04e+10    8.76e+09\n",
      "bay_store_5       -8.014e+08   4.88e+09     -0.164      0.870   -1.04e+10    8.76e+09\n",
      "sto_store_5       -8.014e+08   4.88e+09     -0.164      0.870   -1.04e+10    8.76e+09\n",
      "tyl_store_8         6.02e+08   3.66e+09      0.164      0.870   -6.58e+09    7.78e+09\n",
      "adv_store_8         6.02e+08   3.66e+09      0.164      0.870   -6.58e+09    7.78e+09\n",
      "bay_store_8         6.02e+08   3.66e+09      0.164      0.870   -6.58e+09    7.78e+09\n",
      "sto_store_8         6.02e+08   3.66e+09      0.164      0.870   -6.58e+09    7.78e+09\n",
      "tyl_store_9       -3.534e+08   2.15e+09     -0.164      0.870   -4.57e+09    3.86e+09\n",
      "adv_store_9       -3.534e+08   2.15e+09     -0.164      0.870   -4.57e+09    3.86e+09\n",
      "bay_store_9       -3.534e+08   2.15e+09     -0.164      0.870   -4.57e+09    3.86e+09\n",
      "sto_store_9       -3.534e+08   2.15e+09     -0.164      0.870   -4.57e+09    3.86e+09\n",
      "tyl_store_12      -9.731e+06   5.92e+07     -0.164      0.870   -1.26e+08    1.06e+08\n",
      "adv_store_12      -9.731e+06   5.92e+07     -0.164      0.870   -1.26e+08    1.06e+08\n",
      "bay_store_12      -9.731e+06   5.92e+07     -0.164      0.870   -1.26e+08    1.06e+08\n",
      "sto_store_12      -9.731e+06   5.92e+07     -0.164      0.870   -1.26e+08    1.06e+08\n",
      "tyl_store_14      -1.354e+09   8.24e+09     -0.164      0.870   -1.75e+10    1.48e+10\n",
      "adv_store_14      -1.354e+09   8.24e+09     -0.164      0.870   -1.75e+10    1.48e+10\n",
      "bay_store_14      -1.354e+09   8.24e+09     -0.164      0.870   -1.75e+10    1.48e+10\n",
      "sto_store_14      -1.354e+09   8.24e+09     -0.164      0.870   -1.75e+10    1.48e+10\n",
      "tyl_store_18      -3.554e+08   2.16e+09     -0.164      0.870   -4.59e+09    3.88e+09\n",
      "adv_store_18      -3.554e+08   2.16e+09     -0.164      0.870   -4.59e+09    3.88e+09\n",
      "bay_store_18      -3.554e+08   2.16e+09     -0.164      0.870   -4.59e+09    3.88e+09\n",
      "sto_store_18      -3.554e+08   2.16e+09     -0.164      0.870   -4.59e+09    3.88e+09\n",
      "tyl_store_21       7.726e+08    4.7e+09      0.164      0.870   -8.44e+09    9.99e+09\n",
      "adv_store_21       7.726e+08    4.7e+09      0.164      0.870   -8.44e+09    9.99e+09\n",
      "bay_store_21       7.726e+08    4.7e+09      0.164      0.870   -8.44e+09    9.99e+09\n",
      "sto_store_21       7.726e+08    4.7e+09      0.164      0.870   -8.44e+09    9.99e+09\n",
      "tyl_store_28      -3.772e+08    2.3e+09     -0.164      0.870   -4.88e+09    4.12e+09\n",
      "adv_store_28      -3.772e+08    2.3e+09     -0.164      0.870   -4.88e+09    4.12e+09\n",
      "bay_store_28      -3.772e+08    2.3e+09     -0.164      0.870   -4.88e+09    4.12e+09\n",
      "sto_store_28      -3.772e+08    2.3e+09     -0.164      0.870   -4.88e+09    4.12e+09\n",
      "tyl_store_32      -8.572e+08   5.22e+09     -0.164      0.870   -1.11e+10    9.37e+09\n",
      "adv_store_32      -8.572e+08   5.22e+09     -0.164      0.870   -1.11e+10    9.37e+09\n",
      "bay_store_32      -8.572e+08   5.22e+09     -0.164      0.870   -1.11e+10    9.37e+09\n",
      "sto_store_32      -8.572e+08   5.22e+09     -0.164      0.870   -1.11e+10    9.37e+09\n",
      "tyl_store_33       2.968e+08   1.81e+09      0.164      0.870   -3.24e+09    3.84e+09\n",
      "adv_store_33       2.968e+08   1.81e+09      0.164      0.870   -3.24e+09    3.84e+09\n",
      "bay_store_33       2.968e+08   1.81e+09      0.164      0.870   -3.24e+09    3.84e+09\n",
      "sto_store_33       2.968e+08   1.81e+09      0.164      0.870   -3.24e+09    3.84e+09\n",
      "tyl_store_40       8.946e+08   5.45e+09      0.164      0.870   -9.78e+09    1.16e+10\n",
      "adv_store_40       8.946e+08   5.45e+09      0.164      0.870   -9.78e+09    1.16e+10\n",
      "bay_store_40       8.946e+08   5.45e+09      0.164      0.870   -9.78e+09    1.16e+10\n",
      "sto_store_40       8.946e+08   5.45e+09      0.164      0.870   -9.78e+09    1.16e+10\n",
      "tyl_store_44      -7.068e+08    4.3e+09     -0.164      0.870   -9.14e+09    7.73e+09\n",
      "adv_store_44      -7.068e+08    4.3e+09     -0.164      0.870   -9.14e+09    7.73e+09\n",
      "bay_store_44      -7.068e+08    4.3e+09     -0.164      0.870   -9.14e+09    7.73e+09\n",
      "sto_store_44      -7.068e+08    4.3e+09     -0.164      0.870   -9.14e+09    7.73e+09\n",
      "tyl_store_45       2.046e+08   1.25e+09      0.164      0.870   -2.24e+09    2.65e+09\n",
      "adv_store_45       2.046e+08   1.25e+09      0.164      0.870   -2.24e+09    2.65e+09\n",
      "bay_store_45       2.046e+08   1.25e+09      0.164      0.870   -2.24e+09    2.65e+09\n",
      "sto_store_45       2.046e+08   1.25e+09      0.164      0.870   -2.24e+09    2.65e+09\n",
      "tyl_store_47       1.593e+08    9.7e+08      0.164      0.870   -1.74e+09    2.06e+09\n",
      "adv_store_47       1.593e+08    9.7e+08      0.164      0.870   -1.74e+09    2.06e+09\n",
      "bay_store_47       1.593e+08    9.7e+08      0.164      0.870   -1.74e+09    2.06e+09\n",
      "sto_store_47       1.593e+08    9.7e+08      0.164      0.870   -1.74e+09    2.06e+09\n",
      "tyl_store_48      -1.336e+08   8.13e+08     -0.164      0.870   -1.73e+09    1.46e+09\n",
      "adv_store_48      -1.336e+08   8.13e+08     -0.164      0.870   -1.73e+09    1.46e+09\n",
      "bay_store_48      -1.336e+08   8.13e+08     -0.164      0.870   -1.73e+09    1.46e+09\n",
      "sto_store_48      -1.336e+08   8.13e+08     -0.164      0.870   -1.73e+09    1.46e+09\n",
      "tyl_store_49       -6.44e+07   3.92e+08     -0.164      0.870   -8.33e+08    7.04e+08\n",
      "adv_store_49       -6.44e+07   3.92e+08     -0.164      0.870   -8.33e+08    7.04e+08\n",
      "bay_store_49       -6.44e+07   3.92e+08     -0.164      0.870   -8.33e+08    7.04e+08\n",
      "sto_store_49       -6.44e+07   3.92e+08     -0.164      0.870   -8.33e+08    7.04e+08\n",
      "tyl_store_50        1.66e+08   1.01e+09      0.164      0.870   -1.81e+09    2.15e+09\n",
      "adv_store_50        1.66e+08   1.01e+09      0.164      0.870   -1.81e+09    2.15e+09\n",
      "bay_store_50        1.66e+08   1.01e+09      0.164      0.870   -1.81e+09    2.15e+09\n",
      "sto_store_50        1.66e+08   1.01e+09      0.164      0.870   -1.81e+09    2.15e+09\n",
      "tyl_store_51      -7.513e+07   4.57e+08     -0.164      0.870   -9.71e+08    8.21e+08\n",
      "adv_store_51      -7.513e+07   4.57e+08     -0.164      0.870   -9.71e+08    8.21e+08\n",
      "bay_store_51      -7.513e+07   4.57e+08     -0.164      0.870   -9.71e+08    8.21e+08\n",
      "sto_store_51      -7.513e+07   4.57e+08     -0.164      0.870   -9.71e+08    8.21e+08\n",
      "tyl_store_52      -2.041e+09   1.24e+10     -0.164      0.870   -2.64e+10    2.23e+10\n",
      "adv_store_52      -2.041e+09   1.24e+10     -0.164      0.870   -2.64e+10    2.23e+10\n",
      "bay_store_52      -2.041e+09   1.24e+10     -0.164      0.870   -2.64e+10    2.23e+10\n",
      "sto_store_52      -2.041e+09   1.24e+10     -0.164      0.870   -2.64e+10    2.23e+10\n",
      "tyl_store_53      -6.874e+08   4.18e+09     -0.164      0.870   -8.89e+09    7.51e+09\n",
      "adv_store_53      -6.874e+08   4.18e+09     -0.164      0.870   -8.89e+09    7.51e+09\n",
      "bay_store_53      -6.874e+08   4.18e+09     -0.164      0.870   -8.89e+09    7.51e+09\n",
      "sto_store_53      -6.874e+08   4.18e+09     -0.164      0.870   -8.89e+09    7.51e+09\n",
      "tyl_store_54      -2.883e+08   1.75e+09     -0.164      0.870   -3.73e+09    3.15e+09\n",
      "adv_store_54      -2.883e+08   1.75e+09     -0.164      0.870   -3.73e+09    3.15e+09\n",
      "bay_store_54      -2.883e+08   1.75e+09     -0.164      0.870   -3.73e+09    3.15e+09\n",
      "sto_store_54      -2.883e+08   1.75e+09     -0.164      0.870   -3.73e+09    3.15e+09\n",
      "tyl_store_56      -7.671e+07   4.67e+08     -0.164      0.870   -9.92e+08    8.38e+08\n",
      "adv_store_56      -7.671e+07   4.67e+08     -0.164      0.870   -9.92e+08    8.38e+08\n",
      "bay_store_56      -7.671e+07   4.67e+08     -0.164      0.870   -9.92e+08    8.38e+08\n",
      "sto_store_56      -7.671e+07   4.67e+08     -0.164      0.870   -9.92e+08    8.38e+08\n",
      "tyl_store_59       4.003e+08   2.44e+09      0.164      0.870   -4.38e+09    5.18e+09\n",
      "adv_store_59       4.003e+08   2.44e+09      0.164      0.870   -4.38e+09    5.18e+09\n",
      "bay_store_59       4.003e+08   2.44e+09      0.164      0.870   -4.38e+09    5.18e+09\n",
      "sto_store_59       4.003e+08   2.44e+09      0.164      0.870   -4.38e+09    5.18e+09\n",
      "tyl_store_62      -1.976e+09    1.2e+10     -0.164      0.870   -2.56e+10    2.16e+10\n",
      "adv_store_62      -1.976e+09    1.2e+10     -0.164      0.870   -2.56e+10    2.16e+10\n",
      "bay_store_62      -1.976e+09    1.2e+10     -0.164      0.870   -2.56e+10    2.16e+10\n",
      "sto_store_62      -1.976e+09    1.2e+10     -0.164      0.870   -2.56e+10    2.16e+10\n",
      "tyl_store_64       3.465e+08   2.11e+09      0.164      0.870   -3.79e+09    4.48e+09\n",
      "adv_store_64       3.465e+08   2.11e+09      0.164      0.870   -3.79e+09    4.48e+09\n",
      "bay_store_64       3.465e+08   2.11e+09      0.164      0.870   -3.79e+09    4.48e+09\n",
      "sto_store_64       3.465e+08   2.11e+09      0.164      0.870   -3.79e+09    4.48e+09\n",
      "tyl_store_67      -4.446e+07   2.71e+08     -0.164      0.870   -5.75e+08    4.86e+08\n",
      "adv_store_67      -4.446e+07   2.71e+08     -0.164      0.870   -5.75e+08    4.86e+08\n",
      "bay_store_67      -4.446e+07   2.71e+08     -0.164      0.870   -5.75e+08    4.86e+08\n",
      "sto_store_67      -4.446e+07   2.71e+08     -0.164      0.870   -5.75e+08    4.86e+08\n",
      "tyl_store_68      -7.674e+07   4.67e+08     -0.164      0.870   -9.92e+08    8.39e+08\n",
      "adv_store_68      -7.674e+07   4.67e+08     -0.164      0.870   -9.92e+08    8.39e+08\n",
      "bay_store_68      -7.674e+07   4.67e+08     -0.164      0.870   -9.92e+08    8.39e+08\n",
      "sto_store_68      -7.674e+07   4.67e+08     -0.164      0.870   -9.92e+08    8.39e+08\n",
      "tyl_store_70       8.836e+08   5.38e+09      0.164      0.870   -9.66e+09    1.14e+10\n",
      "adv_store_70       8.836e+08   5.38e+09      0.164      0.870   -9.66e+09    1.14e+10\n",
      "bay_store_70       8.836e+08   5.38e+09      0.164      0.870   -9.66e+09    1.14e+10\n",
      "sto_store_70       8.836e+08   5.38e+09      0.164      0.870   -9.66e+09    1.14e+10\n",
      "tyl_store_71       1.774e+06   1.08e+07      0.164      0.870   -1.94e+07    2.29e+07\n",
      "adv_store_71       1.774e+06   1.08e+07      0.164      0.870   -1.94e+07    2.29e+07\n",
      "bay_store_71       1.774e+06   1.08e+07      0.164      0.870   -1.94e+07    2.29e+07\n",
      "sto_store_71       1.774e+06   1.08e+07      0.164      0.870   -1.94e+07    2.29e+07\n",
      "tyl_store_72      -8.388e+08   5.11e+09     -0.164      0.870   -1.08e+10    9.17e+09\n",
      "adv_store_72      -8.388e+08   5.11e+09     -0.164      0.870   -1.08e+10    9.17e+09\n",
      "bay_store_72      -8.388e+08   5.11e+09     -0.164      0.870   -1.08e+10    9.17e+09\n",
      "sto_store_72      -8.388e+08   5.11e+09     -0.164      0.870   -1.08e+10    9.17e+09\n",
      "tyl_store_73       4.319e+08   2.63e+09      0.164      0.870   -4.72e+09    5.58e+09\n",
      "adv_store_73       4.319e+08   2.63e+09      0.164      0.870   -4.72e+09    5.58e+09\n",
      "bay_store_73       4.319e+08   2.63e+09      0.164      0.870   -4.72e+09    5.58e+09\n",
      "sto_store_73       4.319e+08   2.63e+09      0.164      0.870   -4.72e+09    5.58e+09\n",
      "tyl_store_74      -6.269e+08   3.82e+09     -0.164      0.870   -8.11e+09    6.85e+09\n",
      "adv_store_74      -6.269e+08   3.82e+09     -0.164      0.870   -8.11e+09    6.85e+09\n",
      "bay_store_74      -6.269e+08   3.82e+09     -0.164      0.870   -8.11e+09    6.85e+09\n",
      "sto_store_74      -6.269e+08   3.82e+09     -0.164      0.870   -8.11e+09    6.85e+09\n",
      "tyl_store_75      -2.225e+08   1.35e+09     -0.164      0.870   -2.88e+09    2.43e+09\n",
      "adv_store_75      -2.225e+08   1.35e+09     -0.164      0.870   -2.88e+09    2.43e+09\n",
      "bay_store_75      -2.225e+08   1.35e+09     -0.164      0.870   -2.88e+09    2.43e+09\n",
      "sto_store_75      -2.225e+08   1.35e+09     -0.164      0.870   -2.88e+09    2.43e+09\n",
      "tyl_store_76       3.894e+08   2.37e+09      0.164      0.870   -4.26e+09    5.03e+09\n",
      "adv_store_76       3.894e+08   2.37e+09      0.164      0.870   -4.26e+09    5.03e+09\n",
      "bay_store_76       3.894e+08   2.37e+09      0.164      0.870   -4.26e+09    5.03e+09\n",
      "sto_store_76       3.894e+08   2.37e+09      0.164      0.870   -4.26e+09    5.03e+09\n",
      "tyl_store_77      -1.953e+08   1.19e+09     -0.164      0.870   -2.53e+09    2.13e+09\n",
      "adv_store_77      -1.953e+08   1.19e+09     -0.164      0.870   -2.53e+09    2.13e+09\n",
      "bay_store_77      -1.953e+08   1.19e+09     -0.164      0.870   -2.53e+09    2.13e+09\n",
      "sto_store_77      -1.953e+08   1.19e+09     -0.164      0.870   -2.53e+09    2.13e+09\n",
      "tyl_store_78       1.204e+08   7.33e+08      0.164      0.870   -1.32e+09    1.56e+09\n",
      "adv_store_78       1.204e+08   7.33e+08      0.164      0.870   -1.32e+09    1.56e+09\n",
      "bay_store_78       1.204e+08   7.33e+08      0.164      0.870   -1.32e+09    1.56e+09\n",
      "sto_store_78       1.204e+08   7.33e+08      0.164      0.870   -1.32e+09    1.56e+09\n",
      "tyl_store_80      -5.042e+08   3.07e+09     -0.164      0.870   -6.52e+09    5.51e+09\n",
      "adv_store_80      -5.042e+08   3.07e+09     -0.164      0.870   -6.52e+09    5.51e+09\n",
      "bay_store_80      -5.042e+08   3.07e+09     -0.164      0.870   -6.52e+09    5.51e+09\n",
      "sto_store_80      -5.042e+08   3.07e+09     -0.164      0.870   -6.52e+09    5.51e+09\n",
      "tyl_store_81      -1.858e+08   1.13e+09     -0.164      0.870    -2.4e+09    2.03e+09\n",
      "adv_store_81      -1.858e+08   1.13e+09     -0.164      0.870    -2.4e+09    2.03e+09\n",
      "bay_store_81      -1.858e+08   1.13e+09     -0.164      0.870    -2.4e+09    2.03e+09\n",
      "sto_store_81      -1.858e+08   1.13e+09     -0.164      0.870    -2.4e+09    2.03e+09\n",
      "tyl_store_83       7.999e+08   4.87e+09      0.164      0.870   -8.74e+09    1.03e+10\n",
      "adv_store_83       7.999e+08   4.87e+09      0.164      0.870   -8.74e+09    1.03e+10\n",
      "bay_store_83       7.999e+08   4.87e+09      0.164      0.870   -8.74e+09    1.03e+10\n",
      "sto_store_83       7.999e+08   4.87e+09      0.164      0.870   -8.74e+09    1.03e+10\n",
      "tyl_store_84      -2.669e+08   1.62e+09     -0.164      0.870   -3.45e+09    2.92e+09\n",
      "adv_store_84      -2.669e+08   1.62e+09     -0.164      0.870   -3.45e+09    2.92e+09\n",
      "bay_store_84      -2.669e+08   1.62e+09     -0.164      0.870   -3.45e+09    2.92e+09\n",
      "sto_store_84      -2.669e+08   1.62e+09     -0.164      0.870   -3.45e+09    2.92e+09\n",
      "tyl_store_86       7.272e+08   4.43e+09      0.164      0.870   -7.95e+09     9.4e+09\n",
      "adv_store_86       7.272e+08   4.43e+09      0.164      0.870   -7.95e+09     9.4e+09\n",
      "bay_store_86       7.272e+08   4.43e+09      0.164      0.870   -7.95e+09     9.4e+09\n",
      "sto_store_86       7.272e+08   4.43e+09      0.164      0.870   -7.95e+09     9.4e+09\n",
      "tyl_store_89       7.749e+08   4.72e+09      0.164      0.870   -8.47e+09       1e+10\n",
      "adv_store_89       7.749e+08   4.72e+09      0.164      0.870   -8.47e+09       1e+10\n",
      "bay_store_89       7.749e+08   4.72e+09      0.164      0.870   -8.47e+09       1e+10\n",
      "sto_store_89       7.749e+08   4.72e+09      0.164      0.870   -8.47e+09       1e+10\n",
      "tyl_store_90       1.228e+08   7.48e+08      0.164      0.870   -1.34e+09    1.59e+09\n",
      "adv_store_90       1.228e+08   7.48e+08      0.164      0.870   -1.34e+09    1.59e+09\n",
      "bay_store_90       1.228e+08   7.48e+08      0.164      0.870   -1.34e+09    1.59e+09\n",
      "sto_store_90       1.228e+08   7.48e+08      0.164      0.870   -1.34e+09    1.59e+09\n",
      "tyl_store_91       7.406e+07   4.51e+08      0.164      0.870   -8.09e+08    9.58e+08\n",
      "adv_store_91       7.406e+07   4.51e+08      0.164      0.870   -8.09e+08    9.58e+08\n",
      "bay_store_91       7.406e+07   4.51e+08      0.164      0.870   -8.09e+08    9.58e+08\n",
      "sto_store_91       7.406e+07   4.51e+08      0.164      0.870   -8.09e+08    9.58e+08\n",
      "tyl_store_92       5.667e+08   3.45e+09      0.164      0.870   -6.19e+09    7.33e+09\n",
      "adv_store_92       5.667e+08   3.45e+09      0.164      0.870   -6.19e+09    7.33e+09\n",
      "bay_store_92       5.667e+08   3.45e+09      0.164      0.870   -6.19e+09    7.33e+09\n",
      "sto_store_92       5.667e+08   3.45e+09      0.164      0.870   -6.19e+09    7.33e+09\n",
      "tyl_store_93       3.566e+07   2.17e+08      0.164      0.870    -3.9e+08    4.61e+08\n",
      "adv_store_93       3.566e+07   2.17e+08      0.164      0.870    -3.9e+08    4.61e+08\n",
      "bay_store_93       3.566e+07   2.17e+08      0.164      0.870    -3.9e+08    4.61e+08\n",
      "sto_store_93       3.566e+07   2.17e+08      0.164      0.870    -3.9e+08    4.61e+08\n",
      "tyl_store_94      -3.342e+08   2.03e+09     -0.164      0.870   -4.32e+09    3.65e+09\n",
      "adv_store_94      -3.342e+08   2.03e+09     -0.164      0.870   -4.32e+09    3.65e+09\n",
      "bay_store_94      -3.342e+08   2.03e+09     -0.164      0.870   -4.32e+09    3.65e+09\n",
      "sto_store_94      -3.342e+08   2.03e+09     -0.164      0.870   -4.32e+09    3.65e+09\n",
      "tyl_store_95       3.172e+06   1.93e+07      0.164      0.870   -3.47e+07     4.1e+07\n",
      "adv_store_95       3.172e+06   1.93e+07      0.164      0.870   -3.47e+07     4.1e+07\n",
      "bay_store_95       3.172e+06   1.93e+07      0.164      0.870   -3.47e+07     4.1e+07\n",
      "sto_store_95       3.172e+06   1.93e+07      0.164      0.870   -3.47e+07     4.1e+07\n",
      "tyl_store_97       -3.87e+07   2.36e+08     -0.164      0.870      -5e+08    4.23e+08\n",
      "adv_store_97       -3.87e+07   2.36e+08     -0.164      0.870      -5e+08    4.23e+08\n",
      "bay_store_97       -3.87e+07   2.36e+08     -0.164      0.870      -5e+08    4.23e+08\n",
      "sto_store_97       -3.87e+07   2.36e+08     -0.164      0.870      -5e+08    4.23e+08\n",
      "tyl_store_98       1.549e+09   9.43e+09      0.164      0.870   -1.69e+10       2e+10\n",
      "adv_store_98       1.549e+09   9.43e+09      0.164      0.870   -1.69e+10       2e+10\n",
      "bay_store_98       1.549e+09   9.43e+09      0.164      0.870   -1.69e+10       2e+10\n",
      "sto_store_98       1.549e+09   9.43e+09      0.164      0.870   -1.69e+10       2e+10\n",
      "tyl_store_100      -1.09e+09   6.64e+09     -0.164      0.870   -1.41e+10    1.19e+10\n",
      "adv_store_100      -1.09e+09   6.64e+09     -0.164      0.870   -1.41e+10    1.19e+10\n",
      "bay_store_100      -1.09e+09   6.64e+09     -0.164      0.870   -1.41e+10    1.19e+10\n",
      "sto_store_100      -1.09e+09   6.64e+09     -0.164      0.870   -1.41e+10    1.19e+10\n",
      "tyl_store_101     -3.496e+08   2.13e+09     -0.164      0.870   -4.52e+09    3.82e+09\n",
      "adv_store_101     -3.496e+08   2.13e+09     -0.164      0.870   -4.52e+09    3.82e+09\n",
      "bay_store_101     -3.496e+08   2.13e+09     -0.164      0.870   -4.52e+09    3.82e+09\n",
      "sto_store_101     -3.496e+08   2.13e+09     -0.164      0.870   -4.52e+09    3.82e+09\n",
      "tyl_store_102       1.61e+09    9.8e+09      0.164      0.870   -1.76e+10    2.08e+10\n",
      "adv_store_102       1.61e+09    9.8e+09      0.164      0.870   -1.76e+10    2.08e+10\n",
      "bay_store_102       1.61e+09    9.8e+09      0.164      0.870   -1.76e+10    2.08e+10\n",
      "sto_store_102       1.61e+09    9.8e+09      0.164      0.870   -1.76e+10    2.08e+10\n",
      "tyl_store_103      2.031e+09   1.24e+10      0.164      0.870   -2.22e+10    2.63e+10\n",
      "adv_store_103      2.031e+09   1.24e+10      0.164      0.870   -2.22e+10    2.63e+10\n",
      "bay_store_103      2.031e+09   1.24e+10      0.164      0.870   -2.22e+10    2.63e+10\n",
      "sto_store_103      2.031e+09   1.24e+10      0.164      0.870   -2.22e+10    2.63e+10\n",
      "tyl_store_104     -3.648e+08   2.22e+09     -0.164      0.870   -4.72e+09    3.99e+09\n",
      "adv_store_104     -3.648e+08   2.22e+09     -0.164      0.870   -4.72e+09    3.99e+09\n",
      "bay_store_104     -3.648e+08   2.22e+09     -0.164      0.870   -4.72e+09    3.99e+09\n",
      "sto_store_104     -3.648e+08   2.22e+09     -0.164      0.870   -4.72e+09    3.99e+09\n",
      "tyl_store_105       1.06e+09   6.45e+09      0.164      0.870   -1.16e+10    1.37e+10\n",
      "adv_store_105       1.06e+09   6.45e+09      0.164      0.870   -1.16e+10    1.37e+10\n",
      "bay_store_105       1.06e+09   6.45e+09      0.164      0.870   -1.16e+10    1.37e+10\n",
      "sto_store_105       1.06e+09   6.45e+09      0.164      0.870   -1.16e+10    1.37e+10\n",
      "tyl_store_106      2.798e+08    1.7e+09      0.164      0.870   -3.06e+09    3.62e+09\n",
      "adv_store_106      2.798e+08    1.7e+09      0.164      0.870   -3.06e+09    3.62e+09\n",
      "bay_store_106      2.798e+08    1.7e+09      0.164      0.870   -3.06e+09    3.62e+09\n",
      "sto_store_106      2.798e+08    1.7e+09      0.164      0.870   -3.06e+09    3.62e+09\n",
      "tyl_store_107     -5.794e+08   3.53e+09     -0.164      0.870   -7.49e+09    6.33e+09\n",
      "adv_store_107     -5.794e+08   3.53e+09     -0.164      0.870   -7.49e+09    6.33e+09\n",
      "bay_store_107     -5.794e+08   3.53e+09     -0.164      0.870   -7.49e+09    6.33e+09\n",
      "sto_store_107     -5.794e+08   3.53e+09     -0.164      0.870   -7.49e+09    6.33e+09\n",
      "tyl_store_109     -3.124e+09    1.9e+10     -0.164      0.870   -4.04e+10    3.41e+10\n",
      "adv_store_109     -3.124e+09    1.9e+10     -0.164      0.870   -4.04e+10    3.41e+10\n",
      "bay_store_109     -3.124e+09    1.9e+10     -0.164      0.870   -4.04e+10    3.41e+10\n",
      "sto_store_109     -3.124e+09    1.9e+10     -0.164      0.870   -4.04e+10    3.41e+10\n",
      "tyl_store_110      5.208e+08   3.17e+09      0.164      0.870   -5.69e+09    6.73e+09\n",
      "adv_store_110      5.208e+08   3.17e+09      0.164      0.870   -5.69e+09    6.73e+09\n",
      "bay_store_110      5.208e+08   3.17e+09      0.164      0.870   -5.69e+09    6.73e+09\n",
      "sto_store_110      5.208e+08   3.17e+09      0.164      0.870   -5.69e+09    6.73e+09\n",
      "tyl_store_111      6.874e+08   4.18e+09      0.164      0.870   -7.51e+09    8.89e+09\n",
      "adv_store_111      6.874e+08   4.18e+09      0.164      0.870   -7.51e+09    8.89e+09\n",
      "bay_store_111      6.874e+08   4.18e+09      0.164      0.870   -7.51e+09    8.89e+09\n",
      "sto_store_111      6.874e+08   4.18e+09      0.164      0.870   -7.51e+09    8.89e+09\n",
      "tyl_store_112     -1.262e+09   7.68e+09     -0.164      0.870   -1.63e+10    1.38e+10\n",
      "adv_store_112     -1.262e+09   7.68e+09     -0.164      0.870   -1.63e+10    1.38e+10\n",
      "bay_store_112     -1.262e+09   7.68e+09     -0.164      0.870   -1.63e+10    1.38e+10\n",
      "sto_store_112     -1.262e+09   7.68e+09     -0.164      0.870   -1.63e+10    1.38e+10\n",
      "tyl_store_113     -1.487e+08   9.05e+08     -0.164      0.870   -1.92e+09    1.62e+09\n",
      "adv_store_113     -1.487e+08   9.05e+08     -0.164      0.870   -1.92e+09    1.62e+09\n",
      "bay_store_113     -1.487e+08   9.05e+08     -0.164      0.870   -1.92e+09    1.62e+09\n",
      "sto_store_113     -1.487e+08   9.05e+08     -0.164      0.870   -1.92e+09    1.62e+09\n",
      "tyl_store_114      1.519e+09   9.25e+09      0.164      0.870   -1.66e+10    1.96e+10\n",
      "adv_store_114      1.519e+09   9.25e+09      0.164      0.870   -1.66e+10    1.96e+10\n",
      "bay_store_114      1.519e+09   9.25e+09      0.164      0.870   -1.66e+10    1.96e+10\n",
      "sto_store_114      1.519e+09   9.25e+09      0.164      0.870   -1.66e+10    1.96e+10\n",
      "tyl_store_115     -7.952e+08   4.84e+09     -0.164      0.870   -1.03e+10    8.69e+09\n",
      "adv_store_115     -7.952e+08   4.84e+09     -0.164      0.870   -1.03e+10    8.69e+09\n",
      "bay_store_115     -7.952e+08   4.84e+09     -0.164      0.870   -1.03e+10    8.69e+09\n",
      "sto_store_115     -7.952e+08   4.84e+09     -0.164      0.870   -1.03e+10    8.69e+09\n",
      "tyl_store_116      4.292e+06   2.61e+07      0.164      0.870   -4.69e+07    5.55e+07\n",
      "adv_store_116      4.292e+06   2.61e+07      0.164      0.870   -4.69e+07    5.55e+07\n",
      "bay_store_116      4.292e+06   2.61e+07      0.164      0.870   -4.69e+07    5.55e+07\n",
      "sto_store_116      4.292e+06   2.61e+07      0.164      0.870   -4.69e+07    5.55e+07\n",
      "tyl_store_117       6.39e+07   3.89e+08      0.164      0.870   -6.98e+08    8.26e+08\n",
      "adv_store_117       6.39e+07   3.89e+08      0.164      0.870   -6.98e+08    8.26e+08\n",
      "bay_store_117       6.39e+07   3.89e+08      0.164      0.870   -6.98e+08    8.26e+08\n",
      "sto_store_117       6.39e+07   3.89e+08      0.164      0.870   -6.98e+08    8.26e+08\n",
      "tyl_store_118     -3.955e+08   2.41e+09     -0.164      0.870   -5.11e+09    4.32e+09\n",
      "adv_store_118     -3.955e+08   2.41e+09     -0.164      0.870   -5.11e+09    4.32e+09\n",
      "bay_store_118     -3.955e+08   2.41e+09     -0.164      0.870   -5.11e+09    4.32e+09\n",
      "sto_store_118     -3.955e+08   2.41e+09     -0.164      0.870   -5.11e+09    4.32e+09\n",
      "tyl_store_119      2.506e+08   1.53e+09      0.164      0.870   -2.74e+09    3.24e+09\n",
      "adv_store_119      2.506e+08   1.53e+09      0.164      0.870   -2.74e+09    3.24e+09\n",
      "bay_store_119      2.506e+08   1.53e+09      0.164      0.870   -2.74e+09    3.24e+09\n",
      "sto_store_119      2.506e+08   1.53e+09      0.164      0.870   -2.74e+09    3.24e+09\n",
      "tyl_store_121     -4.365e+08   2.66e+09     -0.164      0.870   -5.64e+09    4.77e+09\n",
      "adv_store_121     -4.365e+08   2.66e+09     -0.164      0.870   -5.64e+09    4.77e+09\n",
      "bay_store_121     -4.365e+08   2.66e+09     -0.164      0.870   -5.64e+09    4.77e+09\n",
      "sto_store_121     -4.365e+08   2.66e+09     -0.164      0.870   -5.64e+09    4.77e+09\n",
      "tyl_store_122     -7.696e+07   4.68e+08     -0.164      0.870   -9.95e+08    8.41e+08\n",
      "adv_store_122     -7.696e+07   4.68e+08     -0.164      0.870   -9.95e+08    8.41e+08\n",
      "bay_store_122     -7.696e+07   4.68e+08     -0.164      0.870   -9.95e+08    8.41e+08\n",
      "sto_store_122     -7.696e+07   4.68e+08     -0.164      0.870   -9.95e+08    8.41e+08\n",
      "tyl_store_123     -2.826e+08   1.72e+09     -0.164      0.870   -3.65e+09    3.09e+09\n",
      "adv_store_123     -2.826e+08   1.72e+09     -0.164      0.870   -3.65e+09    3.09e+09\n",
      "bay_store_123     -2.826e+08   1.72e+09     -0.164      0.870   -3.65e+09    3.09e+09\n",
      "sto_store_123     -2.826e+08   1.72e+09     -0.164      0.870   -3.65e+09    3.09e+09\n",
      "price_hat_hausman  2.549e+10   1.55e+11      0.164      0.870   -2.79e+11     3.3e+11\n",
      "==============================================================================\n",
      "Omnibus:                     1932.195   Durbin-Watson:                   0.848\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2233.478\n",
      "Skew:                          -0.578   Prob(JB):                         0.00\n",
      "Kurtosis:                       3.230   Cond. No.                     2.47e+16\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 1.28e-27. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n",
      "Price coefficient: 25491184656.406025\n"
     ]
    }
   ],
   "source": [
    "# Define the independent variables and the instrument\n",
    "X_fixed_effects_hausman = df1[['prom_'] + [col for col in df1.columns if '_store' in col]]\n",
    "X_fixed_effects_hausman = sm.add_constant(X_fixed_effects_hausman)\n",
    "instrument_hausman = df1['Hausman']\n",
    "\n",
    "# First stage: regress price_ on the instrument Hausman and other exogenous variables\n",
    "first_stage_hausman = sm.OLS(df1['price_'], sm.add_constant(instrument_hausman)).fit()\n",
    "df1['price_hat_hausman'] = first_stage_hausman.fittedvalues\n",
    "\n",
    "# Second stage: regress Y on the predicted values of price_ and other exogenous variables\n",
    "X_fixed_effects_hausman['price_hat_hausman'] = df1['price_hat_hausman']\n",
    "model_iv_fixed_effects_hausman = sm.OLS(Y, X_fixed_effects_hausman).fit()\n",
    "\n",
    "# Print the regression results\n",
    "print(model_iv_fixed_effects_hausman.summary())\n",
    "\n",
    "# Print the coefficient for price\n",
    "print(f\"Price coefficient: {model_iv_fixed_effects_hausman.params['price_hat_hausman']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **QUESTION 2.G**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elasticity for tyl: -0.11258705271206843\n",
      "Elasticity for adv: -0.05278634561724045\n",
      "Elasticity for bay: -0.02817155809285109\n",
      "Elasticity for sto: -0.025423809771131196\n"
     ]
    }
   ],
   "source": [
    "# Define the coefficient of price from model (a)\n",
    "price_coefficient = -0.0514\n",
    "\n",
    "# Calculate the elasticity\n",
    "df1['elasticity'] = price_coefficient * df1['price_'] * (1 - df1['sales_per_count'])\n",
    "\n",
    "# Display the first few rows to verify\n",
    "df1.head()\n",
    "\n",
    "# Now calculate the weighted average of elasticity per product (tyl, adv, bay, sto)\n",
    "elasticity_tyl = (df1['sales_'] * df1['elasticity'] * df1['tyl']).sum() / df1['sales_'].sum()\n",
    "elasticity_adv = (df1['sales_'] * df1['elasticity'] * df1['adv']).sum() / df1['sales_'].sum()\n",
    "elasticity_bay = (df1['sales_'] * df1['elasticity'] * df1['bay']).sum() / df1['sales_'].sum()\n",
    "elasticity_sto = (df1['sales_'] * df1['elasticity'] * df1['sto']).sum() / df1['sales_'].sum()\n",
    "\n",
    "# Print the elasticity for each product\n",
    "print(f\"Elasticity for tyl: {elasticity_tyl}\")\n",
    "print(f\"Elasticity for adv: {elasticity_adv}\")\n",
    "print(f\"Elasticity for bay: {elasticity_bay}\")\n",
    "print(f\"Elasticity for sto: {elasticity_sto}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.1886089022705784\n",
      "Elasticity for tyl (part b): -0.4131307475078399\n",
      "Elasticity for adv (part b): -0.19369600587048794\n",
      "Elasticity for bay (part b): -0.10337367017790804\n",
      "Elasticity for sto (part b): -0.09329098934764707\n"
     ]
    }
   ],
   "source": [
    "# Define the coefficient of price from model (b)\n",
    "price_coefficient_b = model_with_dummies.params['price_']\n",
    "print(price_coefficient_b)\n",
    "# Calculate the elasticity\n",
    "df1['elasticity_b'] = price_coefficient_b * df1['price_'] * (1 - df1['sales_per_count'])\n",
    "\n",
    "# Display the first few rows to verify\n",
    "df1.head()\n",
    "\n",
    "# Now calculate the weighted average of elasticity per product (tyl, adv, bay, sto)\n",
    "elasticity_tyl_b = (df1['sales_'] * df1['elasticity_b'] * df1['tyl']).sum() / df1['sales_'].sum()\n",
    "elasticity_adv_b = (df1['sales_'] * df1['elasticity_b'] * df1['adv']).sum() / df1['sales_'].sum()\n",
    "elasticity_bay_b = (df1['sales_'] * df1['elasticity_b'] * df1['bay']).sum() / df1['sales_'].sum()\n",
    "elasticity_sto_b = (df1['sales_'] * df1['elasticity_b'] * df1['sto']).sum() / df1['sales_'].sum()\n",
    "\n",
    "# Print the elasticity for each product\n",
    "print(f\"Elasticity for tyl (part b): {elasticity_tyl_b}\")\n",
    "print(f\"Elasticity for adv (part b): {elasticity_adv_b}\")\n",
    "print(f\"Elasticity for bay (part b): {elasticity_bay_b}\")\n",
    "print(f\"Elasticity for sto (part b): {elasticity_sto_b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.188034616488536\n",
      "Elasticity for tyl (part c): -0.4118728264258438\n",
      "Elasticity for adv (part c): -0.19310623062196738\n",
      "Elasticity for bay (part c): -0.10305891287692155\n",
      "Elasticity for sto (part c): -0.0930069322955671\n"
     ]
    }
   ],
   "source": [
    "# Define the coefficient of price from model (c)\n",
    "price_coefficient_c = fixed_effects_model.params['price_']\n",
    "\n",
    "print(price_coefficient_c)\n",
    "\n",
    "# Calculate the elasticity\n",
    "df1['elasticity_c'] = price_coefficient_c * df1['price_'] * (1 - df1['sales_per_count'])\n",
    "\n",
    "# Display the first few rows to verify\n",
    "df1.head()\n",
    "\n",
    "# Now calculate the weighted average of elasticity per product (tyl, adv, bay, sto)\n",
    "elasticity_tyl_c = (df1['sales_'] * df1['elasticity_c'] * df1['tyl']).sum() / df1['sales_'].sum()\n",
    "elasticity_adv_c = (df1['sales_'] * df1['elasticity_c'] * df1['adv']).sum() / df1['sales_'].sum()\n",
    "elasticity_bay_c = (df1['sales_'] * df1['elasticity_c'] * df1['bay']).sum() / df1['sales_'].sum()\n",
    "elasticity_sto_c = (df1['sales_'] * df1['elasticity_c'] * df1['sto']).sum() / df1['sales_'].sum()\n",
    "\n",
    "# Print the elasticity for each product\n",
    "print(f\"Elasticity for tyl (part c): {elasticity_tyl_c}\")\n",
    "print(f\"Elasticity for adv (part c): {elasticity_adv_c}\")\n",
    "print(f\"Elasticity for bay (part c): {elasticity_bay_c}\")\n",
    "print(f\"Elasticity for sto (part c): {elasticity_sto_c}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
