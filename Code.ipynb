{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **QUESTION 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store</th>\n",
       "      <th>week</th>\n",
       "      <th>brand</th>\n",
       "      <th>sales_</th>\n",
       "      <th>count</th>\n",
       "      <th>price_</th>\n",
       "      <th>prom_</th>\n",
       "      <th>cost_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>14181</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>13965</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>13538</td>\n",
       "      <td>3.37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>13735</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>13735</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   store  week  brand  sales_  count  price_  prom_  cost_\n",
       "0      2     1      1      16  14181    3.29    0.0   2.06\n",
       "1      2     2      1      12  13965    3.27    0.0   2.04\n",
       "2      2     3      1       6  13538    3.37    0.0   2.15\n",
       "3      2     4      1      12  13735    3.30    0.0   2.07\n",
       "4      2     5      1      10  13735    3.34    0.0   2.12"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################################### Question 1 (Preparation and Data Import) ###################################\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "df1 = pd.read_csv(\"OTC_Sales.csv\",sep=\"\\t\")\n",
    "df2 = pd.read_csv(\"OTC_Demographics.csv\",sep=\"\\t\")\n",
    "df3 = pd.read_csv(\"OTC_Instruments.csv\",sep=\"\\t\")\n",
    "\n",
    "\n",
    "df1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "share_1: 0.14513692602512893\n",
      "share_2: 0.17988041419128795\n",
      "share_3: 0.11786960705561754\n",
      "share_4: 0.11845629580078901\n",
      "share_5: 0.07822151064127274\n",
      "share_6: 0.035480961401911947\n",
      "share_7: 0.04076390164464756\n",
      "share_8: 0.03445288532976568\n",
      "share_9: 0.0800747891073284\n",
      "share_10: 0.09615938194808078\n",
      "share_11: 0.07350332685416947\n"
     ]
    }
   ],
   "source": [
    "################################### Summary statistics for the table 1 ###################################\n",
    "\n",
    "# Calculate the total sales\n",
    "total_sales = df1['sales_'].sum()\n",
    "\n",
    "# Calculate the sales share for each brand\n",
    "brand_sales = df1.groupby('brand')['sales_'].sum()\n",
    "\n",
    "\n",
    "# Generate share variables for each brand\n",
    "share_1 = brand_sales[1] / total_sales\n",
    "share_2 = brand_sales[2] / total_sales\n",
    "share_3 = brand_sales[3] / total_sales\n",
    "share_4 = brand_sales[4] / total_sales\n",
    "share_5 = brand_sales[5] / total_sales\n",
    "share_6 = brand_sales[6] / total_sales\n",
    "share_7 = brand_sales[7] / total_sales\n",
    "share_8 = brand_sales[8] / total_sales\n",
    "share_9 = brand_sales[9] / total_sales\n",
    "share_10 = brand_sales[10] / total_sales\n",
    "share_11 = brand_sales[11] / total_sales\n",
    "\n",
    "# Print the share variables\n",
    "print(f\"share_1: {share_1}\")\n",
    "print(f\"share_2: {share_2}\")\n",
    "print(f\"share_3: {share_3}\")\n",
    "print(f\"share_4: {share_4}\")\n",
    "print(f\"share_5: {share_5}\")\n",
    "print(f\"share_6: {share_6}\")\n",
    "print(f\"share_7: {share_7}\")\n",
    "print(f\"share_8: {share_8}\")\n",
    "print(f\"share_9: {share_9}\")\n",
    "print(f\"share_10: {share_10}\")\n",
    "print(f\"share_11: {share_11}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weighted_avg_price_1: 3.414884775217227\n",
      "weighted_avg_price_2: 4.888457470318381\n",
      "weighted_avg_price_3: 6.935243987533144\n",
      "weighted_avg_price_4: 2.938778235511942\n",
      "weighted_avg_price_5: 5.02520433197813\n",
      "weighted_avg_price_6: 8.071122701282645\n",
      "weighted_avg_price_7: 2.670661107001143\n",
      "weighted_avg_price_8: 3.600319089679319\n",
      "weighted_avg_price_9: 3.9389793892084364\n",
      "weighted_avg_price_10: 1.8611150392017106\n",
      "weighted_avg_price_11: 4.29954384394465\n",
      "weighted_avg_cost_1: 2.17952871174915\n",
      "weighted_avg_cost_2: 3.6696483928489783\n",
      "weighted_avg_cost_3: 5.748667255896171\n",
      "weighted_avg_cost_4: 2.0292830031475653\n",
      "weighted_avg_cost_5: 3.6047360857984017\n",
      "weighted_avg_cost_6: 6.104660794313088\n",
      "weighted_avg_cost_7: 1.8421487658887619\n",
      "weighted_avg_cost_8: 2.484719503461447\n",
      "weighted_avg_cost_9: 3.7093806491372225\n",
      "weighted_avg_cost_10: 0.9077034925160371\n",
      "weighted_avg_cost_11: 1.8716247062772742\n"
     ]
    }
   ],
   "source": [
    "######################################### Weighted average price and cost for each brand #########################################\n",
    "\n",
    "for i in range(1, 12):\n",
    "    weighted_avg_price_i = (df1[df1['brand'] == i]['sales_'] * df1[df1['brand'] == i]['price_']).sum() / df1[df1['brand'] == i]['sales_'].sum()\n",
    "    print(f\"weighted_avg_price_{i}: {weighted_avg_price_i}\")\n",
    "\n",
    "# Calculate the weighted average cost (wholesale price) for each brand\n",
    "\n",
    "for i in range(1, 12):\n",
    "    weighted_avg_cost_i = (df1[df1['brand'] == i]['sales_'] * df1[df1['brand'] == i]['cost_']).sum() / df1[df1['brand'] == i]['sales_'].sum()\n",
    "    print(f\"weighted_avg_cost_{i}: {weighted_avg_cost_i}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **QUESTION 2**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store</th>\n",
       "      <th>week</th>\n",
       "      <th>brand</th>\n",
       "      <th>sales_</th>\n",
       "      <th>count</th>\n",
       "      <th>price_</th>\n",
       "      <th>prom_</th>\n",
       "      <th>cost_</th>\n",
       "      <th>sales_per_count</th>\n",
       "      <th>share_0</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>14181</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.06</td>\n",
       "      <td>0.001128</td>\n",
       "      <td>0.993724</td>\n",
       "      <td>-6.780774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>13965</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.04</td>\n",
       "      <td>0.000859</td>\n",
       "      <td>0.993913</td>\n",
       "      <td>-7.053298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>13538</td>\n",
       "      <td>3.37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>0.995199</td>\n",
       "      <td>-7.716683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>13735</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.07</td>\n",
       "      <td>0.000874</td>\n",
       "      <td>0.993957</td>\n",
       "      <td>-7.036735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>13735</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.12</td>\n",
       "      <td>0.000728</td>\n",
       "      <td>0.995268</td>\n",
       "      <td>-7.220374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   store  week  brand  sales_  count  price_  prom_  cost_  sales_per_count  \\\n",
       "0      2     1      1      16  14181    3.29    0.0   2.06         0.001128   \n",
       "1      2     2      1      12  13965    3.27    0.0   2.04         0.000859   \n",
       "2      2     3      1       6  13538    3.37    0.0   2.15         0.000443   \n",
       "3      2     4      1      12  13735    3.30    0.0   2.07         0.000874   \n",
       "4      2     5      1      10  13735    3.34    0.0   2.12         0.000728   \n",
       "\n",
       "    share_0         Y  \n",
       "0  0.993724 -6.780774  \n",
       "1  0.993913 -7.053298  \n",
       "2  0.995199 -7.716683  \n",
       "3  0.993957 -7.036735  \n",
       "4  0.995268 -7.220374  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####################################### Question 2 (Data Preparation) #######################################\n",
    "\n",
    "df1['sales_per_count'] = df1['sales_'] / df1['count']\n",
    "\n",
    "df1['share_0'] = 1 - df1.groupby(['store', 'week'])['sales_per_count'].transform('sum')\n",
    "\n",
    "df1['Y'] = np.log(df1['sales_per_count']) - np.log(df1['share_0'])\n",
    "\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   R-squared:                       0.016\n",
      "Model:                            OLS   Adj. R-squared:                  0.016\n",
      "Method:                 Least Squares   F-statistic:                     315.2\n",
      "Date:                Fri, 07 Feb 2025   Prob (F-statistic):          1.72e-136\n",
      "Time:                        01:22:19   Log-Likelihood:                -50711.\n",
      "No. Observations:               38544   AIC:                         1.014e+05\n",
      "Df Residuals:                   38541   BIC:                         1.015e+05\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -7.7660      0.012   -627.345      0.000      -7.790      -7.742\n",
      "prom_          0.2130      0.016     13.074      0.000       0.181       0.245\n",
      "price_        -0.0514      0.003    -20.194      0.000      -0.056      -0.046\n",
      "==============================================================================\n",
      "Omnibus:                     2323.526   Durbin-Watson:                   0.558\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2372.728\n",
      "Skew:                          -0.566   Prob(JB):                         0.00\n",
      "Kurtosis:                       2.558   Cond. No.                         17.7\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "##################################### OLS Q2.(a) #####################################\n",
    "\n",
    "# Define the independent variables\n",
    "X = df1[['prom_', 'price_']]\n",
    "\n",
    "# Add a constant to the independent variables\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Define the dependent variable\n",
    "Y = df1['Y']\n",
    "\n",
    "# Fit the regression model\n",
    "model = sm.OLS(Y, X).fit()\n",
    "\n",
    "# Print the regression results\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store</th>\n",
       "      <th>week</th>\n",
       "      <th>brand</th>\n",
       "      <th>sales_</th>\n",
       "      <th>count</th>\n",
       "      <th>price_</th>\n",
       "      <th>prom_</th>\n",
       "      <th>cost_</th>\n",
       "      <th>sales_per_count</th>\n",
       "      <th>share_0</th>\n",
       "      <th>Y</th>\n",
       "      <th>tyl</th>\n",
       "      <th>adv</th>\n",
       "      <th>bay</th>\n",
       "      <th>sto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>14181</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.06</td>\n",
       "      <td>0.001128</td>\n",
       "      <td>0.993724</td>\n",
       "      <td>-6.780774</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>13965</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.04</td>\n",
       "      <td>0.000859</td>\n",
       "      <td>0.993913</td>\n",
       "      <td>-7.053298</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>13538</td>\n",
       "      <td>3.37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>0.995199</td>\n",
       "      <td>-7.716683</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>13735</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.07</td>\n",
       "      <td>0.000874</td>\n",
       "      <td>0.993957</td>\n",
       "      <td>-7.036735</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>13735</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.12</td>\n",
       "      <td>0.000728</td>\n",
       "      <td>0.995268</td>\n",
       "      <td>-7.220374</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   store  week  brand  sales_  count  price_  prom_  cost_  sales_per_count  \\\n",
       "0      2     1      1      16  14181    3.29    0.0   2.06         0.001128   \n",
       "1      2     2      1      12  13965    3.27    0.0   2.04         0.000859   \n",
       "2      2     3      1       6  13538    3.37    0.0   2.15         0.000443   \n",
       "3      2     4      1      12  13735    3.30    0.0   2.07         0.000874   \n",
       "4      2     5      1      10  13735    3.34    0.0   2.12         0.000728   \n",
       "\n",
       "    share_0         Y  tyl  adv  bay  sto  \n",
       "0  0.993724 -6.780774    1    0    0    0  \n",
       "1  0.993913 -7.053298    1    0    0    0  \n",
       "2  0.995199 -7.716683    1    0    0    0  \n",
       "3  0.993957 -7.036735    1    0    0    0  \n",
       "4  0.995268 -7.220374    1    0    0    0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######################################## Generate Dummies for Product Type ########################################\n",
    "\n",
    "# Create dummy variables\n",
    "df1['tyl'] = df1['brand'].isin([1, 2, 3]).astype(int)\n",
    "df1['adv'] = df1['brand'].isin([4, 5, 6]).astype(int)\n",
    "df1['bay'] = df1['brand'].isin([7, 8, 9]).astype(int)\n",
    "df1['sto'] = df1['brand'].isin([10, 11]).astype(int)\n",
    "\n",
    "# Display the first few rows to verify\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   R-squared:                       0.370\n",
      "Model:                            OLS   Adj. R-squared:                  0.370\n",
      "Method:                 Least Squares   F-statistic:                     4535.\n",
      "Date:                Fri, 07 Feb 2025   Prob (F-statistic):               0.00\n",
      "Time:                        01:22:19   Log-Likelihood:                -42106.\n",
      "No. Observations:               38544   AIC:                         8.422e+04\n",
      "Df Residuals:                   38538   BIC:                         8.427e+04\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -5.7781      0.009   -648.960      0.000      -5.796      -5.761\n",
      "price_        -0.1886      0.002    -78.175      0.000      -0.193      -0.184\n",
      "prom_          0.4458      0.013     33.887      0.000       0.420       0.472\n",
      "tyl           -0.5455      0.007    -73.282      0.000      -0.560      -0.531\n",
      "adv           -1.3392      0.008   -170.461      0.000      -1.355      -1.324\n",
      "bay           -2.1007      0.006   -332.015      0.000      -2.113      -2.088\n",
      "sto           -1.7926      0.007   -243.914      0.000      -1.807      -1.778\n",
      "==============================================================================\n",
      "Omnibus:                     1560.106   Durbin-Watson:                   0.872\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1767.102\n",
      "Skew:                          -0.500   Prob(JB):                         0.00\n",
      "Kurtosis:                       3.314   Cond. No.                     2.80e+15\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 1.16e-25. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "##################################### OLS Q2.(b) #####################################\n",
    "\n",
    "# Define the independent variables including the dummy variables\n",
    "X = df1[['price_', 'prom_', 'tyl', 'adv', 'bay', 'sto']]\n",
    "\n",
    "# Add a constant to the independent variables\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Define the dependent variable\n",
    "Y = df1['Y']\n",
    "\n",
    "# Fit the regression model\n",
    "model_with_dummies = sm.OLS(Y, X).fit()\n",
    "\n",
    "# Print the regression results\n",
    "print(model_with_dummies.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2954/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
      "/tmp/ipykernel_2954/3716583663.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store</th>\n",
       "      <th>week</th>\n",
       "      <th>brand</th>\n",
       "      <th>sales_</th>\n",
       "      <th>count</th>\n",
       "      <th>price_</th>\n",
       "      <th>prom_</th>\n",
       "      <th>cost_</th>\n",
       "      <th>sales_per_count</th>\n",
       "      <th>share_0</th>\n",
       "      <th>...</th>\n",
       "      <th>bay_store_121</th>\n",
       "      <th>sto_store_121</th>\n",
       "      <th>tyl_store_122</th>\n",
       "      <th>adv_store_122</th>\n",
       "      <th>bay_store_122</th>\n",
       "      <th>sto_store_122</th>\n",
       "      <th>tyl_store_123</th>\n",
       "      <th>adv_store_123</th>\n",
       "      <th>bay_store_123</th>\n",
       "      <th>sto_store_123</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>14181</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.06</td>\n",
       "      <td>0.001128</td>\n",
       "      <td>0.993724</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>13965</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.04</td>\n",
       "      <td>0.000859</td>\n",
       "      <td>0.993913</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>13538</td>\n",
       "      <td>3.37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>0.995199</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>13735</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.07</td>\n",
       "      <td>0.000874</td>\n",
       "      <td>0.993957</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>13735</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.12</td>\n",
       "      <td>0.000728</td>\n",
       "      <td>0.995268</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  307 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   store  week  brand  sales_  count  price_  prom_  cost_  sales_per_count  \\\n",
       "0      2     1      1      16  14181    3.29    0.0   2.06         0.001128   \n",
       "1      2     2      1      12  13965    3.27    0.0   2.04         0.000859   \n",
       "2      2     3      1       6  13538    3.37    0.0   2.15         0.000443   \n",
       "3      2     4      1      12  13735    3.30    0.0   2.07         0.000874   \n",
       "4      2     5      1      10  13735    3.34    0.0   2.12         0.000728   \n",
       "\n",
       "    share_0  ...  bay_store_121  sto_store_121  tyl_store_122  adv_store_122  \\\n",
       "0  0.993724  ...              0              0              0              0   \n",
       "1  0.993913  ...              0              0              0              0   \n",
       "2  0.995199  ...              0              0              0              0   \n",
       "3  0.993957  ...              0              0              0              0   \n",
       "4  0.995268  ...              0              0              0              0   \n",
       "\n",
       "   bay_store_122  sto_store_122  tyl_store_123  adv_store_123  bay_store_123  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   sto_store_123  \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              0  \n",
       "\n",
       "[5 rows x 307 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############################################### Fixed Effects for Everything ###############################################\n",
    "\n",
    "# Generate new variables for each unique combination of store number and tyl, adv, bay, and sto\n",
    "for store in df1['store'].unique():\n",
    "    df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
    "    df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
    "    df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
    "    df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
    "\n",
    "# Display the first few rows to verify\n",
    "df1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "const           -7.200177\n",
      "price_          -0.188035\n",
      "prom_            0.443860\n",
      "tyl_store_2      0.824262\n",
      "adv_store_2      0.155209\n",
      "                   ...   \n",
      "sto_store_122    0.141384\n",
      "tyl_store_123    0.938088\n",
      "adv_store_123    0.025048\n",
      "bay_store_123   -0.829285\n",
      "sto_store_123   -0.217803\n",
      "Length: 295, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "##################################### OLS Q2.(c) Fixed Effects Model #####################################\n",
    "\n",
    "# Define the independent variables including the dummy variables\n",
    "X_fixed_effects = df1[['price_', 'prom_'] + [col for col in df1.columns if '_store' in col]]\n",
    "\n",
    "# Add a constant to the independent variables\n",
    "X_fixed_effects = sm.add_constant(X_fixed_effects)\n",
    "\n",
    "# Define the dependent variable\n",
    "Y = df1['Y']\n",
    "\n",
    "# Fit the regression model\n",
    "fixed_effects_model = sm.OLS(Y, X_fixed_effects).fit()\n",
    "\n",
    "# Print the coefficients for price and promotion\n",
    "print(fixed_effects_model.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   R-squared:                       0.063\n",
      "Model:                            OLS   Adj. R-squared:                  0.063\n",
      "Method:                 Least Squares   F-statistic:                     866.3\n",
      "Date:                Fri, 07 Feb 2025   Prob (F-statistic):               0.00\n",
      "Time:                        01:23:56   Log-Likelihood:                -49766.\n",
      "No. Observations:               38544   AIC:                         9.954e+04\n",
      "Df Residuals:                   38540   BIC:                         9.957e+04\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -7.5713      0.013   -588.577      0.000      -7.597      -7.546\n",
      "prom_          0.0829      0.016      5.125      0.000       0.051       0.115\n",
      "price_        -0.3445      0.007    -48.468      0.000      -0.358      -0.331\n",
      "cost_          0.3563      0.008     44.011      0.000       0.340       0.372\n",
      "==============================================================================\n",
      "Omnibus:                     1989.019   Durbin-Watson:                   0.589\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1841.689\n",
      "Skew:                          -0.479   Prob(JB):                         0.00\n",
      "Kurtosis:                       2.520   Cond. No.                         23.2\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "####################################### OLS Q2.(d) #####################################\n",
    "\n",
    "\n",
    "from statsmodels.sandbox.regression.gmm import IV2SLS\n",
    "\n",
    "###################################### Q2.(d) #####################################\n",
    "\n",
    "# Define the instrument variable\n",
    "instrument = df1['cost_']\n",
    "\n",
    "# First regression: original model\n",
    "X = df1[['prom_', 'price_', 'cost_']]\n",
    "X = sm.add_constant(X)\n",
    "Y = df1['Y']\n",
    "model_iv = sm.OLS(Y, X).fit()\n",
    "print(model_iv.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   R-squared:                       0.417\n",
      "Model:                            OLS   Adj. R-squared:                  0.417\n",
      "Method:                 Least Squares   F-statistic:                     4595.\n",
      "Date:                Fri, 07 Feb 2025   Prob (F-statistic):               0.00\n",
      "Time:                        01:24:38   Log-Likelihood:                -40623.\n",
      "No. Observations:               38544   AIC:                         8.126e+04\n",
      "Df Residuals:                   38537   BIC:                         8.132e+04\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -5.6167      0.009   -620.789      0.000      -5.634      -5.599\n",
      "price_        -0.5574      0.007    -79.205      0.000      -0.571      -0.544\n",
      "prom_          0.2917      0.013     22.510      0.000       0.266       0.317\n",
      "tyl           -0.6299      0.007    -86.017      0.000      -0.644      -0.616\n",
      "adv           -1.3330      0.008   -176.301      0.000      -1.348      -1.318\n",
      "bay           -2.2282      0.007   -342.421      0.000      -2.241      -2.215\n",
      "sto           -1.4256      0.010   -147.256      0.000      -1.445      -1.407\n",
      "cost_          0.4714      0.008     55.510      0.000       0.455       0.488\n",
      "==============================================================================\n",
      "Omnibus:                     2168.323   Durbin-Watson:                   0.960\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2818.321\n",
      "Skew:                          -0.543   Prob(JB):                         0.00\n",
      "Kurtosis:                       3.758   Cond. No.                     3.40e+15\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 1.19e-25. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "# Second regression: model with dummies\n",
    "X_dummies = df1[['price_', 'prom_', 'tyl', 'adv', 'bay', 'sto','cost_']]\n",
    "X_dummies = sm.add_constant(X_dummies)\n",
    "model_iv_dummies = sm.OLS(Y, X_dummies).fit()\n",
    "print(model_iv_dummies.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   R-squared:                       0.493\n",
      "Model:                            OLS   Adj. R-squared:                  0.489\n",
      "Method:                 Least Squares   F-statistic:                     126.5\n",
      "Date:                Fri, 07 Feb 2025   Prob (F-statistic):               0.00\n",
      "Time:                        01:25:12   Log-Likelihood:                -37933.\n",
      "No. Observations:               38544   AIC:                         7.646e+04\n",
      "Df Residuals:                   38249   BIC:                         7.898e+04\n",
      "Df Model:                         294                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=================================================================================\n",
      "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "const            -6.9975      0.011   -661.028      0.000      -7.018      -6.977\n",
      "price_           -0.5547      0.007    -83.453      0.000      -0.568      -0.542\n",
      "prom_             0.2905      0.012     23.910      0.000       0.267       0.314\n",
      "cost_             0.4679      0.008     58.380      0.000       0.452       0.484\n",
      "tyl_store_2       0.7636      0.054     14.106      0.000       0.658       0.870\n",
      "adv_store_2       0.1471      0.054      2.717      0.007       0.041       0.253\n",
      "bay_store_2      -0.5277      0.054     -9.741      0.000      -0.634      -0.422\n",
      "sto_store_2      -0.5578      0.066     -8.393      0.000      -0.688      -0.428\n",
      "tyl_store_5       0.9701      0.054     17.916      0.000       0.864       1.076\n",
      "adv_store_5       0.3936      0.054      7.270      0.000       0.287       0.500\n",
      "bay_store_5      -0.7058      0.054    -13.026      0.000      -0.812      -0.600\n",
      "sto_store_5       0.0275      0.066      0.414      0.679      -0.103       0.158\n",
      "tyl_store_8       0.8045      0.054     14.856      0.000       0.698       0.911\n",
      "adv_store_8      -0.1846      0.054     -3.410      0.001      -0.291      -0.078\n",
      "bay_store_8      -0.7693      0.054    -14.200      0.000      -0.875      -0.663\n",
      "sto_store_8       0.2027      0.066      3.049      0.002       0.072       0.333\n",
      "tyl_store_9       0.6404      0.054     11.827      0.000       0.534       0.747\n",
      "adv_store_9      -0.0314      0.054     -0.580      0.562      -0.138       0.075\n",
      "bay_store_9      -0.8739      0.054    -16.131      0.000      -0.980      -0.768\n",
      "sto_store_9      -0.2582      0.066     -3.885      0.000      -0.388      -0.128\n",
      "tyl_store_12      0.8060      0.054     14.888      0.000       0.700       0.912\n",
      "adv_store_12     -0.0692      0.054     -1.278      0.201      -0.175       0.037\n",
      "bay_store_12     -0.9788      0.054    -18.066      0.000      -1.085      -0.873\n",
      "sto_store_12     -0.0295      0.066     -0.444      0.657      -0.160       0.101\n",
      "tyl_store_14      1.0766      0.054     19.887      0.000       0.971       1.183\n",
      "adv_store_14      0.3917      0.054      7.234      0.000       0.286       0.498\n",
      "bay_store_14     -0.5896      0.054    -10.884      0.000      -0.696      -0.483\n",
      "sto_store_14     -0.3505      0.066     -5.275      0.000      -0.481      -0.220\n",
      "tyl_store_18      0.9273      0.054     17.125      0.000       0.821       1.033\n",
      "adv_store_18      0.1077      0.054      1.989      0.047       0.002       0.214\n",
      "bay_store_18     -0.6511      0.054    -12.016      0.000      -0.757      -0.545\n",
      "sto_store_18     -0.3143      0.066     -4.730      0.000      -0.445      -0.184\n",
      "tyl_store_21      0.6841      0.054     12.632      0.000       0.578       0.790\n",
      "adv_store_21      0.1055      0.054      1.948      0.051      -0.001       0.212\n",
      "bay_store_21     -1.1185      0.054    -20.640      0.000      -1.225      -1.012\n",
      "sto_store_21      0.2432      0.066      3.659      0.000       0.113       0.374\n",
      "tyl_store_28      0.7456      0.054     13.768      0.000       0.639       0.852\n",
      "adv_store_28      0.0409      0.054      0.756      0.450      -0.065       0.147\n",
      "bay_store_28     -0.8805      0.054    -16.253      0.000      -0.987      -0.774\n",
      "sto_store_28     -0.3188      0.066     -4.796      0.000      -0.449      -0.189\n",
      "tyl_store_32      0.5638      0.054     10.415      0.000       0.458       0.670\n",
      "adv_store_32     -0.1359      0.054     -2.510      0.012      -0.242      -0.030\n",
      "bay_store_32     -0.9298      0.054    -17.162      0.000      -1.036      -0.824\n",
      "sto_store_32     -0.4950      0.066     -7.449      0.000      -0.625      -0.365\n",
      "tyl_store_33      0.2918      0.054      5.389      0.000       0.186       0.398\n",
      "adv_store_33     -0.0030      0.054     -0.055      0.957      -0.109       0.103\n",
      "bay_store_33     -0.9951      0.054    -18.369      0.000      -1.101      -0.889\n",
      "sto_store_33     -0.4536      0.066     -6.823      0.000      -0.584      -0.323\n",
      "tyl_store_40      0.7337      0.054     13.545      0.000       0.628       0.840\n",
      "adv_store_40     -0.1706      0.054     -3.152      0.002      -0.277      -0.065\n",
      "bay_store_40     -1.0054      0.054    -18.546      0.000      -1.112      -0.899\n",
      "sto_store_40      0.1453      0.066      2.186      0.029       0.015       0.276\n",
      "tyl_store_44      0.6744      0.054     12.455      0.000       0.568       0.781\n",
      "adv_store_44     -0.0137      0.054     -0.254      0.800      -0.120       0.092\n",
      "bay_store_44     -0.6384      0.054    -11.784      0.000      -0.745      -0.532\n",
      "sto_store_44     -0.0819      0.066     -1.232      0.218      -0.212       0.048\n",
      "tyl_store_45      0.7999      0.054     14.772      0.000       0.694       0.906\n",
      "adv_store_45      0.1316      0.054      2.432      0.015       0.026       0.238\n",
      "bay_store_45     -0.7445      0.054    -13.743      0.000      -0.851      -0.638\n",
      "sto_store_45      0.0651      0.066      0.979      0.328      -0.065       0.195\n",
      "tyl_store_47      0.7738      0.054     14.292      0.000       0.668       0.880\n",
      "adv_store_47     -0.0707      0.054     -1.306      0.192      -0.177       0.035\n",
      "bay_store_47     -1.0080      0.054    -18.603      0.000      -1.114      -0.902\n",
      "sto_store_47     -0.1932      0.066     -2.907      0.004      -0.324      -0.063\n",
      "tyl_store_48      0.7844      0.054     14.485      0.000       0.678       0.891\n",
      "adv_store_48      0.1317      0.054      2.433      0.015       0.026       0.238\n",
      "bay_store_48     -0.7213      0.054    -13.314      0.000      -0.827      -0.615\n",
      "sto_store_48     -0.1081      0.066     -1.627      0.104      -0.238       0.022\n",
      "tyl_store_49      0.5325      0.054      9.835      0.000       0.426       0.639\n",
      "adv_store_49     -0.1558      0.054     -2.877      0.004      -0.262      -0.050\n",
      "bay_store_49     -0.9121      0.054    -16.834      0.000      -1.018      -0.806\n",
      "sto_store_49     -0.0925      0.066     -1.392      0.164      -0.223       0.038\n",
      "tyl_store_50      0.7157      0.054     13.214      0.000       0.610       0.822\n",
      "adv_store_50      0.0139      0.054      0.256      0.798      -0.092       0.120\n",
      "bay_store_50     -0.8517      0.054    -15.719      0.000      -0.958      -0.746\n",
      "sto_store_50     -0.1263      0.066     -1.901      0.057      -0.257       0.004\n",
      "tyl_store_51      0.7538      0.054     13.922      0.000       0.648       0.860\n",
      "adv_store_51      0.1803      0.054      3.331      0.001       0.074       0.286\n",
      "bay_store_51     -0.7472      0.054    -13.792      0.000      -0.853      -0.641\n",
      "sto_store_51      0.0573      0.066      0.862      0.389      -0.073       0.187\n",
      "tyl_store_52      0.8831      0.054     16.314      0.000       0.777       0.989\n",
      "adv_store_52      0.3745      0.054      6.916      0.000       0.268       0.481\n",
      "bay_store_52     -0.9887      0.054    -18.251      0.000      -1.095      -0.883\n",
      "sto_store_52     -0.3310      0.066     -4.981      0.000      -0.461      -0.201\n",
      "tyl_store_53      0.6486      0.054     11.981      0.000       0.542       0.755\n",
      "adv_store_53     -0.1661      0.054     -3.068      0.002      -0.272      -0.060\n",
      "bay_store_53     -1.0537      0.054    -19.451      0.000      -1.160      -0.948\n",
      "sto_store_53     -0.5116      0.066     -7.699      0.000      -0.642      -0.381\n",
      "tyl_store_54      0.8187      0.054     15.121      0.000       0.713       0.925\n",
      "adv_store_54      0.2415      0.054      4.461      0.000       0.135       0.348\n",
      "bay_store_54     -0.8693      0.054    -16.047      0.000      -0.975      -0.763\n",
      "sto_store_54      0.3026      0.066      4.552      0.000       0.172       0.433\n",
      "tyl_store_56      0.6756      0.054     12.478      0.000       0.569       0.782\n",
      "adv_store_56     -0.0881      0.054     -1.628      0.104      -0.194       0.018\n",
      "bay_store_56     -0.7780      0.054    -14.361      0.000      -0.884      -0.672\n",
      "sto_store_56     -0.0675      0.066     -1.016      0.310      -0.198       0.063\n",
      "tyl_store_59      0.7663      0.054     14.150      0.000       0.660       0.872\n",
      "adv_store_59      0.1708      0.054      3.155      0.002       0.065       0.277\n",
      "bay_store_59     -0.7231      0.054    -13.346      0.000      -0.829      -0.617\n",
      "sto_store_59      0.0325      0.066      0.489      0.625      -0.098       0.163\n",
      "tyl_store_62      1.0833      0.054     20.012      0.000       0.977       1.189\n",
      "adv_store_62      0.7081      0.054     13.079      0.000       0.602       0.814\n",
      "bay_store_62     -0.3718      0.054     -6.863      0.000      -0.478      -0.266\n",
      "sto_store_62      0.0584      0.066      0.878      0.380      -0.072       0.189\n",
      "tyl_store_64      0.7990      0.054     14.758      0.000       0.693       0.905\n",
      "adv_store_64      0.1788      0.054      3.303      0.001       0.073       0.285\n",
      "bay_store_64     -0.8005      0.054    -14.777      0.000      -0.907      -0.694\n",
      "sto_store_64      0.3084      0.066      4.640      0.000       0.178       0.439\n",
      "tyl_store_67      0.6721      0.054     12.410      0.000       0.566       0.778\n",
      "adv_store_67      0.0179      0.054      0.332      0.740      -0.088       0.124\n",
      "bay_store_67     -0.5611      0.054    -10.358      0.000      -0.667      -0.455\n",
      "sto_store_67      0.1359      0.066      2.044      0.041       0.006       0.266\n",
      "tyl_store_68      0.5154      0.054      9.519      0.000       0.409       0.621\n",
      "adv_store_68     -0.3177      0.054     -5.868      0.000      -0.424      -0.212\n",
      "bay_store_68     -1.1152      0.054    -20.586      0.000      -1.221      -1.009\n",
      "sto_store_68     -0.5862      0.066     -8.816      0.000      -0.716      -0.456\n",
      "tyl_store_70      0.7145      0.054     13.189      0.000       0.608       0.821\n",
      "adv_store_70      0.0054      0.054      0.099      0.921      -0.101       0.111\n",
      "bay_store_70     -0.7082      0.054    -13.068      0.000      -0.814      -0.602\n",
      "sto_store_70     -0.2683      0.066     -4.039      0.000      -0.399      -0.138\n",
      "tyl_store_71      0.6594      0.054     12.182      0.000       0.553       0.765\n",
      "adv_store_71     -0.1049      0.054     -1.938      0.053      -0.211       0.001\n",
      "bay_store_71     -0.8847      0.054    -16.331      0.000      -0.991      -0.779\n",
      "sto_store_71      0.1390      0.066      2.091      0.037       0.009       0.269\n",
      "tyl_store_72      0.7088      0.054     13.093      0.000       0.603       0.815\n",
      "adv_store_72     -0.1120      0.054     -2.069      0.039      -0.218      -0.006\n",
      "bay_store_72     -1.0183      0.054    -18.796      0.000      -1.125      -0.912\n",
      "sto_store_72     -0.4822      0.066     -7.255      0.000      -0.612      -0.352\n",
      "tyl_store_73      0.6846      0.054     12.641      0.000       0.578       0.791\n",
      "adv_store_73     -0.2495      0.054     -4.608      0.000      -0.356      -0.143\n",
      "bay_store_73     -0.7557      0.054    -13.947      0.000      -0.862      -0.649\n",
      "sto_store_73     -0.3903      0.066     -5.872      0.000      -0.521      -0.260\n",
      "tyl_store_74      0.8691      0.054     16.049      0.000       0.763       0.975\n",
      "adv_store_74     -0.0743      0.054     -1.373      0.170      -0.180       0.032\n",
      "bay_store_74     -0.5664      0.054    -10.456      0.000      -0.673      -0.460\n",
      "sto_store_74     -0.1239      0.066     -1.864      0.062      -0.254       0.006\n",
      "tyl_store_75      0.6468      0.054     11.947      0.000       0.541       0.753\n",
      "adv_store_75     -0.1903      0.054     -3.515      0.000      -0.296      -0.084\n",
      "bay_store_75     -0.9857      0.054    -18.194      0.000      -1.092      -0.879\n",
      "sto_store_75     -0.6612      0.066     -9.950      0.000      -0.791      -0.531\n",
      "tyl_store_76      0.3934      0.054      7.265      0.000       0.287       0.500\n",
      "adv_store_76     -0.3948      0.054     -7.293      0.000      -0.501      -0.289\n",
      "bay_store_76     -0.9387      0.054    -17.325      0.000      -1.045      -0.832\n",
      "sto_store_76     -0.2521      0.066     -3.792      0.000      -0.382      -0.122\n",
      "tyl_store_77      0.7860      0.054     14.514      0.000       0.680       0.892\n",
      "adv_store_77      0.2862      0.054      5.287      0.000       0.180       0.392\n",
      "bay_store_77     -0.8509      0.054    -15.704      0.000      -0.957      -0.745\n",
      "sto_store_77      0.0267      0.066      0.401      0.688      -0.104       0.157\n",
      "tyl_store_78      0.6090      0.054     11.246      0.000       0.503       0.715\n",
      "adv_store_78     -0.0990      0.054     -1.829      0.067      -0.205       0.007\n",
      "bay_store_78     -1.0356      0.054    -19.108      0.000      -1.142      -0.929\n",
      "sto_store_78     -0.0449      0.066     -0.676      0.499      -0.175       0.085\n",
      "tyl_store_80      0.8447      0.054     15.597      0.000       0.739       0.951\n",
      "adv_store_80      0.2531      0.054      4.675      0.000       0.147       0.359\n",
      "bay_store_80     -0.8302      0.054    -15.320      0.000      -0.936      -0.724\n",
      "sto_store_80      0.2031      0.066      3.055      0.002       0.073       0.333\n",
      "tyl_store_81      0.6184      0.054     11.420      0.000       0.512       0.725\n",
      "adv_store_81     -0.1853      0.054     -3.423      0.001      -0.291      -0.079\n",
      "bay_store_81     -0.9271      0.054    -17.111      0.000      -1.033      -0.821\n",
      "sto_store_81     -0.2940      0.066     -4.422      0.000      -0.424      -0.164\n",
      "tyl_store_83      0.7537      0.054     13.917      0.000       0.648       0.860\n",
      "adv_store_83     -0.0410      0.054     -0.758      0.448      -0.147       0.065\n",
      "bay_store_83     -0.8146      0.054    -15.030      0.000      -0.921      -0.708\n",
      "sto_store_83     -0.0539      0.066     -0.811      0.418      -0.184       0.076\n",
      "tyl_store_84      0.9851      0.054     18.193      0.000       0.879       1.091\n",
      "adv_store_84      0.1450      0.054      2.678      0.007       0.039       0.251\n",
      "bay_store_84     -0.6453      0.054    -11.912      0.000      -0.751      -0.539\n",
      "sto_store_84      0.0453      0.066      0.681      0.496      -0.085       0.176\n",
      "tyl_store_86      0.6143      0.054     11.345      0.000       0.508       0.720\n",
      "adv_store_86     -0.0231      0.054     -0.427      0.670      -0.129       0.083\n",
      "bay_store_86     -0.8611      0.054    -15.891      0.000      -0.967      -0.755\n",
      "sto_store_86      0.1023      0.066      1.539      0.124      -0.028       0.233\n",
      "tyl_store_89      0.0563      0.054      1.039      0.299      -0.050       0.162\n",
      "adv_store_89     -0.6249      0.054    -11.543      0.000      -0.731      -0.519\n",
      "bay_store_89     -1.1742      0.054    -21.670      0.000      -1.280      -1.068\n",
      "sto_store_89     -0.4623      0.066     -6.956      0.000      -0.593      -0.332\n",
      "tyl_store_90      0.4888      0.054      9.026      0.000       0.383       0.595\n",
      "adv_store_90     -0.5242      0.054     -9.683      0.000      -0.630      -0.418\n",
      "bay_store_90     -1.1031      0.054    -20.356      0.000      -1.209      -0.997\n",
      "sto_store_90     -0.5592      0.066     -8.417      0.000      -0.689      -0.429\n",
      "tyl_store_91      0.6674      0.054     12.325      0.000       0.561       0.774\n",
      "adv_store_91     -0.1930      0.054     -3.565      0.000      -0.299      -0.087\n",
      "bay_store_91     -0.9002      0.054    -16.614      0.000      -1.006      -0.794\n",
      "sto_store_91     -0.2450      0.066     -3.687      0.000      -0.375      -0.115\n",
      "tyl_store_92      0.6411      0.054     11.838      0.000       0.535       0.747\n",
      "adv_store_92     -0.3138      0.054     -5.797      0.000      -0.420      -0.208\n",
      "bay_store_92     -1.0480      0.054    -19.342      0.000      -1.154      -0.942\n",
      "sto_store_92     -0.0703      0.066     -1.058      0.290      -0.201       0.060\n",
      "tyl_store_93      0.6906      0.054     12.756      0.000       0.584       0.797\n",
      "adv_store_93      0.1991      0.054      3.677      0.000       0.093       0.305\n",
      "bay_store_93     -0.8515      0.054    -15.717      0.000      -0.958      -0.745\n",
      "sto_store_93     -0.1153      0.066     -1.736      0.083      -0.246       0.015\n",
      "tyl_store_94      0.8741      0.054     16.142      0.000       0.768       0.980\n",
      "adv_store_94      0.1805      0.054      3.335      0.001       0.074       0.287\n",
      "bay_store_94     -0.7730      0.054    -14.270      0.000      -0.879      -0.667\n",
      "sto_store_94      0.2932      0.066      4.411      0.000       0.163       0.424\n",
      "tyl_store_95      0.4982      0.054      9.202      0.000       0.392       0.604\n",
      "adv_store_95     -0.1250      0.054     -2.308      0.021      -0.231      -0.019\n",
      "bay_store_95     -0.7038      0.054    -12.991      0.000      -0.810      -0.598\n",
      "sto_store_95     -0.5184      0.066     -7.802      0.000      -0.649      -0.388\n",
      "tyl_store_97      0.8150      0.054     15.050      0.000       0.709       0.921\n",
      "adv_store_97      0.2227      0.054      4.113      0.000       0.117       0.329\n",
      "bay_store_97     -0.9246      0.054    -17.065      0.000      -1.031      -0.818\n",
      "sto_store_97      0.0314      0.066      0.473      0.636      -0.099       0.162\n",
      "tyl_store_98      0.9914      0.054     18.290      0.000       0.885       1.098\n",
      "adv_store_98      0.0722      0.054      1.334      0.182      -0.034       0.178\n",
      "bay_store_98     -0.6855      0.054    -12.633      0.000      -0.792      -0.579\n",
      "sto_store_98      0.3554      0.066      5.346      0.000       0.225       0.486\n",
      "tyl_store_100     0.9499      0.054     17.545      0.000       0.844       1.056\n",
      "adv_store_100    -0.0216      0.054     -0.400      0.689      -0.128       0.084\n",
      "bay_store_100    -0.9657      0.054    -17.824      0.000      -1.072      -0.860\n",
      "sto_store_100    -0.0473      0.066     -0.712      0.477      -0.178       0.083\n",
      "tyl_store_101     0.9220      0.054     17.012      0.000       0.816       1.028\n",
      "adv_store_101     0.3488      0.054      6.442      0.000       0.243       0.455\n",
      "bay_store_101    -0.6604      0.054    -12.174      0.000      -0.767      -0.554\n",
      "sto_store_101     0.3517      0.066      5.291      0.000       0.221       0.482\n",
      "tyl_store_102     0.8770      0.054     16.179      0.000       0.771       0.983\n",
      "adv_store_102    -0.0267      0.054     -0.494      0.621      -0.133       0.079\n",
      "bay_store_102    -0.7251      0.054    -13.362      0.000      -0.831      -0.619\n",
      "sto_store_102     0.3850      0.066      5.792      0.000       0.255       0.515\n",
      "tyl_store_103     0.8250      0.054     15.219      0.000       0.719       0.931\n",
      "adv_store_103    -0.0174      0.054     -0.321      0.749      -0.123       0.089\n",
      "bay_store_103    -1.3136      0.054    -24.211      0.000      -1.420      -1.207\n",
      "sto_store_103     0.7467      0.066     11.236      0.000       0.616       0.877\n",
      "tyl_store_104     1.0614      0.054     19.600      0.000       0.955       1.168\n",
      "adv_store_104     0.7032      0.054     12.990      0.000       0.597       0.809\n",
      "bay_store_104    -0.5883      0.054    -10.861      0.000      -0.695      -0.482\n",
      "sto_store_104     0.5695      0.066      8.568      0.000       0.439       0.700\n",
      "tyl_store_105     0.9408      0.054     17.356      0.000       0.835       1.047\n",
      "adv_store_105     0.1399      0.054      2.585      0.010       0.034       0.246\n",
      "bay_store_105    -0.7923      0.054    -14.601      0.000      -0.899      -0.686\n",
      "sto_store_105     0.4179      0.066      6.287      0.000       0.288       0.548\n",
      "tyl_store_106     0.7626      0.054     14.082      0.000       0.656       0.869\n",
      "adv_store_106     0.2723      0.054      5.029      0.000       0.166       0.378\n",
      "bay_store_106    -0.8416      0.054    -15.532      0.000      -0.948      -0.735\n",
      "sto_store_106     0.4471      0.066      6.728      0.000       0.317       0.577\n",
      "tyl_store_107     0.8331      0.054     15.384      0.000       0.727       0.939\n",
      "adv_store_107     0.0865      0.054      1.598      0.110      -0.020       0.193\n",
      "bay_store_107    -0.6924      0.054    -12.780      0.000      -0.799      -0.586\n",
      "sto_store_107    -0.0913      0.066     -1.374      0.169      -0.222       0.039\n",
      "tyl_store_109     1.0501      0.054     19.399      0.000       0.944       1.156\n",
      "adv_store_109     0.5790      0.054     10.694      0.000       0.473       0.685\n",
      "bay_store_109    -0.7206      0.054    -13.303      0.000      -0.827      -0.614\n",
      "sto_store_109    -0.1328      0.066     -1.999      0.046      -0.263      -0.003\n",
      "tyl_store_110     0.9639      0.054     17.803      0.000       0.858       1.070\n",
      "adv_store_110     0.3033      0.054      5.602      0.000       0.197       0.409\n",
      "bay_store_110    -0.7172      0.054    -13.240      0.000      -0.823      -0.611\n",
      "sto_store_110     0.3868      0.066      5.822      0.000       0.257       0.517\n",
      "tyl_store_111     0.2231      0.054      4.120      0.000       0.117       0.329\n",
      "adv_store_111    -0.9786      0.054    -18.074      0.000      -1.085      -0.872\n",
      "bay_store_111    -1.1098      0.054    -20.483      0.000      -1.216      -1.004\n",
      "sto_store_111    -1.1320      0.066    -17.030      0.000      -1.262      -1.002\n",
      "tyl_store_112     1.0956      0.054     20.215      0.000       0.989       1.202\n",
      "adv_store_112     0.6378      0.054     11.781      0.000       0.532       0.744\n",
      "bay_store_112    -0.9331      0.054    -17.199      0.000      -1.039      -0.827\n",
      "sto_store_112     0.3949      0.066      5.942      0.000       0.265       0.525\n",
      "tyl_store_113     0.5046      0.054      9.319      0.000       0.398       0.611\n",
      "adv_store_113    -0.0781      0.054     -1.443      0.149      -0.184       0.028\n",
      "bay_store_113    -0.8535      0.054    -15.751      0.000      -0.960      -0.747\n",
      "sto_store_113    -0.4132      0.066     -6.217      0.000      -0.543      -0.283\n",
      "tyl_store_114     0.7830      0.054     14.446      0.000       0.677       0.889\n",
      "adv_store_114    -0.1460      0.054     -2.697      0.007      -0.252      -0.040\n",
      "bay_store_114    -0.7401      0.054    -13.638      0.000      -0.847      -0.634\n",
      "sto_store_114    -0.0184      0.066     -0.277      0.782      -0.149       0.112\n",
      "tyl_store_115     1.0953      0.054     20.213      0.000       0.989       1.202\n",
      "adv_store_115     0.6239      0.054     11.525      0.000       0.518       0.730\n",
      "bay_store_115    -0.9223      0.054    -17.002      0.000      -1.029      -0.816\n",
      "sto_store_115     0.6525      0.066      9.816      0.000       0.522       0.783\n",
      "tyl_store_116     0.7799      0.054     14.402      0.000       0.674       0.886\n",
      "adv_store_116     0.1977      0.054      3.652      0.000       0.092       0.304\n",
      "bay_store_116    -0.7991      0.054    -14.750      0.000      -0.905      -0.693\n",
      "sto_store_116     0.2881      0.066      4.334      0.000       0.158       0.418\n",
      "tyl_store_117     0.7390      0.054     13.647      0.000       0.633       0.845\n",
      "adv_store_117     0.0621      0.054      1.146      0.252      -0.044       0.168\n",
      "bay_store_117    -0.9636      0.054    -17.787      0.000      -1.070      -0.857\n",
      "sto_store_117    -0.1977      0.066     -2.975      0.003      -0.328      -0.067\n",
      "tyl_store_118     0.5814      0.054     10.736      0.000       0.475       0.688\n",
      "adv_store_118    -0.0723      0.054     -1.336      0.181      -0.178       0.034\n",
      "bay_store_118    -0.9950      0.054    -18.367      0.000      -1.101      -0.889\n",
      "sto_store_118    -0.3973      0.066     -5.979      0.000      -0.528      -0.267\n",
      "tyl_store_119     0.5879      0.054     10.859      0.000       0.482       0.694\n",
      "adv_store_119     0.0481      0.054      0.888      0.375      -0.058       0.154\n",
      "bay_store_119    -1.0502      0.054    -19.384      0.000      -1.156      -0.944\n",
      "sto_store_119    -0.0562      0.066     -0.845      0.398      -0.186       0.074\n",
      "tyl_store_121     0.8863      0.054     16.352      0.000       0.780       0.993\n",
      "adv_store_121     0.3823      0.054      7.062      0.000       0.276       0.488\n",
      "bay_store_121    -0.5923      0.054    -10.918      0.000      -0.699      -0.486\n",
      "sto_store_121     0.4039      0.066      6.077      0.000       0.274       0.534\n",
      "tyl_store_122     1.0326      0.054     19.052      0.000       0.926       1.139\n",
      "adv_store_122     0.3807      0.054      7.032      0.000       0.275       0.487\n",
      "bay_store_122    -0.9470      0.054    -17.451      0.000      -1.053      -0.841\n",
      "sto_store_122     0.4629      0.066      6.965      0.000       0.333       0.593\n",
      "tyl_store_123     0.8347      0.054     15.416      0.000       0.729       0.941\n",
      "adv_store_123     0.0084      0.054      0.155      0.877      -0.098       0.115\n",
      "bay_store_123    -0.9885      0.054    -18.243      0.000      -1.095      -0.882\n",
      "sto_store_123     0.1176      0.066      1.769      0.077      -0.013       0.248\n",
      "==============================================================================\n",
      "Omnibus:                     2792.874   Durbin-Watson:                   1.102\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             3933.538\n",
      "Skew:                          -0.617   Prob(JB):                         0.00\n",
      "Kurtosis:                       3.962   Cond. No.                     3.43e+16\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 1.16e-27. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "# Third regression: fixed effects model\n",
    "X_fixed_effects = df1[['price_', 'prom_','cost_'] + [col for col in df1.columns if '_store' in col]]\n",
    "X_fixed_effects = sm.add_constant(X_fixed_effects)\n",
    "model_iv_fixed_effects = sm.OLS(Y, X_fixed_effects).fit()\n",
    "print(model_iv_fixed_effects.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
