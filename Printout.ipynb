{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **QUESTION 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################### Question 1 (Preparation and Data Import) ###################################\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from numpy.linalg import inv\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import chi2\n",
    "from scipy.stats import norm\n",
    "import pyblp\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "df1 = pd.read_csv(\"Sales_Hausman.csv\",sep=\",\")\n",
    "df2 = pd.read_csv(\"OTC_Demographics.csv\",sep=\"\\t\")\n",
    "df3 = pd.read_csv(\"OTC_Instruments.csv\",sep=\"\\t\")\n",
    "\n",
    "\n",
    "df1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################### Summary statistics for the table 1 ###################################\n",
    "\n",
    "# Calculate the total sales\n",
    "total_sales = df1['sales_'].sum()\n",
    "\n",
    "# Calculate the sales share for each brand\n",
    "brand_sales = df1.groupby('brand')['sales_'].sum()\n",
    "\n",
    "\n",
    "# Generate share variables for each brand\n",
    "share_1 = brand_sales[1] / total_sales\n",
    "share_2 = brand_sales[2] / total_sales\n",
    "share_3 = brand_sales[3] / total_sales\n",
    "share_4 = brand_sales[4] / total_sales\n",
    "share_5 = brand_sales[5] / total_sales\n",
    "share_6 = brand_sales[6] / total_sales\n",
    "share_7 = brand_sales[7] / total_sales\n",
    "share_8 = brand_sales[8] / total_sales\n",
    "share_9 = brand_sales[9] / total_sales\n",
    "share_10 = brand_sales[10] / total_sales\n",
    "share_11 = brand_sales[11] / total_sales\n",
    "\n",
    "# Print the share variables\n",
    "print(f\"share_1: {share_1}\")\n",
    "print(f\"share_2: {share_2}\")\n",
    "print(f\"share_3: {share_3}\")\n",
    "print(f\"share_4: {share_4}\")\n",
    "print(f\"share_5: {share_5}\")\n",
    "print(f\"share_6: {share_6}\")\n",
    "print(f\"share_7: {share_7}\")\n",
    "print(f\"share_8: {share_8}\")\n",
    "print(f\"share_9: {share_9}\")\n",
    "print(f\"share_10: {share_10}\")\n",
    "print(f\"share_11: {share_11}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dummy variables for adv, tyl, bay, and sto\n",
    "df1['adv'] = df1['brand'].isin([4, 5, 6]).astype(int)\n",
    "df1['tyl'] = df1['brand'].isin([1, 2, 3]).astype(int)\n",
    "df1['bay'] = df1['brand'].isin([7, 8, 9]).astype(int)\n",
    "df1['sto'] = df1['brand'].isin([10, 11]).astype(int)\n",
    "\n",
    "# Display the first few rows to verify\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################### Weighted average price and cost for each brand #########################################\n",
    "\n",
    "for i in range(1, 12):\n",
    "    weighted_avg_price_i = (df1[df1['brand'] == i]['sales_'] * df1[df1['brand'] == i]['price_']).sum() / df1[df1['brand'] == i]['sales_'].sum()\n",
    "    print(f\"weighted_avg_price_{i}: {weighted_avg_price_i}\")\n",
    "\n",
    "# Calculate the weighted average cost (wholesale price) for each brand\n",
    "\n",
    "for i in range(1, 12):\n",
    "    weighted_avg_cost_i = (df1[df1['brand'] == i]['sales_'] * df1[df1['brand'] == i]['cost_']).sum() / df1[df1['brand'] == i]['sales_'].sum()\n",
    "    print(f\"weighted_avg_cost_{i}: {weighted_avg_cost_i}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **QUESTION 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################### Question 2 (Data Preparation) #######################################\n",
    "\n",
    "df1['sales_per_count'] = df1['sales_'] / df1['count']\n",
    "\n",
    "df1['share_0'] = 1 - df1.groupby(['store', 'week'])['sales_per_count'].transform('sum')\n",
    "\n",
    "df1['Y'] = np.log(df1['sales_per_count']) - np.log(df1['share_0'])\n",
    "\n",
    "df1['market_id'] = df1['store'].astype(str) + '_' + df1['week'].astype(str)\n",
    "df1.head()\n",
    "\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **QUESTION 2a**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################### OLS Q2.(a) #####################################\n",
    "\n",
    "# Define the independent variables\n",
    "X = df1[['prom_', 'price_']]\n",
    "\n",
    "# Add a constant to the independent variables\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Define the dependent variable\n",
    "Y = df1['Y']\n",
    "\n",
    "# Fit the regression model\n",
    "model = sm.OLS(Y, X).fit()\n",
    "\n",
    "# Print the regression results\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **QUESTION 2b**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################## Generate Dummies for Product Type ########################################\n",
    "\n",
    "# Create dummy variables\n",
    "df1['tyl'] = df1['brand'].isin([1, 2, 3]).astype(int)\n",
    "df1['adv'] = df1['brand'].isin([4, 5, 6]).astype(int)\n",
    "df1['bay'] = df1['brand'].isin([7, 8, 9]).astype(int)\n",
    "df1['sto'] = df1['brand'].isin([10, 11]).astype(int)\n",
    "\n",
    "# Display the first few rows to verify\n",
    "df1.head()\n",
    "\n",
    "# Create separate dummy variables for each brand\n",
    "for brand in df1['brand'].unique():\n",
    "    df1[f'brand_{brand}'] = (df1['brand'] == brand).astype(int)\n",
    "\n",
    "# Display the first few rows to verify\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################### OLS Q2.(b) #####################################\n",
    "\n",
    "# Define the independent variables including the dummy variables\n",
    "X = df1[['price_', 'prom_', 'brand_1', 'brand_2', 'brand_3', 'brand_4', 'brand_5', 'brand_6', 'brand_7', 'brand_8', 'brand_9', 'brand_10', 'brand_11']] \n",
    "\n",
    "\n",
    "# Add a constant to the independent variables\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Define the dependent variable\n",
    "Y = df1['Y']\n",
    "\n",
    "# Fit the regression model\n",
    "model_with_dummies = sm.OLS(Y, X).fit()\n",
    "\n",
    "# Print the regression results\n",
    "print(model_with_dummies.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **QUESTION 2c**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################### Fixed Effects for Everything ###############################################\n",
    "\n",
    "# Generate new variables for each unique combination of store number and tyl, adv, bay, and sto\n",
    "for store in df1['store'].unique():\n",
    "    df1[f'tyl_store_{store}'] = df1['tyl'] * (df1['store'] == store).astype(int)\n",
    "    df1[f'adv_store_{store}'] = df1['adv'] * (df1['store'] == store).astype(int)\n",
    "    df1[f'bay_store_{store}'] = df1['bay'] * (df1['store'] == store).astype(int)\n",
    "    df1[f'sto_store_{store}'] = df1['sto'] * (df1['store'] == store).astype(int)\n",
    "\n",
    "# Display the first few rows to verify\n",
    "df1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################### OLS Q2.(c) Fixed Effects Model #####################################\n",
    "\n",
    "# Define the independent variables including the dummy variables\n",
    "X_fixed_effects = df1[['price_', 'prom_'] + [col for col in df1.columns if '_store' in col]]\n",
    "\n",
    "\n",
    "# Add a constant to the independent variables\n",
    "X_fixed_effects = sm.add_constant(X_fixed_effects)\n",
    "\n",
    "# Define the dependent variable\n",
    "Y = df1['Y']\n",
    "\n",
    "# Fit the regression model\n",
    "fixed_effects_model = sm.OLS(Y, X_fixed_effects).fit()\n",
    "\n",
    "\n",
    "# Print the regression results\n",
    "print(fixed_effects_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **QUESTION 2d**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################### OLS Q2.(d) #####################################\n",
    "\n",
    "# Define the independent variables and the instrument\n",
    "X = df1[['prom_']]\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "instrument = df1['cost_']\n",
    "\n",
    "# First stage: regress price_ on the instrument and other exogenous variables\n",
    "first_stage = sm.OLS(df1['price_'], sm.add_constant(instrument)).fit()\n",
    "df1['price_hat'] = first_stage.fittedvalues\n",
    "\n",
    "# Second stage: regress Y on the predicted values of price_ and other exogenous variables\n",
    "X['price_hat'] = df1['price_hat']\n",
    "second_stage = sm.OLS(Y, X).fit()\n",
    "\n",
    "# Print the regression results\n",
    "print(second_stage.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################### IV with Dummies #####################################\n",
    "\n",
    "# Define the independent variables and the instrument\n",
    "X = df1[['prom_', 'brand_1', 'brand_2', 'brand_3', 'brand_4', 'brand_5', 'brand_6', 'brand_7', 'brand_8', 'brand_9', 'brand_10', 'brand_11']]\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "instrument = df1['cost_']\n",
    "\n",
    "# First stage: regress price_ on the instrument and other exogenous variables\n",
    "first_stage = sm.OLS(df1['price_'], sm.add_constant(instrument)).fit()\n",
    "df1['price_hat'] = first_stage.predict()\n",
    "\n",
    "# Second stage: regress Y on the predicted values of price_ and other exogenous variables\n",
    "X['price_hat'] = df1['price_hat']\n",
    "second_stage = sm.OLS(Y, X).fit()\n",
    "\n",
    "# Print the regression results\n",
    "print(second_stage.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################### IV with Fixed Effects #####################################\n",
    "\n",
    "# Define the independent variables and the instrument\n",
    "X_fixed_effects = df1[['prom_'] + [col for col in df1.columns if '_store' in col]]\n",
    "X_fixed_effects = sm.add_constant(X_fixed_effects)\n",
    "instrument = df1['cost_']\n",
    "\n",
    "# First stage: regress price_ on the instrument and other exogenous variables\n",
    "first_stage = sm.OLS(df1['price_'], sm.add_constant(instrument)).fit()\n",
    "df1['price_hat'] = first_stage.fittedvalues\n",
    "\n",
    "# Second stage: regress Y on the predicted values of price_ and other exogenous variables\n",
    "X_fixed_effects['price_hat'] = df1['price_hat']\n",
    "model_iv_fixed_effects = sm.OLS(Y, X_fixed_effects).fit()\n",
    "\n",
    "# Print the regression results\n",
    "print(model_iv_fixed_effects.summary())\n",
    "\n",
    "\n",
    "#print t statistic (-57.541554716524786) \n",
    "print(model_iv_fixed_effects.tvalues['price_hat'])\n",
    "#print confidence interval (-0.158776 -0.148316) for \"price_\" coefficient\n",
    "print(model_iv_fixed_effects.conf_int(alpha=0.05, cols=None))\n",
    "\n",
    "# Print the coefficient for price\n",
    "print(f\"Price coefficient: {model_iv_fixed_effects.params['price_hat']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **QUESTION 2e**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################# Code used to generate Hausman Variable #################################################\n",
    "### In order to save time, I added this column to the initial data set and saved it as a new CSV file. ###\n",
    "# Define a function to calculate the Hausman variable\n",
    "#def calculate_hausman(row):\n",
    "    #other_stores = df1[(df1['store'] != row['store']) & (df1['week'] == row['week']) & (df1['brand'] == row['brand'])]\n",
    "    #if not other_stores.empty:\n",
    "    #    weighted_avg_price_other_stores = (other_stores['sales_'] * other_stores['price_']).sum() / other_stores['sales_'].sum()\n",
    "    #else:\n",
    "    #   weighted_avg_price_other_stores = np.nan\n",
    "    #return weighted_avg_price_other_stores\n",
    "\n",
    "# Apply the function to each row in the dataframe\n",
    "#['Hausman'] = df1.apply(calculate_hausman, axis=1)\n",
    "\n",
    "# Display the first few rows to verify\n",
    "#df1.head()\n",
    "\n",
    "# Add the Hausman variable to the original dataframe\n",
    "\n",
    "#dfHausman = pd.read_csv(\"OTC_Sales.csv\",sep=\"\\t\")\n",
    "#dfHausman['Hausman'] = df1['Hausman']\n",
    "\n",
    "# Save the updated dataframe to a new CSV file\n",
    "#dfHausman.to_csv(\"Sales_Hausman.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First stage: regress price_ on the instrument Hausman\n",
    "first_stage_hausman = sm.OLS(df1['price_'], sm.add_constant(df1['Hausman'])).fit()\n",
    "df1['price_hat_hausman'] = first_stage_hausman.fittedvalues\n",
    "\n",
    "# Second stage: regress Y on the predicted values of price_ and prom_\n",
    "X_hausman = df1[['prom_']]\n",
    "X_hausman = sm.add_constant(X_hausman)\n",
    "X_hausman['price_hat_hausman'] = df1['price_hat_hausman']\n",
    "second_stage_hausman = sm.OLS(Y, X_hausman).fit()\n",
    "\n",
    "# Print the regression results\n",
    "print(second_stage_hausman.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the independent variables including the dummy variables\n",
    "X_dummies_hausman = df1[['prom_', 'price_hat_hausman', 'brand_1', 'brand_2', 'brand_3', 'brand_4', 'brand_5', 'brand_6', 'brand_7', 'brand_8', 'brand_9', 'brand_10', 'brand_11']]\n",
    "\n",
    "# Add a constant to the independent variables\n",
    "X_dummies_hausman = sm.add_constant(X_dummies_hausman)\n",
    "\n",
    "# Define the dependent variable\n",
    "Y = df1['Y']\n",
    "\n",
    "# Fit the regression model\n",
    "second_stage_dummies_hausman = sm.OLS(Y, X_dummies_hausman).fit()\n",
    "\n",
    "# Print the regression results\n",
    "print(second_stage_dummies_hausman.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the independent variables and the instrument\n",
    "X_fixed_effects_hausman = df1[['prom_'] + [col for col in df1.columns if '_store' in col]]\n",
    "X_fixed_effects_hausman = sm.add_constant(X_fixed_effects_hausman)\n",
    "instrument_hausman = df1['Hausman']\n",
    "\n",
    "# First stage: regress price_ on the instrument Hausman and other exogenous variables\n",
    "first_stage_hausman = sm.OLS(df1['price_'], sm.add_constant(instrument_hausman)).fit()\n",
    "df1['price_hat_hausman'] = first_stage_hausman.fittedvalues\n",
    "\n",
    "# Second stage: regress Y on the predicted values of price_ and other exogenous variables\n",
    "X_fixed_effects_hausman['price_hat_hausman'] = df1['price_hat_hausman']\n",
    "model_iv_fixed_effects_hausman = sm.OLS(Y, X_fixed_effects_hausman).fit()\n",
    "\n",
    "# Print the regression results\n",
    "print(model_iv_fixed_effects_hausman.summary())\n",
    "\n",
    "# Print the coefficient for price\n",
    "print(f\"Price coefficient: {model_iv_fixed_effects_hausman.params['price_hat_hausman']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **QUESTION 2g**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the coefficient of price from model (a)\n",
    "price_coefficient = -0.0514\n",
    "\n",
    "# Calculate the elasticity\n",
    "df1['elasticity'] = price_coefficient * df1['price_'] * (1 - df1['sales_per_count'])\n",
    "\n",
    "# Display the first few rows to verify\n",
    "df1.head()\n",
    "\n",
    "# Now calculate the weighted average of elasticity per product (tyl, adv, bay, sto)\n",
    "elasticity_tyl = (df1['sales_'] * df1['elasticity'] * df1['tyl']).sum() / df1['sales_'].sum()\n",
    "elasticity_adv = (df1['sales_'] * df1['elasticity'] * df1['adv']).sum() / df1['sales_'].sum()\n",
    "elasticity_bay = (df1['sales_'] * df1['elasticity'] * df1['bay']).sum() / df1['sales_'].sum()\n",
    "elasticity_sto = (df1['sales_'] * df1['elasticity'] * df1['sto']).sum() / df1['sales_'].sum()\n",
    "\n",
    "# Print the elasticity for each product\n",
    "print(f\"Elasticity for tyl: {elasticity_tyl}\")\n",
    "print(f\"Elasticity for adv: {elasticity_adv}\")\n",
    "print(f\"Elasticity for bay: {elasticity_bay}\")\n",
    "print(f\"Elasticity for sto: {elasticity_sto}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the coefficient of price from model (b)\n",
    "price_coefficient_b = model_with_dummies.params['price_']\n",
    "print(price_coefficient_b)\n",
    "# Calculate the elasticity\n",
    "df1['elasticity_b'] = price_coefficient_b * df1['price_'] * (1 - df1['sales_per_count'])\n",
    "\n",
    "# Display the first few rows to verify\n",
    "df1.head()\n",
    "\n",
    "# Now calculate the weighted average of elasticity per product (tyl, adv, bay, sto)\n",
    "elasticity_tyl_b = (df1['sales_'] * df1['elasticity_b'] * df1['tyl']).sum() / df1['sales_'].sum()\n",
    "elasticity_adv_b = (df1['sales_'] * df1['elasticity_b'] * df1['adv']).sum() / df1['sales_'].sum()\n",
    "elasticity_bay_b = (df1['sales_'] * df1['elasticity_b'] * df1['bay']).sum() / df1['sales_'].sum()\n",
    "elasticity_sto_b = (df1['sales_'] * df1['elasticity_b'] * df1['sto']).sum() / df1['sales_'].sum()\n",
    "\n",
    "# Print the elasticity for each product\n",
    "print(f\"Elasticity for tyl (part b): {elasticity_tyl_b}\")\n",
    "print(f\"Elasticity for adv (part b): {elasticity_adv_b}\")\n",
    "print(f\"Elasticity for bay (part b): {elasticity_bay_b}\")\n",
    "print(f\"Elasticity for sto (part b): {elasticity_sto_b}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the coefficient of price from model (c)\n",
    "price_coefficient_c = fixed_effects_model.params['price_']\n",
    "\n",
    "print(price_coefficient_c)\n",
    "\n",
    "# Calculate the elasticity\n",
    "df1['elasticity_c'] = price_coefficient_c * df1['price_'] * (1 - df1['sales_per_count'])\n",
    "\n",
    "# Display the first few rows to verify\n",
    "df1.head()\n",
    "\n",
    "# Now calculate the weighted average of elasticity per product (tyl, adv, bay, sto)\n",
    "elasticity_tyl_c = (df1['sales_'] * df1['elasticity_c'] * df1['tyl']).sum() / df1['sales_'].sum()\n",
    "elasticity_adv_c = (df1['sales_'] * df1['elasticity_c'] * df1['adv']).sum() / df1['sales_'].sum()\n",
    "elasticity_bay_c = (df1['sales_'] * df1['elasticity_c'] * df1['bay']).sum() / df1['sales_'].sum()\n",
    "elasticity_sto_c = (df1['sales_'] * df1['elasticity_c'] * df1['sto']).sum() / df1['sales_'].sum()\n",
    "\n",
    "# Print the elasticity for each product\n",
    "print(f\"Elasticity for tyl (part c): {elasticity_tyl_c}\")\n",
    "print(f\"Elasticity for adv (part c): {elasticity_adv_c}\")\n",
    "print(f\"Elasticity for bay (part c): {elasticity_bay_c}\")\n",
    "print(f\"Elasticity for sto (part c): {elasticity_sto_c}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **QUESTION 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################### Data Preparation for Question 3 #########################################\n",
    "\n",
    "# Generate a single dummy variable for brands 1 to 9\n",
    "df1['brand_'] = df1['brand'].isin(range(1, 10)).astype(int)\n",
    "\n",
    "df_merged = pd.merge(df1, df2, on=['store'], how='left')\n",
    "df_merged = pd.merge(df_merged, df3, on=['store','week','brand'], how='left')\n",
    "\n",
    "df_merged['cost_']=df_merged['cost__x'].fillna(0)\n",
    "\n",
    "df_merged.drop(columns=['cost__x'], inplace=True)\n",
    "\n",
    "# Generate a value randomly drawn from N(0,1) for each observation\n",
    "df_merged['V'] = np.random.normal(0, 1, df_merged.shape[0])\n",
    "\n",
    "\n",
    "# Generate PI variable which is the product of price_ and e^(income)\n",
    "df_merged['PI'] = df_merged['price_'] * df_merged['income']\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "########################################## Contraction Mapping ###################################################\n",
    "#The model that I'm considering is u=beta*prom_+alpha*price_+sigma_i*PI+beta_i*V*brand_+Zeta+epsilon of the U_i into\n",
    "# two parts (excluding epsilon): delta_i=beta*prom__i+alpha*price__i+sigma_i*PI_i+Zeta_i and mu_i=sigma_b*V_i*brand__i.\n",
    "# define 0_sigma_i=integral (e^(delta_i+mu_i))/(1+sum_{k}e^(delta_k+mu_k))f(v)dv where f is the density of standard normal\n",
    "# and V is the vector 'V' from out dataframe. We will need numerical integration of this in the end.  Now the steps are, \n",
    "# fix sigma_b at some level and start the procedure: pick 0_delta which is the vector of 0_delta_i's where 0_delta_i for \n",
    "# a given individual is its corresponding value of Y variable from the data frame. Then update 0_delta vector to 1_delta \n",
    "# vector the following way-> 1_delta_i=0_delta_i+log(sales_per_count_i)-log(0_sigma_i). \n",
    "# continue this process until the distance between the VECTORS t_delta and {t+1}_delta converges to 0 (up to 3 decimal points) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Calculate the initial delta\n",
    "delta_0 = df_merged['Y']\n",
    "df_merged['delta_0'] = delta_0\n",
    "\n",
    "# Generate mu for each entry\n",
    "sigma_b = 0.00000001\n",
    "df_merged['mu'] = sigma_b * df_merged['V'] * df_merged['brand_']\n",
    "\n",
    "# Calculate sigma_0\n",
    "sigma_0denom = 1 + np.exp(df_merged['delta_0'] + df_merged['mu']).sum()\n",
    "sigma_0numer = np.exp(df_merged['delta_0'] + df_merged['mu'])\n",
    "sigma_0 = sigma_0numer / sigma_0denom\n",
    "df_merged['sigma_0'] = sigma_0\n",
    "\n",
    "# Update delta\n",
    "delta_1 = delta_0 + np.log(df_merged['sales_per_count']) - np.log(sigma_0)\n",
    "df_merged['delta_1'] = delta_1\n",
    "\n",
    "# Calculate sigma_1\n",
    "\n",
    "sigma_1denom = 1 + np.exp(df_merged['delta_1'] + df_merged['mu']).sum()\n",
    "sigma_1numer = np.exp(df_merged['delta_1'] + df_merged['mu'])\n",
    "sigma_1 = sigma_1numer / sigma_1denom\n",
    "\n",
    "df_merged['sigma_1'] = sigma_1\n",
    "\n",
    "\n",
    "# update delta\n",
    "\n",
    "delta_2 = delta_1 + np.log(df_merged['sales_per_count']) - np.log(sigma_1)\n",
    "df_merged['delta_2'] = delta_2\n",
    "\n",
    "# Calculate sigma_2\n",
    "\n",
    "sigma_2denom = 1 + np.exp(df_merged['delta_2'] + df_merged['mu']).sum()\n",
    "sigma_2numer = np.exp(df_merged['delta_2'] + df_merged['mu'])\n",
    "sigma_2 = sigma_2numer / sigma_2denom\n",
    "\n",
    "df_merged['sigma_2'] = sigma_2\n",
    "\n",
    "\n",
    "# Continue iterating this way 5-6 times\n",
    "\n",
    "for t in range(3, 8):\n",
    "    # Calculate sigma_t\n",
    "    sigma_t_denom = 1 + np.exp(df_merged[f'delta_{t-1}'] + df_merged['mu']).sum()\n",
    "    sigma_t_numer = np.exp(df_merged[f'delta_{t-1}'] + df_merged['mu'])\n",
    "    sigma_t = sigma_t_numer / sigma_t_denom\n",
    "    df_merged[f'sigma_{t}'] = sigma_t\n",
    "\n",
    "    # Update delta_t\n",
    "    delta_t = df_merged[f'delta_{t-1}'] + np.log(df_merged['sales_per_count']) - np.log(sigma_t)\n",
    "    df_merged[f'delta_{t}'] = delta_t\n",
    "\n",
    "# Display the final delta and sigma values\n",
    "df_merged[[f'delta_{t}' for t in range(8)] + [f'sigma_{t}' for t in range(8)]].head()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **PYBLP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################    GENERAL  METHOD      #############################\n",
    "\n",
    "import pyblp\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "product_data = df_merged.copy()\n",
    "\n",
    "product_data['market_ids'] = product_data['market_id']\n",
    "\n",
    "product_data['prices']=product_data['price_']\n",
    "\n",
    "product_data['shares']=product_data['sales_per_count']  \n",
    "\n",
    "demand_instruments=product_data[['cost_','avoutprice', 'pricestore1', 'pricestore2', 'pricestore3', 'pricestore4', 'pricestore5', 'pricestore6', 'pricestore7', 'pricestore8', 'pricestore9', 'pricestore10', 'pricestore11', 'pricestore12', 'pricestore13', 'pricestore14', 'pricestore15', 'pricestore16', 'pricestore17', 'pricestore18', 'pricestore19', 'pricestore20', 'pricestore21', 'pricestore22', 'pricestore23', 'pricestore24', 'pricestore25', 'pricestore26', 'pricestore27', 'pricestore28', 'pricestore29', 'pricestore30']]\n",
    "\n",
    "\n",
    "X1_formulation = pyblp.Formulation('0 + prices + PI + prom_ ', absorb='C(brand)')\n",
    "X2_formulation = pyblp.Formulation('1 + brand_')\n",
    "product_formulations = (X1_formulation, X2_formulation)\n",
    "product_formulations\n",
    "\n",
    "pr_integration = pyblp.Integration('product', size=5)\n",
    "\n",
    "\n",
    "problem = pyblp.Problem(product_formulations, product_data,  integration=pr_integration, )\n",
    "problem\n",
    "\n",
    "logit_results = problem.solve(sigma=np.eye(2))\n",
    "logit_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################### BLP with instruments ###########################################\n",
    "\n",
    "import pyblp\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Prepare product data\n",
    "product_data = df_merged.copy()\n",
    "product_data['priceincome'] = product_data['PI']\n",
    "product_data['firm_ids'] = product_data['brand']   # older PyBLP requires this when using X3\n",
    "product_data['market_ids'] = product_data['market_id']\n",
    "product_data['shares'] = product_data['sales_per_count']\n",
    "\n",
    "# IMPORTANT: rename price_ -> 'prices' (plural)\n",
    "product_data['prices'] = product_data['price_']\n",
    "\n",
    "# If you want a random brand dummy:\n",
    "product_data['brand_dummy'] = (\n",
    "    product_data[['brand_1','brand_2','brand_3','brand_4',\n",
    "                  'brand_5','brand_6','brand_7','brand_8',\n",
    "                  'brand_9','brand_10','brand_11']]\n",
    "    .max(axis=1)\n",
    ")\n",
    "\n",
    "# 2. Define X1, X2, X3 as separate Formulations\n",
    "X1_formulation = pyblp.Formulation(\n",
    "    '0 + prices + prom_ + brand_1 + brand_2 + brand_3 + brand_4 + '\n",
    "    'brand_5 + brand_6 + brand_7 + brand_8 + brand_9 + brand_10 + brand_11 + PI'\n",
    ")\n",
    "\n",
    "X2_formulation = pyblp.Formulation('0 + brand_')\n",
    "\n",
    "X3_formulation = pyblp.Formulation(\n",
    "    '0 + cost_ + avoutprice + '\n",
    "    'pricestore1 + pricestore2 + pricestore3 + pricestore4 + '\n",
    "    'pricestore5 + pricestore6 + pricestore7 + pricestore8 + '\n",
    "    'pricestore9 + pricestore10 + pricestore11 + pricestore12 + '\n",
    "    'pricestore13 + pricestore14 + pricestore15 + pricestore16 + '\n",
    "    'pricestore17 + pricestore18 + pricestore19 + pricestore20 + '\n",
    "    'pricestore21 + pricestore22 + pricestore23 + pricestore24 + '\n",
    "    'pricestore25 + pricestore26 + pricestore27 + pricestore28 + '\n",
    "    'pricestore29 + pricestore30'\n",
    ")\n",
    "\n",
    "# 3. Agent data, 1 row per market for integration size=1\n",
    "agent_data = (\n",
    "    product_data[['market_ids', 'income']]\n",
    "    .drop_duplicates('market_ids')\n",
    "    .copy()\n",
    ")\n",
    "agent_data['weights'] = 1\n",
    "\n",
    "agent_formulation = pyblp.Formulation('0 + income')\n",
    "\n",
    "# 4. Pass formulations as SEPARATE positional arguments\n",
    "problem = pyblp.Problem(\n",
    "    product_formulations=(X1_formulation, X2_formulation, X3_formulation),\n",
    "    product_data=product_data,\n",
    "    agent_formulation=agent_formulation,\n",
    "    agent_data=agent_data,\n",
    "    integration=pyblp.Integration('monte_carlo', size=1)\n",
    ")\n",
    "\n",
    "# Check that X2 is recognized\n",
    "print(\"X2 recognized by PyBLP:\\n\", problem.products.X2)\n",
    "\n",
    "bfgs = pyblp.Optimization('bfgs', {'gtol': 1e-4})\n",
    "\n",
    "# 5. Solve\n",
    "results = problem.solve(sigma=np.ones((1,1)), pi=np.ones((1,1)), beta=np.ones((14,1)), optimization=bfgs)  # don't pass rfp=True in older versions\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################## BLP without instruments #########################################\n",
    "\n",
    "import pyblp\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Prepare product data\n",
    "product_data = df_merged.copy()\n",
    "product_data['priceincome'] = product_data['PI']\n",
    "product_data['firm_ids'] = product_data['brand']   # older PyBLP requires this when using X3\n",
    "product_data['market_ids'] = product_data['market_id']\n",
    "product_data['shares'] = product_data['sales_per_count']\n",
    "\n",
    "# IMPORTANT: rename price_ -> 'prices' (plural)\n",
    "product_data['prices'] = product_data['price_']\n",
    "\n",
    "# If you want a random brand dummy:\n",
    "product_data['brand_dummy'] = (\n",
    "    product_data[['brand_1','brand_2','brand_3','brand_4',\n",
    "                  'brand_5','brand_6','brand_7','brand_8',\n",
    "                  'brand_9','brand_10','brand_11']]\n",
    "    .max(axis=1)\n",
    ")\n",
    "\n",
    "# 2. Define X1, X2, X3 as separate Formulations\n",
    "X1_formulation = pyblp.Formulation(\n",
    "    '0 + prices + prom_ + brand_1 + brand_2 + brand_3 + brand_4 + '\n",
    "    'brand_5 + brand_6 + brand_7 + brand_8 + brand_9 + brand_10 + brand_11 + PI'\n",
    ")\n",
    "\n",
    "X2_formulation = pyblp.Formulation('0 + brand_')\n",
    "\n",
    "X3_formulation = pyblp.Formulation(\n",
    "    '0 + cost_ + avoutprice + '\n",
    "    'pricestore1 + pricestore2 + pricestore3 + pricestore4 + '\n",
    "    'pricestore5 + pricestore6 + pricestore7 + pricestore8 + '\n",
    "    'pricestore9 + pricestore10 + pricestore11 + pricestore12 + '\n",
    "    'pricestore13 + pricestore14 + pricestore15 + pricestore16 + '\n",
    "    'pricestore17 + pricestore18 + pricestore19 + pricestore20 + '\n",
    "    'pricestore21 + pricestore22 + pricestore23 + pricestore24 + '\n",
    "    'pricestore25 + pricestore26 + pricestore27 + pricestore28 + '\n",
    "    'pricestore29 + pricestore30'\n",
    ")\n",
    "\n",
    "# 3. Agent data, 1 row per market for integration size=1\n",
    "agent_data = (\n",
    "    product_data[['market_ids', 'income']]\n",
    "    .drop_duplicates('market_ids')\n",
    "    .copy()\n",
    ")\n",
    "agent_data['weights'] = 1\n",
    "\n",
    "agent_formulation = pyblp.Formulation('0 + income')\n",
    "\n",
    "# 4. Pass formulations as SEPARATE positional arguments\n",
    "problem = pyblp.Problem(\n",
    "    product_formulations=(X1_formulation, X2_formulation),\n",
    "    product_data=product_data,\n",
    "    agent_formulation=agent_formulation,\n",
    "    agent_data=agent_data,\n",
    "    integration=pyblp.Integration('monte_carlo', size=1)\n",
    ")\n",
    "\n",
    "# Check that X2 is recognized\n",
    "print(\"X2 recognized by PyBLP:\\n\", problem.products.X2)\n",
    "\n",
    "bfgs = pyblp.Optimization('bfgs', {'gtol': 1e-4})\n",
    "\n",
    "# 5. Solve\n",
    "results = problem.solve(sigma=np.ones((1,1)), pi=np.ones((1,1)), beta=np.ones((14,1)), optimization=bfgs)  # don't pass rfp=True in older versions\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **QUESTION 3b & c**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## Data Preparation ########################\n",
    "\n",
    "df_merged['price_coef'] = df_merged['income'] * 0.296 - 3.65\n",
    "df_merged.head()\n",
    "\n",
    "summary_stats = df_merged['price_coef'].describe()\n",
    "print(summary_stats)\n",
    "\n",
    "price_coefficient_b * df1['price_'] * (1 - df1['sales_per_count'])\n",
    "\n",
    "df_merged['own_price_elasticity'] = df_merged['price_coef'] * df_merged['price_'] * (1 - df_merged['sales_per_count'])\n",
    "\n",
    "# Filter the data for store 9 in week 10\n",
    "store_week_data = df_merged[(df_merged['store'] == 9) & (df_merged['week'] == 10)]\n",
    "\n",
    "#elasticity of Tylenol\n",
    "elasticity_tyl = (store_week_data['sales_'] * store_week_data['own_price_elasticity'] * store_week_data['tyl']).sum() / store_week_data['sales_'].sum()\n",
    "print(f\"Elasticity for Tylenol: {elasticity_tyl}\")\n",
    "\n",
    "#elasticity of Advil\n",
    "elasticity_adv = (store_week_data['sales_'] * store_week_data['own_price_elasticity'] * store_week_data['adv']).sum() / store_week_data['sales_'].sum()\n",
    "print(f\"Elasticity for Advil: {elasticity_adv}\")\n",
    "\n",
    "#elasticity of Bayer\n",
    "elasticity_bay = (store_week_data['sales_'] * store_week_data['own_price_elasticity'] * store_week_data['bay']).sum() / store_week_data['sales_'].sum()\n",
    "print(f\"Elasticity for Bayer: {elasticity_bay}\")\n",
    "\n",
    "#elasticity of Store Brand\n",
    "elasticity_sto = (store_week_data['sales_'] * store_week_data['own_price_elasticity'] * store_week_data['sto']).sum() / store_week_data['sales_'].sum()\n",
    "print(f\"Elasticity for Store Brand: {elasticity_sto}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the data for store 9 in week 10\n",
    "store_week_data = df_merged[(df_merged['store'] == 9) & (df_merged['week'] == 10)]\n",
    "\n",
    "# Define the goods and their corresponding shares and prices\n",
    "goods = ['tyl', 'adv', 'bay', 'sto']\n",
    "shares = {\n",
    "    'tyl': share_1,\n",
    "    'adv': share_2,\n",
    "    'bay': share_3,\n",
    "    'sto': share_4\n",
    "}\n",
    "prices = {\n",
    "    'tyl': store_week_data[store_week_data['tyl'] == 1]['price_'].mean(),\n",
    "    'adv': store_week_data[store_week_data['adv'] == 1]['price_'].mean(),\n",
    "    'bay': store_week_data[store_week_data['bay'] == 1]['price_'].mean(),\n",
    "    'sto': store_week_data[store_week_data['sto'] == 1]['price_'].mean()\n",
    "}\n",
    "\n",
    "# Calculate cross-price elasticity for each good with respect to the other three goods\n",
    "cross_price_elasticities = {}\n",
    "\n",
    "for good in goods:\n",
    "    cross_price_elasticities[good] = {}\n",
    "    for other_good in goods:\n",
    "        if good != other_good:\n",
    "            cross_price_elasticities[good][other_good] = -prices[other_good] * shares[other_good] * store_week_data['price_coef'].mean()\n",
    "\n",
    "# Print the cross-price elasticities\n",
    "for good, elasticities in cross_price_elasticities.items():\n",
    "    print(f\"Cross-price elasticities for {good}:\")\n",
    "    for other_good, elasticity in elasticities.items():\n",
    "        print(f\"  With respect to {other_good}: {elasticity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the data for store 9 in week 10\n",
    "store_week_data = df_merged[(df_merged['store'] == 9) & (df_merged['week'] == 10)]\n",
    "\n",
    "# Calculate the marginal cost for each brand\n",
    "store_week_data['marginal_cost'] = store_week_data['price_'] + (1 / store_week_data['own_price_elasticity'])\n",
    "\n",
    "# Display the marginal costs\n",
    "store_week_data[['brand', 'price_', 'own_price_elasticity', 'marginal_cost', 'cost_']]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the simple average marginal cost for each brand\n",
    "# Calculate the simple average marginal cost for each brand group\n",
    "average_marginal_costs_group1 = store_week_data[store_week_data['brand'].isin([1, 2, 3])]['marginal_cost'].mean()\n",
    "average_marginal_costs_group2 = store_week_data[store_week_data['brand'].isin([4, 5, 6])]['marginal_cost'].mean()\n",
    "average_marginal_costs_group3 = store_week_data[store_week_data['brand'].isin([7, 8, 9])]['marginal_cost'].mean()\n",
    "average_marginal_costs_group4 = store_week_data[store_week_data['brand'].isin([10, 11])]['marginal_cost'].mean()\n",
    "\n",
    "# Calculate the simple average cost for each brand group\n",
    "average_costs_group1 = store_week_data[store_week_data['brand'].isin([1, 2, 3])]['cost_'].mean()\n",
    "average_costs_group2 = store_week_data[store_week_data['brand'].isin([4, 5, 6])]['cost_'].mean()\n",
    "average_costs_group3 = store_week_data[store_week_data['brand'].isin([7, 8, 9])]['cost_'].mean()\n",
    "average_costs_group4 = store_week_data[store_week_data['brand'].isin([10, 11])]['cost_'].mean()\n",
    "\n",
    "# Print the results\n",
    "print(\"Average Marginal Costs for each brand group:\")\n",
    "print(f\"Group 1 (Brands 1, 2, 3): {average_marginal_costs_group1}\")\n",
    "print(f\"Group 2 (Brands 4, 5, 6): {average_marginal_costs_group2}\")\n",
    "print(f\"Group 3 (Brands 7, 8, 9): {average_marginal_costs_group3}\")\n",
    "print(f\"Group 4 (Brands 10, 11): {average_marginal_costs_group4}\")\n",
    "\n",
    "print(\"\\nAverage Costs for each brand group:\")\n",
    "print(f\"Group 1 (Brands 1, 2, 3): {average_costs_group1}\")\n",
    "print(f\"Group 2 (Brands 4, 5, 6): {average_costs_group2}\")\n",
    "print(f\"Group 3 (Brands 7, 8, 9): {average_costs_group3}\")\n",
    "print(f\"Group 4 (Brands 10, 11): {average_costs_group4}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the overall average marginal cost\n",
    "overall_avg_marginal_cost = np.mean(list(weighted_avg_marginal_cost.values()))\n",
    "\n",
    "# Calculate the overall average elasticity\n",
    "overall_avg_elasticity = np.mean([\n",
    "    elasticity_brand1_store_week,\n",
    "    elasticity_brand2_store_week,\n",
    "    elasticity_brand3_store_week,\n",
    "    elasticity_brand4_store_week,\n",
    "    elasticity_brand5_store_week,\n",
    "    elasticity_brand6_store_week,\n",
    "    elasticity_brand7_store_week,\n",
    "    elasticity_brand8_store_week,\n",
    "    elasticity_brand9_store_week,\n",
    "    elasticity_brand11_store_week,\n",
    "    elasticity_sto_store_week\n",
    "])\n",
    "\n",
    "# Print the results\n",
    "print(f\"Overall Average Marginal Cost: {overall_avg_marginal_cost}\")\n",
    "print(f\"Overall Average Elasticity: {overall_avg_elasticity}\")\n",
    "\n",
    "predicted_price=overall_avg_marginal_cost/(1+overall_avg_elasticity)\n",
    "predicted_price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **QUESTION 5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model parameters\n",
    "alpha = -0.0514  # Price coefficient from model (a)\n",
    "beta_prom = 0.3778387  # Promotion coefficient from model (a)\n",
    "\n",
    "# Remove all Tylenol products from the dataset\n",
    "df_no_tyl = df1[df1['tyl'] == 0]\n",
    "\n",
    "# Recalculate the total sales without Tylenol\n",
    "total_sales_no_tyl = df_no_tyl['sales_'].sum()\n",
    "\n",
    "# Recalculate the sales share for each remaining brand\n",
    "brand_sales_no_tyl = df_no_tyl.groupby('brand')['sales_'].sum()\n",
    "\n",
    "# Generate new share variables for each remaining brand\n",
    "shares_no_tyl = brand_sales_no_tyl / total_sales_no_tyl\n",
    "\n",
    "# Predict the new shares using the model parameters\n",
    "predicted_shares_no_tyl = {}\n",
    "for brand, share in shares_no_tyl.items():\n",
    "    price = df_no_tyl[df_no_tyl['brand'] == brand]['price_'].mean()\n",
    "    prom = df_no_tyl[df_no_tyl['brand'] == brand]['prom_'].mean()\n",
    "    denominator = sum(np.exp(alpha * df_no_tyl['price_'] + beta_prom * df_no_tyl['prom_']))\n",
    "    predicted_share = np.exp(alpha * price + beta_prom * prom) / denominator\n",
    "    predicted_shares_no_tyl[brand] = predicted_share\n",
    "\n",
    "\n",
    "# Scale the predicted shares so that they sum up to 1\n",
    "total_predicted_share = sum(predicted_shares_no_tyl.values())\n",
    "scaled_predicted_shares_no_tyl = {brand: share / total_predicted_share for brand, share in predicted_shares_no_tyl.items()}\n",
    "\n",
    "# Print the scaled predicted shares\n",
    "for brand, scaled_share in scaled_predicted_shares_no_tyl.items():\n",
    "        print(f\"Scaled predicted share for brand {brand}: {scaled_share}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
